apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: rbac
    app.kubernetes.io/version: 1.0.0
    helm.sh/chart: rbac-0.9.0
  name: harness-default
  namespace: harness
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-manager
    app.kubernetes.io/version: 0.0.81725
    helm.sh/chart: harness-manager-1.105.3
  name: harness-manager
  namespace: harness
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: platform-service
    app.kubernetes.io/version: 0.0.80000
    helm.sh/chart: platform-service-1.84.1
  name: harness-platform-service
  namespace: harness
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: queue-service
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: queue-service-1.7.4
  name: harness-queue-service
  namespace: harness
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iacm-manager
    app.kubernetes.io/part-of: harness-infra-as-code
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: iacm-manager-1.100.1
  name: iacm-manager
  namespace: harness
---
apiVersion: v1
automountServiceAccountToken: false
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2025.7.18
    helm.sh/chart: minio-17.0.15
  name: minio
  namespace: harness
secrets:
- name: minio
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/version: 6.0.1
    helm.sh/chart: mongodb-13.1.2
  name: mongodb-replicaset-chart
  namespace: harness
secrets:
- name: mongodb-replicaset-chart
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-manager
    app.kubernetes.io/version: 0.0.80209
    helm.sh/chart: ng-manager-1.107.6
  name: ng-manager
  namespace: harness
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app: postgres
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.2.0
    helm.sh/chart: postgresql-12.4.2
  name: postgres
  namespace: harness
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: template-service
    app.kubernetes.io/version: 1.12.1
    helm.sh/chart: template-service-1.109.2
  name: template-service
  namespace: harness
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-manager
    app.kubernetes.io/version: 0.0.81725
    helm.sh/chart: harness-manager-1.105.3
  name: harness-manager-additional-role
  namespace: harness
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: rbac
    app.kubernetes.io/version: 1.0.0
    helm.sh/chart: rbac-0.9.0
  name: harness-manager-role
  namespace: harness
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iacm-manager
    app.kubernetes.io/part-of: harness-infra-as-code
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: iacm-manager-1.100.1
  name: iacm-manager-role
  namespace: harness
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-manager
    app.kubernetes.io/version: 0.0.80209
    helm.sh/chart: ng-manager-1.107.6
  name: ng-manager-role
  namespace: harness
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: platform-service
    app.kubernetes.io/version: 0.0.80000
    helm.sh/chart: platform-service-1.84.1
  name: platform-service-role
  namespace: harness
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: queue-service
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: queue-service-1.7.4
  name: queue-service-role
  namespace: harness
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: template-service
    app.kubernetes.io/version: 1.12.1
    helm.sh/chart: template-service-1.109.2
  name: template-service-role
  namespace: harness
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-manager
    app.kubernetes.io/version: 0.0.81725
    helm.sh/chart: harness-manager-1.105.3
  name: harness-manager-additional-role-binding
  namespace: harness
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: harness-manager-additional-role
subjects:
- kind: ServiceAccount
  name: harness-manager
  namespace: harness
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: rbac
    app.kubernetes.io/version: 1.0.0
    helm.sh/chart: rbac-0.9.0
  name: harness-manager-role-binding
  namespace: harness
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: harness-manager-role
subjects:
- kind: ServiceAccount
  name: harness-default
  namespace: harness
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iacm-manager
    app.kubernetes.io/part-of: harness-infra-as-code
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: iacm-manager-1.100.1
  name: iacm-manager-role-binding
  namespace: harness
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: iacm-manager-role
subjects:
- kind: ServiceAccount
  name: iacm-manager
  namespace: harness
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-manager
    app.kubernetes.io/version: 0.0.80209
    helm.sh/chart: ng-manager-1.107.6
  name: ng-manager-role-binding
  namespace: harness
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ng-manager-role
subjects:
- kind: ServiceAccount
  name: ng-manager
  namespace: harness
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: platform-service
    app.kubernetes.io/version: 0.0.80000
    helm.sh/chart: platform-service-1.84.1
  name: platform-service-role-binding
  namespace: harness
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: platform-service-role
subjects:
- kind: ServiceAccount
  name: harness-platform-service
  namespace: harness
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: queue-service
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: queue-service-1.7.4
  name: queue-service-role-binding
  namespace: harness
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: queue-service-role
subjects:
- kind: ServiceAccount
  name: harness-queue-service
  namespace: harness
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: template-service
    app.kubernetes.io/version: 1.12.1
    helm.sh/chart: template-service-1.109.2
  name: template-service-role-binding
  namespace: harness
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: template-service-role
subjects:
- kind: ServiceAccount
  name: template-service
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control:9006/api/
  ACCESS_CONTROL_PREFERENCE_ENABLED: "true"
  ACCESS_CONTROL_READ_TIMEOUT: "10"
  ACCESS_CONTROL_SERVICE_BASE_URL: http://access-control:9006/api/
  ACCOUNT_CLIENT_BASE_URL: http://harness-manager:9090/api/
  ACL_DELETION_SLEEP_IN_MILLIS: "1000"
  ACL_HEAVY_OPERATION_SLEEP_IN_MILLIS: "5000"
  ACL_HEAVY_OPERATION_THRESHOLD: "100000"
  ACL_RECONCILIATION_ITERATOR_ENABLED: "true"
  ACL_RECONCILIATION_ITERATOR_INTERVAL: "172800"
  ACL_RECONCILIATION_ITERATOR_THREAD_COUNT: "5"
  AGGREGATOR_ENABLED: "true"
  AUDIT_CLIENT_BASE_URL: http://platform-service:9005/api/
  AUDIT_CLIENT_BASEURL: http://platform-service:9005/api/
  AUDIT_ENABLED: "true"
  BATCH_SIZE_FOR_ACL_CREATION: "5000"
  BATCH_SIZE_FOR_ACL_DELETION: "10000"
  CDE_MANAGER_CLIENT_BASEURL: http://cde-manager:80/api/
  CDE_READ_TIMEOUT: "15"
  CE_NEXTGEN_CLIENT_BASEURL: http://nextgen-ce:6340/ccm/api/
  CE_NG_READ_TIMEOUT: "15"
  CG_MANAGER_READ_TIMEOUT: "10"
  CODE_READ_TIMEOUT: "15"
  CODE_SERVICE_CLIENT_BASEURL: http://code-api:80/
  CODE_SERVICE_SECRET: ""
  DBOPS_SERVICE_CLIENT_BASEURL: http://db-devops-service:5001/
  DEPLOY_MODE: KUBERNETES_ONPREM
  DISTRIBUTED_LOCK_IMPLEMENTATION: REDIS
  DYNAMIC_RESOURCE_REFRESH_INTERVAL_IN_SECONDS: "300"
  ENABLE_ACCESS_CHECK_USING_PRINCIPAL_UNIQUE_ID: "false"
  ENABLE_ACCESS_CONTROL: "true"
  ENABLE_ACL_PROCESSING_THROUGH_OUTBOX: "true"
  ENABLE_AUDIT: "true"
  ENABLE_AUTH: "true"
  ENABLE_LOAD_PRIVILEGED_ROLES_FROM_DB: "false"
  ENABLE_PARALLEL_PROCESSING_OF_USERGROUP_UPDATES: "true"
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  ENABLE_RESOURCE_GROUP: "false"
  ENFORCEMENT_CHECK_ENABLED: "true"
  ENV: SMP
  EVENTS_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_CONFIG_USE_SENTINEL: "true"
  EVENTS_FRAMEWORK_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_USE_SENTINEL: "true"
  FEATURE_FLAG_CLIENT_BASE_URL: http://harness-manager:9090/api/
  FILE_LOGGING_ENABLED: "true"
  FIPS_ENABLED: "false"
  GITOPS_SERVICE_CLIENT_BASEURL: http://gitops:7908/api/v1/
  GOOGLE_APPLICATION_CREDENTIALS: /opt/harness/monitoring/stackdriver.json
  HAR_READ_TIMEOUT: "10"
  HAR_SERVICE_CLIENT_BASEURL: http://registry-api:8181/api/
  IDP_READ_TIMEOUT: "10"
  IDP_SERVICE_CLIENT_BASEURL: http://idp-service:12003/
  IGNORE_SERVICE_NAME_MATCH: "true"
  IN_MEMORY_REFRESH_OF_DISABLED_PERMISSIONS_INTERVAL_SECONDS: "5"
  IN_MEMORY_REFRESH_OF_RESOURCE_TYPE_AND_PERMISSIONS_MAP_INTERVAL_SECONDS: "5"
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  JAVA_ADVANCED_FLAGS: -XX:+ExitOnOutOfMemoryError
  LOCK_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  LOCK_CONFIG_USE_SENTINEL: "true"
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  LOGGING_LEVEL: INFO
  MANAGED_ROLES_SLEEP_IN_MILLIS: "10000"
  MANAGER_CLIENT_BASEURL: http://harness-manager:9090/api/
  MAX_ACLS_PER_ACCESS_POLICY_CHANGE: "5000000"
  MEMORY: 512m
  MONGO_MAX_OPERATION_TIME_IN_MILLIS: "15000"
  NG_MANAGER_CLIENT_BASEURL: http://ng-manager:7090/
  NG_MANAGER_READ_TIMEOUT: "60"
  NOTIFICATION_ENVIRONMENT: ONPREM
  NOTIFICATION_SLACK_WEBHOOK_URL: ""
  OPA_CONNECTIVITY_ENABLED: "true"
  OPA_READ_TIMEOUT: "10"
  OPA_SERVER_BASEURL: http://policy-mgmt.harness.svc.cluster.local:3000/
  ORGANIZATION_CLIENT_BASE_URL: http://ng-manager:7090/
  OUTBOX_LOCK_DURATION: "5"
  PIPELINE_READ_TIMEOUT: "15"
  PIPELINE_SERVICE_CLIENT_BASEURL: http://pipeline-service:12001/api/
  PLATFORM_READ_TIMEOUT: "10"
  POLICY_ANALYZER_QUERY_TIMEOUT_IN_MS: "30000"
  PROJECT_CLIENT_BASE_URL: http://ng-manager:7090/
  PROMETHEUS_COLLECTOR_PORT: "8889"
  REDISSON_PING_CONNECTION_INTERVAL_IN_MILLIS: "0"
  REFRESH_PRIVILEGED_ROLES_INTERVAL_SECONDS: "300"
  RESOURCE_GROUP_CLIENT_BASE_URL: http://platform-service:9005/api/
  RESOURCE_GROUP_ITERATOR_ENABLED: "true"
  RESOURCE_GROUP_ITERATOR_INTERVAL: "21600"
  RESOURCE_GROUP_ITERATOR_THREAD_COUNT: "2"
  RESOURCE_IDENTIFIERS_THRESHOLD: "1300"
  RESOURCEGROUP_MONGO_MAX_DOCUMENT_LIMIT: "10000"
  RESOURCEGROUP_MONGO_MAX_OPERATION_TIME_IN_MILLIS: "25000"
  ROLE_MANAGEMENT_SERVICE_DELAY_IN_MINUTES: "1440"
  SCOPE_ITERATOR_ENABLED: "true"
  SCOPE_ITERATOR_INTERVAL: "43200"
  SCOPE_ITERATOR_THREAD_COUNT: "2"
  SCOPE_SELECTOR_THRESHOLD: "75"
  SERVICEACCOUNT_CLIENT_BASE_URL: http://ng-manager:7090/
  SERVICEACCOUNT_ITERATOR_ENABLED: "true"
  SERVICEACCOUNT_ITERATOR_INTERVAL: "21600"
  SERVICEACCOUNT_ITERATOR_THREAD_COUNT: "2"
  SKIP_ADD_ACL_QUERY_STRING_V2: "false"
  STACK_DRIVER_LOGGING_ENABLED: "false"
  SUPPORTPREFERENCE_ITERATOR_ENABLED: "true"
  SUPPORTPREFERENCE_ITERATOR_INTERVAL: "600"
  SUPPORTPREFERENCE_ITERATOR_THREAD_COUNT: "5"
  TEMPLATE_SERVICE_CLIENT_BASEURL: http://template-service:15002/api/
  TEMPLATE_SERVICE_READ_TIMEOUT: "10"
  USER_CLIENT_BASE_URL: http://ng-manager:7090/
  USER_GROUP_CLIENT_BASE_URL: http://ng-manager:7090/
  USER_GROUP_ITERATOR_ENABLED: "true"
  USER_GROUP_ITERATOR_INTERVAL: "43200"
  USER_GROUP_ITERATOR_THREAD_COUNT: "2"
  USER_ITERATOR__THREAD_COUNT: "2"
  USER_ITERATOR_ENABLED: "true"
  USER_ITERATOR_INTERVAL: "43200"
kind: ConfigMap
metadata:
  labels: null
  name: access-control
  namespace: harness
---
apiVersion: v1
data:
  AUDIT_CLIENT_BASEURL: http://platform-service:9005/api/
  BATCH_CURSOR_SIZE: "1000"
  BATCH_LIMIT: "10000"
  BATCH_MAX_RETRIES: "3"
  DEPLOY_MODE: KUBERNETES_ONPREM
  EVENT_COLLECTION_BATCH_JOB_CRON: 0 */30 * * * *
  GRPC_MANAGER_AUTHORITY: harness-manager:9879
  GRPC_MANAGER_TARGET: harness-manager:9879
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  JAVA_ADVANCED_FLAGS: -XX:NativeMemoryTracking=summary -XX:-UseBiasedLocking -XX:+UseG1GC
  LOGGING_LEVEL: INFO
  MEMORY: 768m
  MONGO_MAX_DOCUMENT_LIMIT: "10000"
  MONGO_MAX_OPERATION_TIME_IN_MILLIS: "30000"
  NG_MANAGER_CLIENT_BASEURL: http://ng-manager:7090/
  REDISSON_PING_CONNECTION_INTERVAL_IN_MILLIS: "0"
  REPLICA: "1"
  STACK_DRIVER_LOGGING_ENABLED: "false"
  SUMO_LOGIC_BATCH_CURSOR_SIZE: "1000"
  SUMO_LOGIC_BATCH_LIMIT: "1000"
  SUMO_LOGIC_BATCH_MAX_RETRIES: "2"
kind: ConfigMap
metadata:
  labels: null
  name: audit-event-streaming
  namespace: harness
---
apiVersion: v1
data:
  cgi-config.yaml: |
    - cgiTaskExecutables:
      - arch: amd64
        os: darwin
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/AwsSecretManager/0.0.1/AwsSecretManager-darwin-amd64
      - arch: arm64
        os: darwin
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/AwsSecretManager/0.0.1/AwsSecretManager-darwin-arm64
      - arch: amd64
        os: linux
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/AwsSecretManager/0.0.1/AwsSecretManager-linux-amd64
      - arch: arm64
        os: linux
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/AwsSecretManager/0.0.1/AwsSecretManager-linux-arm64
      - arch: arm64
        os: windows
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/AwsSecretManager/0.0.1/AwsSecretManager-windows-arm64
      - arch: amd64
        os: windows
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/AwsSecretManager/0.0.1/AwsSecretManager-windows-amd64
      type: AwsSecretManager
      version: 0.0.1
    - cgiTaskExecutables:
      - arch: amd64
        os: darwin
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/DockerRegistry/0.0.1/DockerRegistry-darwin-amd64
      - arch: arm64
        os: darwin
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/DockerRegistry/0.0.1/DockerRegistry-darwin-arm64
      - arch: amd64
        os: linux
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/DockerRegistry/0.0.1/DockerRegistry-linux-amd64
      - arch: arm64
        os: linux
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/DockerRegistry/0.0.1/DockerRegistry-linux-arm64
      - arch: arm64
        os: windows
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/DockerRegistry/0.0.1/DockerRegistry-windows-arm64
      - arch: amd64
        os: windows
        url: https://storage.googleapis.com/harness-qa-public/public/shared/cgi/DockerRegistry/0.0.1/DockerRegistry-windows-amd64
      type: DockerRegistry
      version: 0.0.1
    - cgiTaskExecutables:
      - arch: amd64
        os: darwin
        url: https://storage.googleapis.com/harness-prod-public/public/shared/tools/scm/release/16f77b41c/bin/darwin/amd64/scm
      - arch: arm64
        os: darwin
        url: https://storage.googleapis.com/harness-prod-public/public/shared/tools/scm/release/16f77b41c/bin/darwin/amd64/scm
      - arch: amd64
        os: linux
        url: https://storage.googleapis.com/harness-prod-public/public/shared/tools/scm/release/16f77b41c/bin/linux/amd64/scm
      - arch: arm64
        os: linux
        url: https://storage.googleapis.com/harness-prod-public/public/shared/tools/scm/release/16f77b41c/bin/linux/arm64/scm
      - arch: arm64
        os: windows
        url: https://storage.googleapis.com/harness-prod-public/public/shared/tools/scm/release/16f77b41c/bin/windows/amd64/scm
      - arch: amd64
        os: windows
        url: https://storage.googleapis.com/harness-prod-public/public/shared/tools/scm/release/16f77b41c/bin/windows/amd64/scm
      type: SCM
      version: 0.0.2
kind: ConfigMap
metadata:
  name: cgi-config-ng-manager
  namespace: harness
---
apiVersion: v1
data:
  DEPLOY_MODE: KUBERNETES
  ENV: SMP
  FILE_LOGGING_ENABLED: "true"
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  MEMORY: "2048"
  MONGO_TAG_NAME: none
  MONGO_TAG_VALUE: none
  STACK_DRIVER_LOGGING_ENABLED: "false"
kind: ConfigMap
metadata:
  name: change-data-capture
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control:9006/api/
  ACCESS_CONTROL_ENABLED: "true"
  ACR_PUSH_IMAGE: plugins/kaniko-acr:1.11.4
  ADDON_IMAGE: harness/ci-addon:1.17.3
  ADDON_IMAGE_ROOTLESS: harness/ci-addon:rootless-1.17.3
  ANCHORE_IMAGE: harness/anchore-job-runner:latest
  API_URL: https://harness.mcintosh.farm/ng/
  AQUA_SECURITY_IMAGE: harness/aqua-security-job-runner:latest
  AQUA_TRIVY_IMAGE: harness/aqua-trivy-job-runner:latest
  ARTIFACTORY_UPLOAD_IMAGE: plugins/artifactory:1.7.6
  ASYNC_DELEGATE_RESPONSE_THREAD_COUNT: "10"
  AWS_ECR_IMAGE: harness/aws-ecr-job-runner:latest
  AWS_SECURITY_HUB_IMAGE: harness/aws-security-hub-job-runner:latest
  BANDIT_IMAGE: harness/bandit-job-runner:latest
  BLACKDUCK_IMAGE: harness/blackduckhub-job-runner:latest
  BRAKEMAN_IMAGE: harness/brakeman-job-runner:latest
  BUILD_PUSH_ACR_DLC_IMAGE: plugins/buildx-acr:1.3.4
  BUILD_PUSH_DOCKER_DLC_IMAGE: plugins/buildx:1.3.6
  BUILD_PUSH_ECR_DLC_IMAGE: plugins/buildx-ecr:1.3.4
  BUILD_PUSH_GAR_DLC_IMAGE: plugins/buildx-gar:1.3.4
  BUILD_PUSH_GCR_DLC_IMAGE: plugins/buildx-gcr:1.2.11
  CACHE_BACKEND: REDIS
  CACHE_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  CACHE_CONFIG_USE_SENTINEL: "true"
  CACHE_PROXY_IMAGE: harness/harness-cache-server:1.7.5
  CACHE_SERVICE_ENDPOINT: https://harness.mcintosh.farm/cache-service/
  CACHE_SERVICE_INTERNAL_ENDPOINT: http://cache-service:8082/
  CHECKMARX_IMAGE: harness/checkmarx-job-runner:latest
  DEFAULT_INTERNAL_IMAGE_CONNECTOR: account.harnessImage
  DEPLOY_MODE: KUBERNETES_ONPREM
  DISTRIBUTED_LOCK_IMPLEMENTATION: REDIS
  DOCKER_PUSH_IMAGE: plugins/kaniko:1.11.4
  ECR_PUSH_IMAGE: plugins/kaniko-ecr:1.11.4
  ENABLE_ASYNC_RESOURCE_CLEANUP: "true"
  ENABLE_AUTH: "true"
  ENABLE_DASHBOARD_TIMESCALE: "true"
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  ENABLE_QUEUE: "true"
  ENFORCEMENT_CHECK_ENABLED: "true"
  ENV: SMP
  EVENTS_FRAMEWORK_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_USE_SENTINEL: "true"
  FEATURE_FLAG_SYSTEM: LOCAL
  FILE_LOGGING_ENABLED: "true"
  FIPS_ENABLED: "false"
  FOSSA_IMAGE: harness/fossa-job-runner:latest
  GCR_PUSH_IMAGE: plugins/kaniko-gcr:1.11.4
  GCS_CACHE_IMAGE: plugins/cache:1.9.11
  GCS_UPLOAD_IMAGE: plugins/gcs:1.6.6
  GIT_CLONE_IMAGE: harness/drone-git:1.7.2-rootless
  GITHUB_ADVANCED_SECURITY_IMAGE: harness/github-advanced-security-job-runner:latest
  GITNESS_INTERNAL_URL: http://code-api:80/
  GRPC_MAX_CONNECTION_AGE: "30"
  GRPC_SERVER_PORT: "9979"
  GRYPE_IMAGE: harness/grype-job-runner:latest
  HARNESS_CODE_GIT_URL: https://harness.mcintosh.farm/code/git
  HSQS_BASE_URL: http://queue-service:9091/
  IACM_EXTERNAL_SERVICE_ENDPOINT: https://harness.mcintosh.farm/iacm/
  IACM_INFRACOST_API_ENDPOINT: https://harness.mcintosh.farm/iac-pricing/
  IACM_SERVICE_ENDPOINT: http://iac-server.harness.svc.cluster.local:8080/
  INTERNAL_MANAGER_AUTHORITY: dns:///harness-manager-headless:9879
  INTERNAL_MANAGER_TARGET: dns:///harness-manager-headless:9879
  INTERNAL_PMS_AUTHORITY: dns:///pipeline-service-headless:12011
  INTERNAL_PMS_TARGET: dns:///pipeline-service-headless:12011
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  JAVA_ADVANCED_FLAGS: -XX:+ExitOnOutOfMemoryError
  LE_IMAGE: harness/ci-lite-engine:1.17.3
  LE_IMAGE_ROOTLESS: harness/ci-lite-engine:rootless-1.17.3
  LOCK_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  LOCK_CONFIG_USE_SENTINEL: "true"
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_SERVICE_ENDPOINT: https://harness.mcintosh.farm/log-service/
  LOG_SERVICE_INTERNAL_URL: http://log-service:8079/
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  LOGGING_LEVEL: INFO
  MANAGER_AUTHORITY: harness-manager:9879
  MANAGER_TARGET: harness-manager:9879
  MANAGER_URL: http://harness-manager:9090/api/
  MEMORY: 4096m
  MODELSCAN_IMAGE: harness/modelscan-job-runner:latest
  NEXUSIQ_IMAGE: harness/nexusiq-job-runner:latest
  NG_MANAGER_URL: http://ng-manager:7090/
  NIKTO_IMAGE: harness/nikto-job-runner:latest
  NMAP_IMAGE: harness/nmap-job-runner:latest
  OPA_SERVER_BASEURL: http://policy-mgmt:3000/
  OSV_SCANNER_IMAGE: harness/osv-job-runner:latest
  OWASP_IMAGE: harness/owasp-dependency-check-job-runner:latest
  PIPELINE_SDK_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_RESPONSE_SPAWN_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_STEP_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PLAN_CREATOR_SERVICE_EXECUTOR_POOL_CORE_SIZE: "150"
  PLAN_CREATOR_SERVICE_EXECUTOR_POOL_MAX_SIZE: "200"
  PMS_AUTHORITY: pipeline-service:12011
  PMS_SDK_EXECUTION_POOL_CORE_SIZE: "300"
  PMS_SDK_EXECUTION_POOL_MAX_SIZE: "500"
  PMS_TARGET: pipeline-service:12011
  PROMETHEUS_COLLECTOR_PORT: "8889"
  PROWLER_IMAGE: harness/prowler-job-runner:latest
  REDISSON_PING_CONNECTION_INTERVAL_IN_MILLIS: "0"
  S3_CACHE_IMAGE: plugins/cache:1.9.11
  S3_UPLOAD_IMAGE: plugins/s3:1.5.3
  SCM_SERVICE_URI: dns:///scm-service-headless:8091
  SECURITY_IMAGE: harness/sto-plugin:latest
  SHOULD_CONFIGURE_WITH_PMS: "true"
  SONARQUBE_IMAGE: harness/sonarqube-agent-job-runner:latest
  STACK_DRIVER_LOGGING_ENABLED: "false"
  STO_IMAGE: harness/sto-plugin:latest
  STO_SERVICE_ENDPOINT: https://harness.mcintosh.farm/sto/
  STO_SERVICE_INTERNAL_ENDPOINT: http://sto-core.harness.svc.cluster.local:4000/
  SYNK_IMAGE: harness/snyk-job-runner:latest
  TI_SERVICE_ENDPOINT: https://harness.mcintosh.farm/ti-service/
  TI_SERVICE_INTERNAL_URL: http://ti-service:8078/
  TRACEABLE_IMAGE: harness/traceable-job-runner:latest
  TWISTLOCK_IMAGE: harness/twistlock-job-runner:latest
  USE_REDIS_FOR_SDK_RESPONSE_EVENTS: "true"
  VERACODE_IMAGE: harness/veracode-agent-job-runner:latest
  VM_ACR_PUSH_IMAGE: plugins/acr:21.0.1
  VM_DOCKER_PUSH_IMAGE: plugins/docker:21.0.1
  VM_ECR_PUSH_IMAGE: plugins/ecr:21.0.1
  VM_GAR_PUSH_IMAGE: plugins/gar:21.0.1
  VM_GCR_PUSH_IMAGE: plugins/gcr:21.0.1
  WHITE_SOURCE_IMAGE: harness/whitesource-agent-job-runner:latest
  WIZ_IMAGE: harness/wiz-job-runner:latest
  ZAP_IMAGE: harness/zap-job-runner:latest
kind: ConfigMap
metadata:
  labels: null
  name: ci-manager
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control.harness.svc.cluster.local:9006/api/
  ACCESS_CONTROL_ENABLED: "true"
  AUDIT_CLIENT_BASEURL: http://platform-service.harness.svc.cluster.local:9005/api/
  CACHE_BACKEND: REDIS
  CACHE_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  CACHE_CONFIG_USE_SENTINEL: "true"
  DEPLOY_MODE: KUBERNETES_ONPREM
  ENABLE_AUDIT: "true"
  ENABLE_DASHBOARD_TIMESCALE: "true"
  ENABLE_PROMETHEUS_COLLECTOR: "true"
  ENV: SMP
  ET_SERVICE_BASE_URL: http://et-service.harness.svc.cluster.local:9191/api/
  EVENTS_FRAMEWORK_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_USE_SENTINEL: "true"
  FILE_LOGGING_ENABLED: "true"
  GRPC_SERVER_PORT: "9979"
  INTERNAL_PMS_AUTHORITY: pipeline-service:12011
  INTERNAL_PMS_TARGET: pipeline-service:12011
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  JAVA_ADVANCED_FLAGS: -XX:+ExitOnOutOfMemoryError
  LOCK_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  LOCK_CONFIG_USE_SENTINEL: "true"
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  LOGGING_LEVEL: INFO
  MANAGER_AUTHORITY: dns:///harness-manager-headless:9879
  MANAGER_CLIENT_BASEURL: http://harness-manager.harness.svc.cluster.local:9090/
  MANAGER_TARGET: dns:///harness-manager-headless:9879
  MANAGER_URL: http://harness-manager.harness.svc.cluster.local:9090/
  MEMORY: "4096"
  MOCK_ACCESS_CONTROL_SERVICE: "false"
  NG_MANAGER_URL: http://ng-manager.harness.svc.cluster.local:7090/
  NOTIFICATION_BASE_URL: http://platform-service.harness.svc.cluster.local:9005/api/
  PIPELINE_SDK_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_RESPONSE_SPAWN_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_STEP_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SERVICE_CLIENT_BASEURL: http://pipeline-service:12001/api/
  PMS_AUTHORITY: pipeline-service:12011
  PMS_TARGET: pipeline-service:12011
  PORTAL_URL: https://harness.mcintosh.farm
  PROMETHEUS_COLLECTOR_PORT: "8889"
  SERVICE_DISCOVERY_SERVICE_BASE_URL: http://service-discovery-manager:8080/
  SHOULD_CONFIGURE_WITH_NOTIFICATION: "true"
  SHOULD_CONFIGURE_WITH_PMS: "true"
  STACK_DRIVER_LOGGING_ENABLED: "false"
  TEMPLATE_SERVICE_ENDPOINT: http://template-service:15002/api/
  VERIFICATION_PORT: "6060"
  WEBHOOK_BASEURL: https://harness.mcintosh.farm/gateway/cv/api/
kind: ConfigMap
metadata:
  labels: null
  name: cv-nextgen
  namespace: harness
---
apiVersion: v1
data:
  proxy.conf: |-
    server { root /www/data;proxy_http_version 1.1;
    }
kind: ConfigMap
metadata:
  labels: null
  name: delegate-proxy
  namespace: harness
---
apiVersion: v1
data:
  license_manager_config.json: |
    {
      "PRODUCT_CONFIGURATIONS" : [
        {
          "LICENSING_MODEL" : {
            "LICENSING_TYPE" : "DEVOPS_ESSENTIALS"
          },
          "PRICING_MODEL" : [
            {
              "MODULE_TYPE": "HARNESS_CD",
              "PREPAY_UNIT_COST": 0.5,
              "POSTPAY_UNIT_COST": 0.575,
              "INCLUDED_QUANTITY": 25000,
              "PREPAY_EXTENSION_QUANTITY": 5000,
              "DISPLAY_NAME": "Continuous Delivery & GitOps",
              "DESCRIPTION": "Deploy applications with automated pipelines and GitOps workflows",
              "ICON": "cd-main",
              "ENABLED": true,
              "UNIT": "deployment events",
              "DISPLAY_TEXT": "{quantity:,} deployment events included"
            },
            {
              "MODULE_TYPE": "HARNESS_CI",
              "PREPAY_UNIT_COST": 0.005,
              "POSTPAY_UNIT_COST": 0.00575,
              "INCLUDED_QUANTITY": 300000,
              "PREPAY_EXTENSION_QUANTITY": 2500000,
              "DISPLAY_NAME": "Continuous Integration",
              "DESCRIPTION": "Build, test, and scan your code with intelligent pipelines",
              "ICON": "ci-main",
              "ENABLED": true,
              "UNIT": "build minutes",
              "DISPLAY_TEXT": "{quantity:,} build minutes included"
            },
            {
              "MODULE_TYPE": "HARNESS_STO",
              "PREPAY_UNIT_COST": 1,
              "POSTPAY_UNIT_COST": 1.15,
              "INCLUDED_QUANTITY": 3600,
              "PREPAY_EXTENSION_QUANTITY": 2500,
              "DISPLAY_NAME": "Security Testing Orchestration",
              "DESCRIPTION": "Comprehensive security testing integrated into your pipelines",
              "ICON": "sto-color-filled",
              "ENABLED": true,
              "UNIT": "security scans",
              "DISPLAY_TEXT": "{quantity:,} security scans included"
            },
            {
              "MODULE_TYPE": "HARNESS_IACM",
              "PREPAY_UNIT_COST": 1.5,
              "POSTPAY_UNIT_COST": 1.725,
              "INCLUDED_QUANTITY": 500,
              "PREPAY_EXTENSION_QUANTITY": 1700,
              "DISPLAY_NAME": "Infrastructure as Code Management",
              "DESCRIPTION": "Provision and manage cloud infrastructure with confidence",
              "ICON": "iacm-blue",
              "ENABLED": true,
              "UNIT": "resource hours",
              "DISPLAY_TEXT": "{quantity:,} resource hours included"
            }
          ],
          "CURRENCY": "USD",
          "BASE_PRICE_PER_SEAT": 30.0,
          "BILLING_OPTIONS": [
            {
              "CYCLE": "MONTHLY",
              "PRICE_PER_SEAT": 30.0,
              "DISCOUNT_PERCENTAGE": 0.0
            },
            {
              "CYCLE": "ANNUAL",
              "PRICE_PER_SEAT": 24.0,
              "DISCOUNT_PERCENTAGE": 20.0
            }
          ],
          "LIMITS": {
            "MIN_SEATS": 1,
            "MAX_SEATS": 500,
            "DEFAULT_SEATS": 50
          }
        }
      ]
    }
kind: ConfigMap
metadata:
  name: devops-essentials-config-ng-manager
  namespace: harness
---
apiVersion: v1
data:
  API_VERSION: release-gateway:182
  CACHE_TYPE: REDIS
  DEPLOY_MODE: KUBERNETES_ONPREM
  ENABLE_LETTUCE_REJECT: "false"
  ENABLE_OAUTH_SIGNUP: "true"
  ENABLE_USER_IMPERSONATION: "true"
  ENV: SMP
  FIPS_ENABLED: "false"
  HARNESS_ENABLE_NG_AUTH_UI: "true"
  HTTP_CLIENT_CONNECT_TIMEOUT_SECONDS: "10"
  HTTP_CLIENT_READ_TIMEOUT_SECONDS: "15"
  JAVA_ADVANCED_FLAGS: -Dreactor.netty.ioWorkerCount=1024
  MANAGER_PUBLIC_URL: https://harness.mcintosh.farm
  MANAGER_URL: https://harness.mcintosh.farm
  MEMORY: "512"
  REDIS_HOST: redis-sentinel-harness-announce-0,redis-sentinel-harness-announce-1,redis-sentinel-harness-announce-2
  REDIS_PORT: "26379"
  REDIS_SENTINELS: redis-sentinel-harness-announce-0,redis-sentinel-harness-announce-1,redis-sentinel-harness-announce-2
  SENTINEL_MASTER_NAME: harness-redis
  TOKEN_CACHE_TTL: "300"
  USE_SENTINEL: "true"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gateway
    app.kubernetes.io/version: 0.0.11401
    helm.sh/chart: gateway-1.54.7
  name: gateway
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_DEFAULT_SCHEMES: http
  ACCESS_CONTROL_SERVICE_BASEPATH: api/
  ACCESS_CONTROL_SERVICE_HOST: access-control:9006
  ACCESS_CONTROL_SERVICE_SKIPSECUREVERIFY: "true"
  AGENT_ARGO_CD_IMAGE_REPO: docker.io/harness/argocd:v2.14.13
  AGENT_CUSTOM_IMAGE_TAG: "true"
  AGENT_DOCKER_IMAGE_REPO: docker.io/harness/gitops-agent:v0.101.2
  AGENT_ENABLE_AUTH: "true"
  AGENT_GRPC_TARGET: https://harness.mcintosh.farm:443
  AGENT_HA_PROXY_IMAGE_REPO: docker.io/haproxy:lts-alpine3.22
  AGENT_HTTP_TARGET: https://harness.mcintosh.farm/gitops
  AGENT_HTTP_TLS_ENABLED: "false"
  AGENT_PROTOCOL: HTTP1
  AGENT_REDIS_HA_CONFIG_TEST_IMAGE: docker.io/koalaman/shellcheck:v0.5.0
  AGENT_REDIS_IMAGE_REPO: docker.io/redis:7.4.1-alpine
  APP_SYNC_COMPRESS_JOB_ENABLED: "false"
  DROP_ALL_INDEXES_ONCE: "false"
  ENABLE_CDN: "false"
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  FIPS_ENABLED: "false"
  GITOPS_AGENT_UPGRADER_IMAGE: docker.io/harness/upgrader:latest
  GITOPS_AGENT_VERSION_FILE_LOCATION: /app/VERSIONS/AGENT
  GITOPS_DISABLE_TRANSACTION_IN_CASCADE_DELETE: "true"
  GITOPS_DISABLE_TRANSACTION_IN_RECONCILE: "true"
  GITOPS_LOG_FORMAT: ""
  GITOPS_LONG_RECONCILER_EVENT_THRESHOLD_ACC_LIST: '[]'
  GITOPS_MINIMUM_AGENT_VERSION_V2: 0.33.0
  GITOPS_SERVICE_CERT_PATH: ""
  GITOPS_SERVICE_GRPC_PORT: "7909"
  GITOPS_SERVICE_HTTP_ACME: "false"
  GITOPS_SERVICE_HTTP_BIND: :7908
  GITOPS_SERVICE_HTTP_HOST: https://harness.mcintosh.farm/gitops
  GITOPS_SERVICE_KEY_PATH: ""
  GITOPS_SERVICE_METRICS_PORT: "6565"
  GITOPS_SERVICE_MONGODB_DB_NAME: harness-gitops
  GITOPS_SERVICE_MONGODB_ENABLE_REFLECTION: "true"
  GITOPS_SERVICE_STREAM_TIMEOUT: 3600s
  GITOPS_SERVICE_TASK_LONG_POLLING: "true"
  GITOPS_SERVICE_TIMESCALE_DB_NAME: harness_gitops
  GITOPS_SERVICE_TIMESCALE_LOG_LEVEL: "3"
  GITOPS_SERVICE_VERSION_FILE_LOCATION: /app/VERSIONS/SERVER
  MANAGER_URL: http://harness-manager:9090/api
  PLATFORM_SERVICE_SKIPSECUREVERIFY: "true"
  PLATFORM_SERVICE_URL: http://ng-manager:7090
  PLATFORMSERVICE_AUDITS_API_PATH: audit/api
  PLATFORMSERVICE_HOST: http://platform-service:9005/api
  PLATFORMSERVICE_SKIPSECUREVERIFY: "true"
  PROMETHEUS_COLLECTOR_PORT: "6565"
  REDIS_ENDPOINT: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  REDIS_MASTER_NAME: harness-redis
  SOPS_INSTALLER_IMAGE: docker.io/harness/gitops-agent-installer-helper:v0.0.3
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gitops
    app.kubernetes.io/version: v0.81.3
    helm.sh/chart: gitops-1.41.5
  name: gitops
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control:9006/api/
  ACCESS_CONTROL_ENABLED: "true"
  ALLOWED_ORIGINS: https://harness.mcintosh.farm
  API_URL: https://harness.mcintosh.farm
  ATMOSPHERE_ASYNC_WRITE_THREADPOOL_MAXSIZE: "40"
  ATMOSPHERE_BACKEND: REDIS
  ATMOSPHERE_MESSAGE_PROCESSING_THREADPOOL_MAXSIZE: "40"
  AUDIT_CLIENT_BASEURL: http://platform-service:9005/api/
  BACKGROUND_SCHEDULER_CLUSTERED: "true"
  CACHE_BACKEND: REDIS
  CAPSULE_JAR: rest-capsule.jar
  DELEGATE_METADATA_URL: https://harness.mcintosh.farm/storage/wingsdelegates/delegateprod.txt
  DELEGATE_SERVICE_AUTHORITY: harness-manager:9879
  DELEGATE_SERVICE_TARGET: harness-manager:9879
  DELEGATE_TASK_REBROADCAST_ITERATOR_THREAD_COUNT: "2"
  DEPLOY_MODE: KUBERNETES_ONPREM
  DISABLE_INSTANCE_SYNC_ITERATOR: "true"
  DISABLE_NEW_RELIC: "true"
  DISTRIBUTED_LOCK_IMPLEMENTATION: REDIS
  ENABLE_AUDIT: "true"
  ENABLE_CRONS: "true"
  ENABLE_G1GC: "true"
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  ENV: SMP
  EVENTS_FRAMEWORK_AVAILABLE_IN_ONPREM: "true"
  EVENTS_FRAMEWORK_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_USE_SENTINEL: "true"
  EXTERNAL_GRAPHQL_RATE_LIMIT: "500"
  FAIL_DELEGATE_TASK_ITERATOR_THREAD_COUNT: "5"
  FEATURE_FLAG_SYSTEM: LOCAL
  FEATURES: ASYNC_ARTIFACT_COLLECTION,JIRA_INTEGRATION,AUDIT_TRAIL_UI,GDS_TIME_SERIES_SAVE_PER_MINUTE,STACKDRIVER_SERVICEGUARD,TIME_SERIES_SERVICEGUARD_V2,TIME_SERIES_WORKFLOW_V2,CUSTOM_DASHBOARD,GRAPHQL,CV_FEEDBACKS,LOGS_V2_247,UPGRADE_JRE,LOG_STREAMING_INTEGRATION,NG_HARNESS_APPROVAL,GIT_SYNC_NG,NG_CG_TASK_ASSIGNMENT_ISOLATION,AZURE_CLOUD_PROVIDER_VALIDATION_ON_DELEGATE,TERRAFORM_AWS_CP_AUTHENTICATION,NG_TEMPLATES,NEW_DEPLOYMENT_FREEZE,HELM_CHART_AS_ARTIFACT,RESOLVE_DEPLOYMENT_TAGS_BEFORE_EXECUTION,WEBHOOK_TRIGGER_AUTHORIZATION,GITHUB_WEBHOOK_AUTHENTICATION,CUSTOM_MANIFEST,GIT_ACCOUNT_SUPPORT,AZURE_WEBAPP,POLLING_INTERVAL_CONFIGURABLE,APPLICATION_DROPDOWN_MULTISELECT,RESOURCE_CONSTRAINT_SCOPE_PIPELINE_ENABLED,NG_TEMPLATE_GITX,ELK_HEALTH_SOURCE,CVNG_METRIC_THRESHOLD,SRM_HOST_SAMPLING_ENABLE,SRM_ENABLE_HEALTHSOURCE_CLOUDWATCH_METRICS,CDS_SHELL_VARIABLES_EXPORT,CDS_TAS_NG,CD_TRIGGER_V2,CDS_NG_TRIGGER_MULTI_ARTIFACTS,ACCOUNT_BASIC_ROLE,CD_NG_DOCKER_ARTIFACT_DIGEST,CDS_SERVICE_OVERRIDES_2_0,NG_SVC_ENV_REDESIGN,NG_EXECUTION_INPUT,CDS_SERVICENOW_REFRESH_TOKEN_AUTH,SERVICE_DASHBOARD_V2,CDS_OrgAccountLevelServiceEnvEnvGroup,CDC_SERVICE_DASHBOARD_REVAMP_NG,PL_FORCE_DELETE_CONNECTOR_SECRET,POST_PROD_ROLLBACK,PIE_STATIC_YAML_SCHEMA,SPG_SIDENAV_COLLAPSE,HOSTED_BUILDS,CIE_HOSTED_VMS,ENABLE_K8_BUILDS,CI_OUTPUT_VARIABLES_AS_ENV,CDS_GITHUB_APP_AUTHENTICATION,CDS_REMOVE_TIME_BUCKET_GAPFILL_QUERY,CDS_CONTAINER_STEP_GROUP,CDS_SUPPORT_EXPRESSION_REMOTE_TERRAFORM_VAR_FILES_NG,CDS_AWS_CDK,DISABLE_WINRM_COMMAND_ENCODING_NG,SKIP_ADDING_TRACK_LABEL_SELECTOR_IN_ROLLING,ENABLE_CERT_VALIDATION,CDS_GET_SERVICENOW_STANDARD_TEMPLATE,CDS_ENABLE_NEW_PARAMETER_FIELD_PROCESSOR,SRM_MICRO_FRONTEND,CVNG_TEMPLATE_MONITORED_SERVICE,PL_DISCOVERY_ENABLE,PIE_GIT_BI_DIRECTIONAL_SYNC,CDS_METHOD_INVOCATION_NEW_FLOW_EXPRESSION_ENGINE,CD_NG_DYNAMIC_PROVISIONING_ENV_V2,CDS_HELM_MULTIPLE_MANIFEST_SUPPORT_NG,CDS_SERVERLESS_V2,CDP_AWS_SAM,CDS_IMPROVED_HELM_DEPLOYMENT_TRACKING,CDS_K8S_APPLY_MANIFEST_WITHOUT_SERVICE_NG,CDS_HELM_FETCH_CHART_METADATA_NG,CDS_K8S_HELM_INSTANCE_SYNC_V2_NG,USE_K8S_API_FOR_STEADY_STATE_CHECK,CVNG_TEMPLATE_VERIFY_STEP,CDS_HIDE_AIDA_RCA,OPA_PIPELINE_GOVERNANCE,OPA_GIT_GOVERNANCE,CDS_AUTO_APPROVAL,CDS_NG_TRIGGER_SELECTIVE_STAGE_EXECUTION,CI_INDIRECT_LOG_UPLOAD,CIE_ENABLE_RUNTEST_V2,CVNG_ENABLED,NG_LICENSES_ENABLED,VIEW_USAGE_ENABLED,ENABLE_DEFAULT_NG_EXPERIENCE_FOR_ONPREM,NEXT_GEN_ENABLED,NEW_LEFT_NAVBAR_SETTINGS,SPG_SIDENAV_COLLAPSE,PL_ENABLE_JIT_USER_PROVISION,CDS_NAV_2_0,PL_CUSTOM_BANNERS,PL_HIDE_ACCOUNT_EDITION_UI
  FILE_LOGGING_ENABLED: "true"
  FIPS_ENABLED: "false"
  GENERAL_CONSUMER_COUNT: "2"
  GITOPS_SERVICE_CLIENT_BASEURL: http://gitops:7908/api/v1/
  GRPC_MAX_CONNECTION_AGE: "30"
  HARNESS_ENABLE_NG_AUTH_UI_PLACEHOLDER: "true"
  HAZELCAST_NAMESPACE: harness
  HAZELCAST_SERVICE: harness-manager
  HZ_CLUSTER_NAME: harness-manager
  IMMUTABLE_DELEGATE_DOCKER_IMAGE: docker.io/harness/delegate:25.08.86600
  IMMUTABLE_DELEGATE_ENABLED: "true"
  INTERNAL_DELEGATE_SERVICE_AUTHORITY: harness-manager:9879
  INTERNAL_DELEGATE_SERVICE_TARGET: harness-manager:9879
  ITERATOR_CONFIG_PATH: /opt/harness/config
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  JAVA_ADVANCED_FLAGS: -XX:+ExitOnOutOfMemoryError
  LOCK_NOTIFY_RESPONSE_CLEANUP: "true"
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_STREAMING_SERVICE_BASEURL: http://log-service.harness.svc.cluster.local:8079/
  LOG_STREAMING_SERVICE_EXTERNAL_URL: https://harness.mcintosh.farm/log-service/
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  LOGGING_LEVEL: INFO
  MALLOC_ARENA_MAX: "4"
  MEMORY: "2048"
  MONGO_MAX_DOCUMENT_LIMIT: "30000"
  MONGO_MAX_OPERATION_TIME_IN_MILLIS: "60000"
  NG_MANAGER_AVAILABLE: "true"
  NG_MANAGER_BASE_URL: http://ng-manager:7090/
  NG_MANAGER_READ_TIMEOUT: "15"
  NOTIFICATION_BASE_URL: http://platform-service:9005/api/
  NOTIFY_CONSUMER_COUNT: "2"
  PERPETUAL_TASK_ASSIGNMENT_ITERATOR_THREAD_COUNT: "4"
  PERPETUAL_TASK_REBALANCE_ITERATOR_THREAD_COUNT: "2"
  PIPELINE_CLIENT_BASEURL: http://pipeline-service:12001/api/
  PLATFORM_READ_TIMEOUT: "10"
  PROMETHEUS_COLLECTOR_PORT: "8889"
  PUBLISH_DELEGATE_TASK_METRICS: "false"
  REDIS_CONNECTION_MINIMUM_IDLE_SIZE: "32"
  REDIS_MASTER_NAME: harness-redis
  REDIS_NETTY_THREADS: "32"
  REDIS_SENTINEL: "true"
  REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  REDIS_SUBSCRIPTION_CONNECTION_POOL_SIZE: "100"
  REDIS_SUBSCRIPTIONS_PER_CONNECTION: "10"
  REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  REDISSON_PING_CONNECTION_INTERVAL_IN_MILLIS: "0"
  SEARCH_ENABLED: "false"
  SERVER_PORT: "9090"
  SERVICE_ACC: /opt/harness/svc/service_acc.json
  STACK_DRIVER_LOGGING_ENABLED: "false"
  TIMESCALEDB_HEALTH_CHECK_NEEDED: "false"
  UI_SERVER_URL: https://harness.mcintosh.farm
  UPGRADER_DOCKER_IMAGE: docker.io/harness/upgrader:latest
  USE_GLOBAL_KMS_AS_BASE_ALGO: "false"
  USE_WORKLOAD_IDENTITY: "true"
  VERSION: 1.0.80209
  WATCHER_METADATA_URL: https://harness.mcintosh.farm/storage/wingswatchers/watcherprod.txt
kind: ConfigMap
metadata:
  name: harness-manager-config
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control:9006/api/
  ACCESS_CONTROL_ENABLED: "true"
  ADDON_IMAGE: harness/ci-addon:1.16.73
  ADDON_IMAGE_ROOTLESS: harness/ci-addon:rootless-1.16.73
  API_URL: https://harness.mcintosh.farm/ng/#/
  ASYNC_DELEGATE_RESPONSE_THREAD_COUNT: "15"
  CACHE_BACKEND: REDIS
  CACHE_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  CACHE_CONFIG_USE_SENTINEL: "true"
  CACHE_NAMESPACE: ""
  CACHE_PROXY_IMAGE: harness/harness-cache-server:1.6.0
  CACHE_SERVICE_ENDPOINT: https://harness.mcintosh.farm/cache-service/
  CF_CLIENT_CONFIG_URL: http://ff-proxy-v2-clusterip
  CF_CLIENT_EVENT_URL: http://ff-proxy-v2-clusterip
  DEFAULT_CPU_LIMIT: "500"
  DEFAULT_INTERNAL_IMAGE_CONNECTOR: account.harnessImage
  DEFAULT_MEMORY_LIMIT: "1000"
  DEPLOY_MODE: KUBERNETES_ONPREM
  DISABLE_NEW_RELIC: "true"
  DISTRIBUTED_LOCK_IMPLEMENTATION: REDIS
  ENABLE_APPDYNAMICS: "false"
  ENABLE_AUTH: "true"
  ENABLE_DASHBOARD_TIMESCALE: "true"
  ENABLE_PROMETHEUS_COLLECTOR: "true"
  ENABLE_QUEUE: "false"
  ENFORCEMENT_CHECK_ENABLED: "true"
  EVENTS_FRAMEWORK_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_USE_SENTINEL: "true"
  FEATURE_FLAG_SYSTEM: LOCAL
  GIT_CLONE_IMAGE: harness/drone-git:1.6.6-rootless
  GITNESS_INTERNAL_URL: http://code-api.harness.svc.cluster.local:80/
  GOOGLE_APPLICATION_CREDENTIALS: /opt/harness/svc/cloud_stackdriver.json
  GRPC_SERVER_PORT: "9979"
  HARNESS_CODE_GIT_URL: https://harness.mcintosh.farm/code/git
  HOSTED_VM_SPLIT_LINUX_AMD64_POOL: "false"
  HOSTED_VM_SPLIT_LINUX_ARM64_POOL: "false"
  HOSTED_VM_SPLIT_WINDOWS_AMD64_POOL: "false"
  HSQS_BASE_URL: http://queue-service.harness.svc.cluster.local:9091/
  IACM_EXTERNAL_SERVICE_ENDPOINT: https://harness.mcintosh.farm/iacm/
  IACM_INFRACOST_API_ENDPOINT: https://harness.mcintosh.farm/iac-pricing/
  IACM_OPEN_TOFU_IMAGE: plugins/harness_terraform:latest
  IACM_OPEN_TOFU_VM_IMAGE: plugins/harness_terraform_vm:latest
  IACM_SERVICE_ENDPOINT: http://iac-server.harness.svc.cluster.local:8080/
  IACM_TERRAFORM_IMAGE: plugins/harness_terraform:latest
  IACM_TERRAFORM_VM_IMAGE: plugins/harness_terraform_vm:latest
  INTERNAL_MANAGER_AUTHORITY: harness-manager:9879
  INTERNAL_MANAGER_TARGET: harness-manager:9879
  INTERNAL_PMS_AUTHORITY: pipeline-service:12011
  INTERNAL_PMS_TARGET: pipeline-service:12011
  IS_LOCAL: "false"
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  LE_IMAGE: harness/ci-lite-engine:1.16.73
  LE_IMAGE_ROOTLESS: harness/ci-lite-engine:rootless-1.16.73
  LOCK_CONFIG_ENV_NAMESPACE: ""
  LOCK_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_REDIS_USERNAME: ""
  LOCK_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  LOCK_CONFIG_USE_SENTINEL: "true"
  LOG_SERVICE_ENDPOINT: https://harness.mcintosh.farm/log-service/
  MANAGER_AUTHORITY: harness-manager:9879
  MANAGER_TARGET: harness-manager:9879
  MANAGER_URL: http://harness-manager.harness.svc.cluster.local:9090/api/
  MEMORY: "2500"
  MOCK_ACCESS_CONTROL_SERVICE: "false"
  MONGO_INDEX_MANAGER_MODE: AUTO
  NG_MANAGER_URL: http://ng-manager.harness.svc.cluster.local:7090/
  OPA_SERVER_BASEURL: http://policy-mgmt.harness.svc.cluster.local:3000/
  PIE_STREAM_PER_SERVICE: "false"
  PIPELINE_SDK_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_RESPONSE_SPAWN_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_STEP_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SERVICE_URL: http://pipeline-service.harness.svc.cluster.local:12001/api/
  PMS_AUTHORITY: pipeline-service:12011
  PMS_SDK_ORCHESTRATION_EVENT_POOL_CORE_SIZE: "15"
  PMS_TARGET: pipeline-service:12011
  S3_UPLOAD_IMAGE: plugins/s3:1.2.7
  SCM_SERVICE_URI: scm-service:8091
  SECURITY_IMAGE: harness/sto-plugin:latest
  SHOULD_CONFIGURE_WITH_PMS: "true"
  STACK_DRIVER_LOGGING_ENABLED: "false"
  STO_SERVICE_ENDPOINT: https://harness.mcintosh.farm/sto/
  STO_SERVICE_INTERNAL_ENDPOINT: http://sto-core.harness.svc.cluster.local:4000/
  TI_SERVICE_ENDPOINT: https://harness.mcintosh.farm/ti-service/
  USE_DMS: "false"
  USE_REDIS_FOR_SDK_RESPONSE_EVENTS: "true"
  VERSION: 1.100.1
kind: ConfigMap
metadata:
  labels: null
  name: iacm-manager
  namespace: harness
---
apiVersion: v1
data:
  iterator_config.json: |
    [
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "AccessRequestHandler",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 15,
        "threadPoolIntervalInSeconds": 5,
        "threadPoolSize": 5,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "AccountInactivityCheck",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 1800,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 5,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "AccountRingInformation",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 7200,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 1,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "AlertReconciliation",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 600,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "ApprovalPolling",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 60,
        "threadPoolIntervalInSeconds": 10,
        "threadPoolSize": 20,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "ArtifactCleanup",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 7200,
        "threadPoolIntervalInSeconds": 300,
        "threadPoolSize": 5,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "ArtifactCollection",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 60,
        "threadPoolIntervalInSeconds": 10,
        "threadPoolSize": 25,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "BarrierInstanceMonitor",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 60,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "CeLicenceExpiryProcessor",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 86400,
        "threadPoolIntervalInSeconds": 86400,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "DelegateDisconnectDetector",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 60,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "DelegateExpiryAlert",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 86400,
        "threadPoolIntervalInSeconds": 86400,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "DelegateTaskFail",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 30,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "DelegateTaskFailOnDMS",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 30,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "DelegateTelemetryPublisherIteration",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 86400,
        "threadPoolIntervalInSeconds": 600,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": false,
        "iteratorMode": "PUMP",
        "name": "DeleteAccountIterator",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 18000,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": false,
        "iteratorMode": "PUMP",
        "name": "DeletedEntityIterator",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 43200,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": false,
        "iteratorMode": "LOOP",
        "name": "DeploymentFreezeActivities",
        "nextIterationMode": "THROTTLE",
        "targetIntervalInSeconds": 0,
        "threadPoolIntervalInSeconds": 0,
        "threadPoolSize": 3,
        "throttleIntervalInSeconds": 45
      },
      {
        "enabled": false,
        "iteratorMode": "LOOP",
        "name": "DeploymentFreezeDeactivation",
        "nextIterationMode": "THROTTLE",
        "targetIntervalInSeconds": 0,
        "threadPoolIntervalInSeconds": 0,
        "threadPoolSize": 3,
        "throttleIntervalInSeconds": 45
      },
      {
        "enabled": false,
        "iteratorMode": "PUMP",
        "name": "EncryptedDataLocalToGcpKmsMigrationHandler",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 72000,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 5,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "EntityAuditRecordProcessor",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 1800,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 6,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "EventDelivery",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 5,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 35,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "ExportExecutionsRequestCleanupHandler",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 2700,
        "threadPoolIntervalInSeconds": 3600,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "ExportExecutionsRequestHandler",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 1800,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "GCPBilling",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 3600,
        "threadPoolIntervalInSeconds": 1800,
        "threadPoolSize": 5,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "GitSyncEntityExpiryCheck",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 43200,
        "threadPoolIntervalInSeconds": 600,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "GitSyncPollingIterator",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 300,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "REDIS_BATCH",
        "maxRecordsInOneRound": 10000,
        "name": "HighPriorityPerpetualTaskAssignment",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 60,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 20,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "InstanceSync",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 600,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 20,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "LOOP",
        "name": "LdapGroupScheduled",
        "nextIterationMode": "THROTTLE",
        "targetIntervalInSeconds": 0,
        "threadPoolIntervalInSeconds": 0,
        "threadPoolSize": 8,
        "throttleIntervalInSeconds": 45
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "LicenseExpiryCheck",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 1800,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 5,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "REDIS_BATCH",
        "maxRecordsInOneRound": 10000,
        "name": "PerpetualTaskAssignment",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 300,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 20,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "ResourceConstraint-Backup",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 30,
        "threadPoolIntervalInSeconds": 60,
        "threadPoolSize": 20,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "ResourceLookupTagLinkSync",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 43200,
        "threadPoolIntervalInSeconds": 43200,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "RunnerTransactionsCleaner",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 30,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": false,
        "iteratorMode": "LOOP",
        "name": "ScheduledTrigger",
        "nextIterationMode": "THROTTLE",
        "targetIntervalInSeconds": 0,
        "threadPoolIntervalInSeconds": 0,
        "threadPoolSize": 8,
        "throttleIntervalInSeconds": 45
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "SegmentGroupEventJob",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 86400,
        "threadPoolIntervalInSeconds": 1800,
        "threadPoolSize": 5,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "SettingAttributeValidateConnectivity",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 10800,
        "threadPoolIntervalInSeconds": 600,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "SettingAttributesSecretsMigrationHandler",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 1800,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": false,
        "iteratorMode": "LOOP",
        "name": "TimeoutEngine",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 10,
        "threadPoolIntervalInSeconds": 10,
        "threadPoolSize": 5,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "UsageMetricsHandler",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 86400,
        "threadPoolIntervalInSeconds": 30,
        "threadPoolSize": 4,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "VaultSecretManagerRenewalHandler",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 31,
        "threadPoolIntervalInSeconds": 5,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      },
      {
        "enabled": true,
        "iteratorMode": "PUMP",
        "name": "WorkflowExecutionMonitor",
        "nextIterationMode": "TARGET",
        "targetIntervalInSeconds": 60,
        "threadPoolIntervalInSeconds": 10,
        "threadPoolSize": 10,
        "throttleIntervalInSeconds": 0
      }
    ]
kind: ConfigMap
metadata:
  name: iterator-config
  namespace: harness
---
apiVersion: v1
data:
  https_port: "10800"
  learning_env: on_prem
  server_url: http://cv-nextgen:6060
  taskTypes: CANARY_LOG_ANALYSIS,TEST_LOG_ANALYSIS,TIME_SERIES_CANARY,TIME_SERIES_LOAD_TEST,BEFORE_AFTER_DEPLOYMENT_TIME_SERIES,CANARY_DEPLOYMENT_TIME_SERIES,LOG_ANALYSIS,LOG_FEEDBACK,CV_LOG_CLUSTER
kind: ConfigMap
metadata:
  name: le-nextgen
  namespace: harness
---
apiVersion: v1
data:
  https_port: "10800"
  learning_env: on_prem
  server_url: http://cv-nextgen:6060
  taskTypes: SERVICE_GUARD_TIME_SERIES,SERVICE_GUARD_LOG_ANALYSIS,LOG_CLUSTER,SERVICE_GUARD_FEEDBACK_ANALYSIS
kind: ConfigMap
metadata:
  name: le-nextgen-srm
  namespace: harness
---
apiVersion: v1
data:
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  ENV: SMP
  FIPS_ENABLED: "false"
  LOG_SERVICE_DISABLE_AUTH: "true"
  LOG_SERVICE_ENDPOINT: https://harness.mcintosh.farm/log-service/
  LOG_SERVICE_GCS_BUCKET: ""
  LOG_SERVICE_GCS_ENDPOINT: ""
  LOG_SERVICE_GCS_PATH_STYLE: "true"
  LOG_SERVICE_GCS_REGION: ""
  LOG_SERVICE_GENAI_ENDPOINT: http://genai-service:8000
  LOG_SERVICE_MANAGER_URL: http://harness-manager:9090/api
  LOG_SERVICE_MINIO_ENABLED: "true"
  LOG_SERVICE_PIPELINE_BASE_URL: http://pipeline-service:12001/api
  LOG_SERVICE_PLATFORM_ACCESS_CONTROL_BASE_URL: http://access-control:9006/api
  LOG_SERVICE_PLATFORM_BASE_URL: http://ng-manager:7090
  LOG_SERVICE_REDIS_DISABLE_EXPIRY_WATCHER: "false"
  LOG_SERVICE_REDIS_ENDPOINT: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  LOG_SERVICE_REDIS_MASTER_NAME: harness-redis
  LOG_SERVICE_REDIS_SENTINEL_ADDRS: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  LOG_SERVICE_REDIS_USE_SENTINEL: "true"
  LOG_SERVICE_S3_BUCKET: logs
  LOG_SERVICE_S3_ENDPOINT: http://minio.harness.svc.cluster.local:9000
  LOG_SERVICE_S3_PATH_STYLE: "true"
  LOG_SERVICE_S3_REGION: us-east-1
  LOG_SERVICE_STREAM_USE_PROTOBUF: "true"
  LOG_SERVICE_UPLOAD_USING_LINK_CD_ENABLED: "true"
  LOG_SERVICE_UPLOAD_USING_LINK_ENABLED: "true"
  PROMETHEUS_COLLECTOR_PORT: "8889"
kind: ConfigMap
metadata:
  name: log-service
  namespace: harness
---
apiVersion: v1
data:
  ping-mongodb.sh: |
    #!/bin/bash
    mongosh  $TLS_OPTIONS --port $MONGODB_PORT_NUMBER --eval "db.adminCommand('ping')"
  readiness-probe.sh: |
    #!/bin/bash
    # Run the proper check depending on the version
    [[ $(mongod -version | grep "db version") =~ ([0-9]+\.[0-9]+\.[0-9]+) ]] && VERSION=${BASH_REMATCH[1]}
    . /opt/bitnami/scripts/libversion.sh
    VERSION_MAJOR="$(get_sematic_version "$VERSION" 1)"
    VERSION_MINOR="$(get_sematic_version "$VERSION" 2)"
    VERSION_PATCH="$(get_sematic_version "$VERSION" 3)"
    if [[ ( "$VERSION_MAJOR" -ge 5 ) || ( "$VERSION_MAJOR" -ge 4 && "$VERSION_MINOR" -ge 4 && "$VERSION_PATCH" -ge 2 ) ]]; then
        mongosh $TLS_OPTIONS --port $MONGODB_PORT_NUMBER --eval 'db.hello().isWritablePrimary || db.hello().secondary' | grep -q 'true$'
    else
        mongosh  $TLS_OPTIONS --port $MONGODB_PORT_NUMBER --eval 'db.isMaster().ismaster || db.isMaster().secondary' | grep -q 'true$'
    fi
  startup-probe.sh: |
    #!/bin/bash
    mongosh  $TLS_OPTIONS --port $MONGODB_PORT_NUMBER --eval 'db.hello().isWritablePrimary || db.hello().secondary' | grep -q 'true$'
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: mongodb
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/version: 6.0.1
    helm.sh/chart: mongodb-13.1.2
  name: mongodb-replicaset-chart-common-scripts
  namespace: harness
---
apiVersion: v1
data:
  setup-hidden.sh: |-
    #!/bin/bash

    . /opt/bitnami/scripts/mongodb-env.sh

    echo "Advertised Hostname: $MONGODB_ADVERTISED_HOSTNAME"
    echo "Advertised Port: $MONGODB_ADVERTISED_PORT_NUMBER"
    echo "Configuring node as a hidden node"
    export MONGODB_REPLICA_SET_MODE="hidden"
    export MONGODB_INITIAL_PRIMARY_ROOT_USER="$MONGODB_ROOT_USER"
    export MONGODB_INITIAL_PRIMARY_ROOT_PASSWORD="$MONGODB_ROOT_PASSWORD"
    export MONGODB_INITIAL_PRIMARY_PORT_NUMBER="$MONGODB_PORT_NUMBER"
    export MONGODB_ROOT_PASSWORD=""
    export MONGODB_EXTRA_USERNAMES=""
    export MONGODB_EXTRA_DATABASES=""
    export MONGODB_EXTRA_PASSWORDS=""
    export MONGODB_ROOT_PASSWORD_FILE=""
    export MONGODB_EXTRA_USERNAMES_FILE=""
    export MONGODB_EXTRA_DATABASES_FILE=""
    export MONGODB_EXTRA_PASSWORDS_FILE=""
    exec /opt/bitnami/scripts/mongodb/entrypoint.sh /opt/bitnami/scripts/mongodb/run.sh
  setup.sh: |-
    #!/bin/bash

    . /opt/bitnami/scripts/mongodb-env.sh
    . /opt/bitnami/scripts/libfs.sh
    . /opt/bitnami/scripts/liblog.sh
    . /opt/bitnami/scripts/libvalidations.sh

    if is_empty_value "$MONGODB_ADVERTISED_PORT_NUMBER"; then
      export MONGODB_ADVERTISED_PORT_NUMBER="$MONGODB_PORT_NUMBER"
    fi

    info "Advertised Hostname: $MONGODB_ADVERTISED_HOSTNAME"
    info "Advertised Port: $MONGODB_ADVERTISED_PORT_NUMBER"

    # Check for existing replica set in case there is no data in the PVC
    # This is for cases where the PVC is lost or for MongoDB caches without
    # persistence
    current_primary=""
    if is_dir_empty "${MONGODB_DATA_DIR}/db"; then
      info "Data dir empty, checking if the replica set already exists"
      current_primary=$(mongosh admin --host "mongodb-replicaset-chart-0.mongodb-replicaset-chart-headless.harness.svc.cluster.local:27017,mongodb-replicaset-chart-1.mongodb-replicaset-chart-headless.harness.svc.cluster.local:27017,mongodb-replicaset-chart-2.mongodb-replicaset-chart-headless.harness.svc.cluster.local:27017" --authenticationDatabase admin -u root -p $MONGODB_ROOT_PASSWORD --eval 'db.runCommand("ismaster")' | awk -F\' '/primary/ {print $2}')

      if ! is_empty_value "$current_primary"; then
        info "Detected existing primary: ${current_primary}"
      fi
    fi

    if ! is_empty_value "$current_primary" && [[ "$MONGODB_ADVERTISED_HOSTNAME:$MONGODB_ADVERTISED_PORT_NUMBER" == "$current_primary" ]]; then
        info "Advertised name matches current primary, configuring node as a primary"
        export MONGODB_REPLICA_SET_MODE="primary"
    elif ! is_empty_value "$current_primary" && [[ "$MONGODB_ADVERTISED_HOSTNAME:$MONGODB_ADVERTISED_PORT_NUMBER" != "$current_primary" ]]; then
        info "Current primary is different from this node. Configuring the node as replica of ${current_primary}"
        export MONGODB_REPLICA_SET_MODE="secondary"
        export MONGODB_INITIAL_PRIMARY_HOST="${current_primary%:*}"
        export MONGODB_INITIAL_PRIMARY_PORT_NUMBER="${current_primary#*:}"
        export MONGODB_SET_SECONDARY_OK="yes"
    elif [[ "$MY_POD_NAME" = "mongodb-replicaset-chart-0" ]]; then
        info "Pod name matches initial primary pod name, configuring node as a primary"
        export MONGODB_REPLICA_SET_MODE="primary"
    else
        info "Pod name doesn't match initial primary pod name, configuring node as a secondary"
        export MONGODB_REPLICA_SET_MODE="secondary"
        export MONGODB_INITIAL_PRIMARY_PORT_NUMBER="$MONGODB_PORT_NUMBER"
    fi

    if [[ "$MONGODB_REPLICA_SET_MODE" == "secondary" ]]; then
        export MONGODB_INITIAL_PRIMARY_ROOT_USER="$MONGODB_ROOT_USER"
        export MONGODB_INITIAL_PRIMARY_ROOT_PASSWORD="$MONGODB_ROOT_PASSWORD"
        export MONGODB_ROOT_PASSWORD=""
        export MONGODB_EXTRA_USERNAMES=""
        export MONGODB_EXTRA_DATABASES=""
        export MONGODB_EXTRA_PASSWORDS=""
        export MONGODB_ROOT_PASSWORD_FILE=""
        export MONGODB_EXTRA_USERNAMES_FILE=""
        export MONGODB_EXTRA_DATABASES_FILE=""
        export MONGODB_EXTRA_PASSWORDS_FILE=""
    fi

    exec /opt/bitnami/scripts/mongodb/entrypoint.sh /opt/bitnami/scripts/mongodb/run.sh
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: mongodb
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/version: 6.0.1
    helm.sh/chart: mongodb-13.1.2
  name: mongodb-replicaset-chart-scripts
  namespace: harness
---
apiVersion: v1
data:
  API_URL: /gateway
  APPSEC_SERVER_URL: https://appsec.harness.io
  ATA_API_SERVER_URL: https://app.relicx.ai/api/
  ATA_ASSETS_PATH: https://app.relicx.ai/micro-frontend
  CSP_BUGSNAG_ENABLED: "false"
  CSP_CANNY_ENABLED: "false"
  CSP_GOOGLE_ENABLED: "false"
  CSP_INTERCOM_ENABLED: "false"
  CSP_MIXPANEL_ENABLED: "false"
  CSP_NEWRELIC_ENABLED: "false"
  CSP_REFINER_ENABLED: "false"
  CSP_RELICX_ENABLED: "false"
  CSP_SEGMENT_ENABLED: "false"
  CSP_SPLIT_ENABLED: "false"
  CSP_STRIPE_ENABLED: "false"
  CSP_ZENDESK_ENABLED: "false"
  DEPLOYMENT_TYPE: ON_PREM
  ENV: SMP
  EXPECTED_HOSTNAME: app.harness.io
  FME_SERVER_URL: https://app.split.io
  HARNESS_CLUSTER_URL: ""
  HARNESS_ENABLE_CSP_HEADERS: "false"
  HARNESS_ENABLE_NG_AUTH_UI_PLACEHOLDER: "true"
  INCLUDE_ALL_LICENSE_LIFECYCLE_STAGES: "false"
  SSCA_PATH_PREFIX: /ssca-manager
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: next-gen-ui
    app.kubernetes.io/version: 0.353.10
    helm.sh/chart: next-gen-ui-1.93.7
  name: next-gen-ui
  namespace: harness
---
apiVersion: v1
data:
  API_URL: /gateway
  DEPLOYMENT_TYPE: ON_PREM
  ENV: SMP
  EXPECTED_HOSTNAME: app.harness.io
  OAUTH_SIGNUP_ENABLED: "true"
kind: ConfigMap
metadata:
  name: ng-auth-ui
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control:9006/api/
  BIG_QUERY_DATA_SET: mart_product
  BIG_QUERY_FEATURE_DEFINITION_TABLE: dim_feature_definitions
  BIG_QUERY_FEATURE_USAGE_TABLE: fct_feature_usage
  BIG_QUERY_GCP_PROJECT_ID: segment-warehouse-236622
  CD_CLIENT_BASEURL: http://pipeline-service:12001/api/
  DEPLOY_MODE: KUBERNETES_ONPREM
  FILE_LOGGING_ENABLED: "true"
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  MANAGER_CLIENT_BASEURL: http://harness-manager:9090/api/
  NG_MANAGER_CLIENT_BASEURL: http://ng-manager:7090/
  REDISSON_PING_CONNECTION_INTERVAL_IN_MILLIS: "0"
  STACK_DRIVER_LOGGING_ENABLED: "false"
kind: ConfigMap
metadata:
  labels: null
  name: ng-dashboard-aggregator
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control.harness.svc.cluster.local:9006/api/
  ACCESS_CONTROL_ENABLED: "true"
  ACCESS_CONTROL_READ_TIMEOUT: "10"
  AIMLOPS_SERVICE_CLIENT_BASEURL: http://ai-agent-ops-service:9550/
  ALLOWED_ORIGINS: https://harness.mcintosh.farm
  AUDIT_CLIENT_BASEURL: http://platform-service.harness.svc.cluster.local:9005/api/
  AUDIT_ENABLED: "true"
  AUTH_ENABLED: "true"
  AWS_SERVICE_ENDPOINT_URLS_CLOUDWATCH_ENDPOINT_URL: https://monitoring.us-east-2.amazonaws.com
  AWS_SERVICE_ENDPOINT_URLS_ECS_ENDPOINT_URL: https://ecs.us-east-2.amazonaws.com
  AWS_SERVICE_ENDPOINT_URLS_ENABLED: "false"
  AWS_SERVICE_ENDPOINT_URLS_ENDPOINT_REGION: us-east-2
  AWS_SERVICE_ENDPOINT_URLS_STS_ENDPOINT_URL: https://sts.us-east-2.amazonaws.com
  BITBUCKET_SERVER_OAUTH_CALLBACK_URL: https://harness.mcintosh.farm/gateway/api/secret/oauth2/bitbucket_server
  CACHE_BACKEND: REDIS
  CE_NG_CLIENT_BASEURL: http://nextgen-ce.harness.svc.cluster.local:6340/ccm/api/
  CE_SETUP_CONFIG_GCP_PROJECT_ID: placeHolderGcpProjectId
  CENG_CLIENT_BASEURL: http://nextgen-ce.harness.svc.cluster.local:6340/ccm/api/
  CGI_TASK_CONFIG_PATH: /opt/harness/cgi-config
  CHAOS_SERVICE_BASE_URL: http://chaos-web-service.harness.svc.cluster.local:8184/
  CI_MANAGER_SERVICE_CLIENT_BASEURL: http://ci-manager:7090/
  CURRENT_GEN_UI_URL: https://harness.mcintosh.farm/#/
  CVNG_SERVICE_CLIENT_BASEURL: http://cv-nextgen:6060/cv/api/
  DBOPS_SERVICE_CLIENT_BASEURL: http://db-devops-service:5001/
  DEPLOY_MODE: KUBERNETES_ONPREM
  DEVOPS_ESSENTIAL_CONFIG_PATH: /opt/harness/devops
  DISTRIBUTED_LOCK_IMPLEMENTATION: REDIS
  ENABLE_DASHBOARD_TIMESCALE: "true"
  ENABLE_DEFAULT_RESOURCE_GROUP_CREATION: "true"
  ENABLE_DEFAULT_USER_GROUPS_CREATION_JOB: "true"
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  ENFORCEMENT_CHECK_ENABLED: "true"
  ENV: SMP
  EVENTS_FRAMEWORK_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_USE_SENTINEL: "true"
  FILE_LOGGING_ENABLED: "true"
  FIPS_ENABLED: "false"
  GIT_SERVICE_CACHING_MAX_CACHE_DURATION: "2592000000"
  GIT_SERVICE_CACHING_VALID_CACHE_DURATION: "7200000"
  GITHUB_ENTERPRISE_OAUTH_CALLBACK_URL: https://harness.mcintosh.farm/gateway/api/secret/oauth2/github_enterprise
  GITLAB_ON_PREM_OAUTH_CALLBACK_URL: https://harness.mcintosh.farm/gateway/api/secret/oauth2/gitlab_on_prem
  GITOPS_RESOURCE_CLIENT_CONNECT_TIMEOUT_SECONDS: "15"
  GITOPS_RESOURCE_CLIENT_READ_TIMEOUT_SECONDS: "15"
  GITOPS_SERVICE_CLIENT_BASEURL: http://gitops:7908/api/v1/
  GRPC_MAX_CONNECTION_AGE: "30"
  GRPC_SERVER_PORT: "9979"
  HARNESS_ARTIFACT_REGISTRY_SERVICE_URL: http://registry-api.harness.svc.cluster.local:80
  HARNESS_CODE_EXTERNAL_API_URL: https://harness.mcintosh.farm/gateway/code/
  HARNESS_CODE_GIT_URL: https://harness.mcintosh.farm/code/git
  HARNESS_ENABLE_NG_AUTH_UI_PLACEHOLDER: "true"
  HARNESS_NG_MANAGER_INTERNAL_URL: http://ng-manager.harness.svc.cluster.local:7090
  HARNESS_SCM_API_INTERNAL_URL: http://code-api.harness.svc.cluster.local:80
  HSQS_BASE_URL: http://queue-service:9091/
  IACM_SERVICE_BASE_URL: http://iac-server.harness.svc.cluster.local:8080/api/
  IDP_SERVICE_CLIENT_BASE_URL: http://idp-service:12003/
  INSTANCE_SYNC_PERPETUAL_TASK_INTERVAL_SECONDS: "600"
  INSTANCE_SYNC_PERPETUAL_TASK_TIMEOUT_SECONDS: "600"
  INTERNAL_MANAGER_AUTHORITY: dns:///harness-manager-headless:9879
  INTERNAL_MANAGER_TARGET: dns:///harness-manager-headless:9879
  INTERNAL_NG_MANAGER_AUTHORITY: dns:///ng-manager-headless:13002
  INTERNAL_NG_MANAGER_TARGET: dns:///ng-manager-headless:13002
  INTERNAL_PMS_AUTHORITY: dns:///pipeline-service-headless:12011
  INTERNAL_PMS_GITSYNC_AUTHORITY: dns:///pipeline-service-headless:14002
  INTERNAL_PMS_GITSYNC_TARGET: dns:///pipeline-service-headless:14002
  INTERNAL_PMS_TARGET: dns:///pipeline-service-headless:12011
  INTERNAL_TEMPLATE_GITSYNC_AUTHORITY: template-service:16002
  INTERNAL_TEMPLATE_GITSYNC_TARGET: template-service:16002
  IR_DCT_ENABLED: "true"
  IR_DCT_INITIAL_DELAY_SECONDS: "0"
  IR_DCT_LIMIT_PER_API_CALL: "25"
  IR_DCT_MAX_COUNT_PER_ITERATION: "100"
  IR_DCT_SCHEDULER_PERIOD_SECONDS: "30"
  IR_DCT_SLEEP_MILLI_SECONDS: "5000"
  IR_ENABLE_DCT: "true"
  IRO_MANAGER_SERVICE_BASE_URL: http://iro-manager.harness.svc.cluster.local:8080/
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  JAVA_ADVANCED_FLAGS: -XX:+ExitOnOutOfMemoryError
  LOCK_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  LOCK_CONFIG_USE_SENTINEL: "true"
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_STREAMING_SERVICE_BASEURL: http://log-service.harness.svc.cluster.local:8079/
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  LOGGING_LEVEL: INFO
  MALLOC_ARENA_MAX: "4"
  MANAGER_AUTHORITY: harness-manager:9879
  MANAGER_CLIENT_BASEURL: http://harness-manager.harness.svc.cluster.local:9090/api/
  MANAGER_TARGET: harness-manager:9879
  MANAGER_UI_URL: https://harness.mcintosh.farm
  MEMORY: 4096m
  MOCK_ACCESS_CONTROL_SERVICE: "false"
  MONGO_MAX_DOCUMENT_LIMIT: "10000"
  MONGO_MAX_OPERATION_TIME_IN_MILLIS: "40000"
  MONGO_TRANSACTIONS_ALLOWED: "false"
  MONITORING_MANAGER_SERVICE_BASE_URL: http://monitoring-manager.harness.svc.cluster.local:8092/
  NEXT_GEN_UI_URL: https://harness.mcintosh.farm/ng/#/
  NG_MANAGER_API_URL: http://ng-manager:7090/
  NG_MANAGER_AUTHORITY: ng-manager:13002
  NG_MANAGER_CLIENT_BASEURL: http://ng-manager:7090/
  NG_MANAGER_TARGET: ng-manager:13002
  NG_MANAGER_UI_URL: https://harness.mcintosh.farm/ng/#/
  NOTIFICATION_BASE_URL: http://platform-service:9005/api/
  OIDC_CONFIG_PATH: /opt/harness/config
  OPA_CONNECTIVITY_ENABLED: "true"
  OPA_SERVER_BASEURL: http://policy-mgmt.harness.svc.cluster.local:3000/
  PIPELINE_SDK_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_RESPONSE_SPAWN_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_STEP_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SERVICE_CLIENT_BASEURL: http://pipeline-service:12001/api/
  PLAN_CREATOR_SERVICE_EXECUTOR_POOL_CORE_SIZE: "150"
  PLAN_CREATOR_SERVICE_EXECUTOR_POOL_MAX_SIZE: "200"
  PLATFORM_READ_TIMEOUT: "10"
  PMS_AUTHORITY: pipeline-service:12011
  PMS_GITSYNC_AUTHORITY: pipeline-service:14002
  PMS_GITSYNC_TARGET: pipeline-service:14002
  PMS_TARGET: pipeline-service:12011
  PROMETHEUS_COLLECTOR_PORT: "8889"
  PROXY_ENABLED: "false"
  PROXY_HOST: localhost
  PROXY_PASSWORD: ""
  PROXY_PORT: "80"
  PROXY_PROTOCOL: http
  PROXY_USERNAME: ""
  REDISSON_PING_CONNECTION_INTERVAL_IN_MILLIS: "0"
  RELICX_BASE_URL: http://localhost:13000
  RESOURCE_GROUP_BASE_URL: http://platform-service.harness.svc.cluster.local:9005/api/
  SCM_SERVICE_URI: dns:///scm-service-headless:8091
  SERVICE_DISCOVERY_SERVICE_BASE_URL: http://service-discovery-manager:8080/
  SHOULD_CONFIGURE_WITH_PMS: "true"
  STACK_DRIVER_LOGGING_ENABLED: "false"
  STO_CORE_SERVICE_CLIENT_BASEURL: http://sto-core:4000/api/
  STRIPE_ACCOUNT: sandboxAccount
  STRIPE_DISABLE_METERS: "false"
  STRIPE_IDEMPOTENCY_KEY: sandboxIdempotencyKey
  STRIPE_INVOICE_EMAIL: test@harness.io
  TEMPLATE_GITSYNC_AUTHORITY: template-service:16002
  TEMPLATE_GITSYNC_TARGET: template-service:16002
  TEMPLATE_SERVICE_ENDPOINT: http://template-service:15002/api/
  USE_QUEUE_SERVICE_FOR_GITX_WEBHOOK: "true"
  USE_REDIS_FOR_SDK_RESPONSE_EVENTS: "true"
  WEBHOOK_BASE_URL: https://harness.mcintosh.farm/gateway/ng/api/
kind: ConfigMap
metadata:
  labels: null
  name: ng-manager
  namespace: harness
---
apiVersion: v1
data:
  oidc_config.json: |
    {
      "OPENID_CONFIGURATION" : {
        "issuer": "https://harness.mcintosh.farm/ng/api/oidc/account/{account_id}",
        "jwks_uri": "https://harness.mcintosh.farm/ng/api/oidc/account/{account_id}/.wellknown/jwks",
        "subject_types_supported":["public","pairwise"],
        "response_types_supported":["id_token"],
        "claims_supported":
        [
          "sub","aud","exp","iat","iss","account_id"
        ],
        "id_token_signing_alg_values_supported":["RS256"],
        "scopes_supported":["openid"]
      },
      "AWS": {
        "header": {
          "typ": "JWT",
          "alg": "RS256",
          "kid": "GENERATE_AT_RUNTIME"
        },
        "payload": {
          "sub": "{account_id}",
          "aud": "sts.amazonaws.com",
          "iss": "https://harness.mcintosh.farm/ng/api/oidc/account/{account_id}",
          "exp": 3600,
          "iat": 0,
          "account_id": "{account_id}"
        }
      },
      "CUSTOM": {
        "header": {
          "typ": "JWT",
          "alg": "RS256",
          "kid": "GENERATE_AT_RUNTIME"
        },
        "payload": {
          "sub": "{account_id}",
          "iss": "https://harness.mcintosh.farm/ng/api/oidc/account/{account_id}",
          "exp": 3600,
          "iat": 0,
          "account_id": "{account_id}"
        }
      },
      "GCP": {
        "header": {
          "typ": "JWT",
          "alg": "RS256",
          "kid": "GENERATE_AT_RUNTIME"
        },
        "payload": {
          "sub": "{account_id}",
          "aud": "https://iam.googleapis.com/projects/{gcp_project_id}/locations/global/workloadIdentityPools/{workload_pool_id}/providers/{provider_id}",
          "iss": "https://harness.mcintosh.farm/ng/api/oidc/account/{account_id}",
          "exp": 3600,
          "iat": 0,
          "account_id": "{account_id}"
        },
        "access_token_sts_endpoint": "https://sts.googleapis.com",
        "access_token_iam_sa_credentials_endpoint": "https://iamcredentials.googleapis.com/v1/projects/-/serviceAccounts/",
        "workload_access_token_config": {
          "audience": "//iam.googleapis.com/projects/{gcp_project_id}/locations/global/workloadIdentityPools/{workload_pool_id}/providers/{provider_id}",
          "grant_type": "urn:ietf:params:oauth:grant-type:token-exchange",
          "requested_token_type": "urn:ietf:params:oauth:token-type:access_token",
          "scope": "https://www.googleapis.com/auth/cloud-platform",
          "subject_token_type": "urn:ietf:params:oauth:token-type:id_token",
          "subject_token": "{SUBJECT_TOKEN_TYPE}",
          "options": {
            "userProject": "{gcp_project_id}"
          }
        }
      },
      "VAULT": {
        "header": {
          "typ": "JWT",
          "alg": "RS256",
          "kid": "GENERATE_AT_RUNTIME"
        },
        "payload": {
          "sub": "{account_id}",
          "aud": "{vault_jwt_auth_path}",
          "iss": "https://harness.mcintosh.farm/ng/api/oidc/account/{account_id}",
          "exp": 3600,
          "iat": 0,
          "account_id": "{account_id}"
        }
      },
      "AZURE": {
        "header": {
          "typ": "JWT",
          "alg": "RS256",
          "kid": "GENERATE_AT_RUNTIME"
        },
        "payload": {
          "sub": "{account_id}",
          "aud": "api://AzureADTokenExchange",
          "iss": "https://harness.mcintosh.farm/ng/api/oidc/account/{account_id}",
          "exp": 3600,
          "iat": 0,
          "account_id": "{account_id}"
        }
      }
    }
kind: ConfigMap
metadata:
  name: oidc-config-ng-manager
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control:9006/api/
  ACCESS_CONTROL_ENABLED: "true"
  AUDIT_SERVICE_BASE_URL: http://platform-service:9005/api/
  AUTH_ENABLED: "true"
  BASE_PATH_PREFIX: /gateway/pipeline/api
  CACHE_BACKEND: REDIS
  CACHE_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  CACHE_CONFIG_USE_SENTINEL: "true"
  CACHE_NAMESPACE: ""
  CI_MANAGER_BASE_URL: http://ci-manager:7090/
  CUSTOM_TRIGGER_BASEURL: https://harness.mcintosh.farm/gateway/pipeline/api/
  CV_MANAGER_BASE_URL: http://cv-nextgen:6060/cv/api/
  DEBEZIUM_CONSUMER_BATCH_SIZE: "100"
  DEBEZIUM_CONSUMER_THREADS: "2"
  DEBEZIUM_CONSUMER_TOPIC_NAME: DEBEZIUM_pms-harness.pms-harness.planExecutionsSummary
  DEPLOY_MODE: KUBERNETES_ONPREM
  DISABLE_CUSTOM_STAGE_IN_PIPELINE_SERVICE: "true"
  DISABLE_FREEZE_NOTIFY_TEMPLATE: "false"
  DISTRIBUTED_LOCK_IMPLEMENTATION: REDIS
  ELASTIC_SEARCH_URL: elastic-search:9200
  ENABLE_APPDYNAMICS: "false"
  ENABLE_AUDIT: "true"
  ENABLE_CONFLUENT_KAFKA_PRODUCER: "false"
  ENABLE_COVERAGE: "false"
  ENABLE_DASHBOARD_TIMESCALE: "true"
  ENABLE_ERROR_TRACKING: "false"
  ENABLE_GIT_SYNC: "true"
  ENABLE_MIGRATION_JOB_FOR_GCS: "false"
  ENABLE_OPENTELEMETRY: "false"
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  ENFORCEMENT_CHECK_ENABLED: "true"
  ENV: SMP
  EVENTS_FRAMEWORK_NETTY_THREADS: "64"
  EVENTS_FRAMEWORK_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_USE_SENTINEL: "true"
  FEATURE_FLAG_SYSTEM: LOCAL
  FF_SERVER_BASE_URL: http://ff-admin-server.harness.svc.cluster.local/api/1.0
  FILE_LOGGING_ENABLED: "true"
  FILTER_CREATOR_MERGE_SERVICE_EXECUTOR_POOL_CORE_SIZE: "5"
  FILTER_CREATOR_MERGE_SERVICE_EXECUTOR_POOL_MAX_SIZE: "5"
  FIPS_ENABLED: "false"
  GCS_MIGRATION_JOB_FREQUENCY_MINUTES: "60"
  GRPC_MAX_CONNECTION_AGE: "30"
  GRPC_SERVER_PORT: "12011"
  HARNESS_CODE_GIT_BASE_URL: https://harness.mcintosh.farm/code/git
  HARNESS_CODE_INTERNAL_API_URL: http://code-api:80/
  HSQS_BASE_URL: http://queue-service:9091/
  IACM_MANAGER_BASE_URL: http://iacm-manager:7090/
  INITIATE_NODE_EVENT_CONSUMER_THREAD_COUNT: "2"
  INTERNAL_CI_MANAGER_AUTHORITY: dns:///ci-manager-headless:9979
  INTERNAL_CI_MANAGER_TARGET: dns:///ci-manager-headless:9979
  INTERNAL_CVNG_MANAGER_AUTHORITY: cv-nextgen:9979
  INTERNAL_CVNG_MANAGER_TARGET: cv-nextgen:9979
  INTERNAL_IACM_MANAGER_AUTHORITY: iacm-manager:9979
  INTERNAL_IACM_MANAGER_TARGET: iacm-manager:9979
  INTERNAL_IDP_SERVICE_AUTHORITY: idp-service:9979
  INTERNAL_IDP_SERVICE_TARGET: idp-service:9979
  INTERNAL_MANAGER_AUTHORITY: dns:///harness-manager-headless:9879
  INTERNAL_MANAGER_TARGET: dns:///harness-manager-headless:9879
  INTERNAL_NG_MANAGER_AUTHORITY: dns:///ng-manager-headless:9979
  INTERNAL_NG_MANAGER_GITSYNC_AUTHORITY: dns:///ng-manager-headless:13002
  INTERNAL_NG_MANAGER_GITSYNC_TARGET: dns:///ng-manager-headless:13002
  INTERNAL_NG_MANAGER_TARGET: dns:///ng-manager-headless:9979
  INTERNAL_PIPELINE_SERVICE_AUTHORITY: dns:///pipeline-service-headless:15302
  INTERNAL_PIPELINE_SERVICE_TARGET: dns:///pipeline-service-headless:15302
  INTERNAL_STO_MANAGER_AUTHORITY: sto-manager:9979
  INTERNAL_STO_MANAGER_TARGET: sto-manager:9979
  INTERRUPT_MONITOR_ITERATOR_THREAD_POOL_SIZE: "2"
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  JAVA_ADVANCED_FLAGS: -XX:+ExitOnOutOfMemoryError
  KAFKA_CONFLUENT_BOOTSTRAP_SERVER_URLS: pkc-z1o60.europe-west1.gcp.confluent.cloud:9092
  KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: https://psrc-yow81o.europe-west1.gcp.confluent.cloud
  KAFKA_CONFLUENT_SECURITY_PROTOCOL: SASL_SSL
  KAFKA_CONFLUENT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
  LOCK_CONFIG_ENV_NAMESPACE: ""
  LOCK_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  LOCK_CONFIG_USE_SENTINEL: "true"
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_STREAMING_CONTAINER_STEP_BASE_URL: https://harness.mcintosh.farm/log-service/
  LOG_STREAMING_SERVICE_BASEURL: http://log-service.harness.svc.cluster.local:8079/
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  LOGGING_LEVEL: INFO
  MANAGER_BASE_URL: http://harness-manager:9090/api/
  MANAGER_CLIENT_BASEURL: http://harness-manager:9090/api/
  MEMORY: 4096m
  MIGRATION_JOB_BATCH_SIZE_FOR_GCS: "1000"
  MONGO_INDEX_MANAGER_MODE: AUTO
  MONGO_MESSAGE_BROKER_URI: ""
  MONGO_TRANSACTIONS_ALLOWED: "false"
  NG_MANAGER_BASE_URL: http://ng-manager:7090/
  NODE_START_EVENT_CONSUMER_THREAD_COUNT: "2"
  NOTIFICATION_BASE_URL: http://platform-service:9005/api/
  OPA_CONNECT_TIMEOUT: "40"
  OPA_READ_TIMEOUT: "40"
  OPA_SERVER_BASEURL: http://policy-mgmt:3000/
  ORCHESTRATION_LOG_SHOULD_USE_BATCHING: "true"
  ORCHESTRATION_POOL_MAX_SIZE: "300"
  ORCHESTRATION_VISUALIZATION_POOL_CORE_SIZE: "10"
  ORCHESTRATION_VISUALIZATION_POOL_MAX_SIZE: "50"
  OTEL_EXPORTER_OTLP_ENDPOINT: ""
  OTEL_SERVICE_NAME: pipeline-service
  PIPELINE_SDK_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_RESPONSE_SPAWN_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SDK_STEP_RESPONSE_EVENT_MAX_TOPIC_SIZE: "10000"
  PIPELINE_SERVICE_BASE_URL: https://harness.mcintosh.farm/ng/#
  PIPELINE_SERVICE_ENDPOINT: http://pipeline-service:12001/api/
  PLAN_CREATOR_DEPENDENCY_BATCH: "10"
  PLAN_CREATOR_MERGE_SERVICE_EXECUTOR_POOL_CORE_SIZE: "20"
  PLAN_CREATOR_MERGE_SERVICE_EXECUTOR_POOL_MAX_SIZE: "100"
  PLAN_CREATOR_SERVICE_EXECUTOR_POOL_CORE_SIZE: "20"
  PLAN_CREATOR_SERVICE_EXECUTOR_POOL_MAX_SIZE: "100"
  PMS_API_BASE_URL: https://harness.mcintosh.farm/gateway/pipeline/api/
  PMS_WEBHOOK_EVENT_CONSUMER_THREAD_COUNT: "15"
  PROMETHEUS_COLLECTOR_PORT: "8889"
  PUBLISH_ADVISER_EVENT_FOR_CUSTOM_ADVISERS: "true"
  REDIS_RETRY_ATTEMPTS: "5"
  REDIS_RETRY_INTERVAL: "2500"
  REDIS_SUBSCRIPTIONS_PER_CONNECTION: "10"
  REDISSON_PING_CONNECTION_INTERVAL_IN_MILLIS: "0"
  REDUCE_ORCHESTRATION_EVENT_LOG: "true"
  RESOURCE_GROUP_BASE_URL: http://platform-service:9005/api/
  RESOURCE_RESTRAINT_ITERATOR_THREAD_POOL_SIZE: "10"
  RESUME_EVENT_CONSUMER_THREAD_COUNT: "2"
  SCM_SERVICE_URI: dns:///scm-service-headless:8091
  SDK_RESPONSE_EVENT_CONSUMER_THREAD_COUNT: "2"
  SDK_RESPONSE_EVENT_POOL_MAX_SIZE: "300"
  SEGMENT_ENABLED: "false"
  SHOULD_CONFIGURE_WITH_CI: "true"
  STACK_DRIVER_LOGGING_ENABLED: "false"
  STO_MANAGER_BASE_URL: http://sto-manager:7090/
  STO_SERVICE_ENDPOINT: https://harness.mcintosh.farm/sto/
  STO_SERVICE_INTERNAL_ENDPOINT: http://sto-core.harness.svc.cluster.local:4000/
  TEMPLATE_SERVICE_ENDPOINT: http://template-service:15002/api/
  VARIABLE_CREATOR_MERGE_SERVICE_EXECUTOR_POOL_CORE_SIZE: "5"
  VARIABLE_CREATOR_MERGE_SERVICE_EXECUTOR_POOL_MAX_SIZE: "5"
  VERSION: 1.147.3
  WEBHOOK_TRIGGER_BASEURL: https://harness.mcintosh.farm/ng/api/
kind: ConfigMap
metadata:
  labels: null
  name: pipeline-service
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control:9006/api/
  ACCESS_CONTROL_ENABLED: "true"
  ACCESS_CONTROL_READ_TIMEOUT: "10"
  AUDIT_CLIENT_BASEURL: http://platform-service:9005/api/
  AUDIT_ENABLED: "true"
  AUDIT_MONGO_MAX_OPERATION_TIME_IN_MILLIS: "25000"
  CDE_MANAGER_CLIENT_BASEURL: http://cde-manager:80/api/
  CDE_READ_TIMEOUT: "15"
  CE_NEXTGEN_CLIENT_BASEURL: http://nextgen-ce.harness.svc.cluster.local:6340/ccm/api/
  CE_NG_READ_TIMEOUT: "15"
  CF_CLIENT_ANALYTICS_ENABLED: "true"
  CF_CLIENT_BUFFER_SIZE: "10240"
  CF_CLIENT_CONFIG_URL: https://config.feature-flags.uat.harness.io/api/1.0
  CF_CLIENT_CONNECTION_TIMEOUT: "10000"
  CF_CLIENT_EVENT_URL: https://event.feature-flags.uat.harness.io/api/1.0
  CF_CLIENT_READ_TIMEOUT: "45000"
  CF_CLIENT_RETRIES: "6"
  CF_CLIENT_SLEEP_INTERVAL: "5000"
  CG_MANAGER_READ_TIMEOUT: "15"
  CHATBOT_SERVICE_URL: http://chatbot-service:8000/chat
  CODE_READ_TIMEOUT: "15"
  CODE_SERVICE_CLIENT_BASEURL: http://code-api:80/
  CODE_SERVICE_SECRET: '"IC04LYMBf1lDP5oeY4hupxd4HJhLmN6azUku3xEbeE3SUx5G3ZYzhbiwVtK4i7AmqyU9OZkwB4v8E9qM"'
  DBOPS_SERVICE_CLIENT_BASEURL: http://db-devops-service:5001/
  DEPLOY_MODE: KUBERNETES_ONPREM
  DISTRIBUTED_LOCK_IMPLEMENTATION: REDIS
  DYNAMIC_RESOURCE_REFRESH_INTERVAL_IN_SECONDS: "300"
  ENABLE_AUDIT_SERVICE: "true"
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  ENABLE_RESOURCE_GROUP: "true"
  ENFORCEMENT_CHECK_ENABLED: "true"
  ENV: SMP
  EVENTS_FRAMEWORK_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_USE_SENTINEL: "true"
  FEATURE_FLAG_SYSTEM: LOCAL
  FILE_LOGGING_ENABLED: "true"
  FIPS_ENABLED: "false"
  GITOPS_SERVICE_CLIENT_BASEURL: http://gitops:7908/api/v1/
  GRPC_MANAGER_AUTHORITY: harness-manager:9879
  GRPC_MANAGER_TARGET: harness-manager:9879
  HAR_READ_TIMEOUT: "15"
  HAR_SERVICE_CLIENT_BASEURL: http://registry-api:8181/api/
  IDP_READ_TIMEOUT: "10"
  IDP_SERVICE_CLIENT_BASEURL: http://idp-service:12003/
  INTERNAL_GRPC_MANAGER_AUTHORITY: harness-manager:9879
  INTERNAL_GRPC_MANAGER_TARGET: harness-manager:9879
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  JAVA_ADVANCED_FLAGS: -XX:+ExitOnOutOfMemoryError
  LOCK_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  LOCK_CONFIG_USE_SENTINEL: "true"
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  LOGGING_LEVEL: INFO
  MANAGER_CLIENT_BASEURL: http://harness-manager:9090/api/
  MEMORY: 3072m
  MONGO_MAX_DOCUMENT_LIMIT: "10000"
  MONGO_MAX_OPERATION_TIME_IN_MILLIS: "20000"
  MONGO_MESSAGE_CONSUMER_THREAD_COUNT: "4"
  NG_MANAGER_CLIENT_BASEURL: http://ng-manager:7090/
  NOTIFICATION_ATTACHMENTS_CLEANUP_FREQUENCY_MINS: "180"
  NOTIFICATION_ATTACHMENTS_TTL_DAYS: "7"
  NOTIFICATION_QUEUE_METRICS_PUBLISH_INTERVAL: "2"
  OPA_READ_TIMEOUT: "10"
  OPA_SERVER_BASEURL: http://policy-mgmt.harness.svc.cluster.local:3000/
  OPA_SERVER_SECRET: dOkdsVqdRPPRJG31XU0qY4MPqmBBMk0PTAGIKM6O7TGqhjyxScIdJe80mwh5Yb5zF3KxYBHw6B3Lfzlq
  PIPELINE_READ_TIMEOUT: "15"
  PIPELINE_SERVICE_CLIENT_BASEURL: http://pipeline-service:12001/api/
  PIPELINE_SERVICE_READ_TIMEOUT: "15"
  PLATFORM_READ_TIMEOUT: "10"
  PLATFORM_SERVICE_CLIENT_BASEURL: http://platform-service:9005/api/
  PROMETHEUS_COLLECTOR_PORT: "8889"
  RBAC_URL: http://ng-manager:7090/
  REDISSON_PING_CONNECTION_INTERVAL_IN_MILLIS: "0"
  RESOURCE_GROUP_CLIENT_BASE_URL: http://platform-service:9005/api/
  RESOURCE_IDENTIFIERS_THRESHOLD: "1300"
  RESOURCEGROUP_MONGO_MAX_DOCUMENT_LIMIT: "10000"
  RESOURCEGROUP_MONGO_MAX_OPERATION_TIME_IN_MILLIS: "25000"
  SCOPE_SELECTOR_THRESHOLD: "75"
  SERVICE_CONNECT_TIMEOUT: "15"
  STACK_DRIVER_LOGGING_ENABLED: "false"
  SYNC_FEATURES_TO_CF: "false"
  TEMPLATE_SERVICE_BASE_URL: http://template-service:15002/api/
  TEMPLATE_SERVICE_CLIENT_BASEURL: http://template-service:15002/api/
  TEMPLATE_SERVICE_CONNECT_TIMEOUT: "15"
  TEMPLATE_SERVICE_READ_TIMEOUT: "10"
kind: ConfigMap
metadata:
  labels: null
  name: platform-service
  namespace: harness
---
apiVersion: v1
data:
  APP_ACCESS_CONTROL_BASE_URL: http://access-control:9006
  APP_DATABASE_DBNAME: policy-mgmt
  APP_DATABASE_DRIVER: postgres
  APP_DEBUG: "true"
  APP_ENABLE_AUDIT_TRAIL: "true"
  APP_EVENTS_FRAMEWORK_REDIS_SENTINEL_MASTER_NAME: harness-redis
  APP_EVENTS_FRAMEWORK_REDIS_SENTINEL_URLS: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  APP_EVENTS_FRAMEWORK_REDIS_SSL_ENABLED: "false"
  APP_EVENTS_FRAMEWORK_REDIS_URL: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  APP_EVENTS_FRAMEWORK_REDIS_USE_PASSWORD: "false"
  APP_EVENTS_FRAMEWORK_REDIS_USE_SENTINEL: "true"
  APP_FEATURE_FLAGS_ENABLED: "false"
  APP_GITX_AUTHORITY: ng-manager:13002
  APP_GITX_ENABLED: "true"
  APP_GITX_URL: ng-manager:13002
  APP_HTTP_BIND: :3000
  APP_NG_BASE_URL: http://ng-manager:7090
  APP_ON_PREM: "true"
  APP_PLATFORM_BASE_URL: http://platform-service:9005
  HARNESS_SERVICES_PIPELINE_CLIENT_BASEURL: http://pipeline-service:12001/
  HARNESS_SERVICES_PIPELINE_CLIENT_SECURE: "false"
  HARNESS_SERVICES_PIPELINE_JWT_IDENTITY: Pipeline
  PG_SSLMODE: disable
  POLICY_MGMT_SERVICE_METRICS_PORT: "3535"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: policy-mgmt
    app.kubernetes.io/version: v1.68.0
    helm.sh/chart: policy-mgmt-1.24.4
  name: policy-mgmt
  namespace: harness
---
apiVersion: v1
data:
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  HSQS_DEBUG: "false"
  HSQS_DISABLE_AUTH: "false"
  HSQS_ENABLE_PROFILER: "false"
  HSQS_HOST: ""
  HSQS_PORT: "9091"
  HSQS_REDIS_ENDPOINT: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  HSQS_REDIS_SENTINEL_ENABLED: "true"
  PROMETHEUS_COLLECTOR_PORT: "9091"
kind: ConfigMap
metadata:
  name: queue-service
  namespace: harness
---
apiVersion: v1
data:
  haproxy_init.sh: |
    HAPROXY_CONF=/data/haproxy.cfg
    cp /readonly/haproxy.cfg "$HAPROXY_CONF"
    for loop in $(seq 1 10); do
      getent hosts redis-sentinel-harness-announce-0 && break
      echo "Waiting for service redis-sentinel-harness-announce-0 to be ready ($loop) ..." && sleep 1
    done
    ANNOUNCE_IP0=$(getent hosts "redis-sentinel-harness-announce-0" | awk '{ print $1 }')
    if [ -z "$ANNOUNCE_IP0" ]; then
      echo "Could not resolve the announce ip for redis-sentinel-harness-announce-0"
      exit 1
    fi
    sed -i "s/REPLACE_ANNOUNCE0/$ANNOUNCE_IP0/" "$HAPROXY_CONF"

    if [ "${AUTH:-}" ]; then
        echo "Setting auth values"
        ESCAPED_AUTH=$(echo "$AUTH" | sed -e 's/[\/&]/\\&/g');
        sed -i "s/REPLACE_AUTH_SECRET/${ESCAPED_AUTH}/" "$HAPROXY_CONF"
    fi
    for loop in $(seq 1 10); do
      getent hosts redis-sentinel-harness-announce-1 && break
      echo "Waiting for service redis-sentinel-harness-announce-1 to be ready ($loop) ..." && sleep 1
    done
    ANNOUNCE_IP1=$(getent hosts "redis-sentinel-harness-announce-1" | awk '{ print $1 }')
    if [ -z "$ANNOUNCE_IP1" ]; then
      echo "Could not resolve the announce ip for redis-sentinel-harness-announce-1"
      exit 1
    fi
    sed -i "s/REPLACE_ANNOUNCE1/$ANNOUNCE_IP1/" "$HAPROXY_CONF"

    if [ "${AUTH:-}" ]; then
        echo "Setting auth values"
        ESCAPED_AUTH=$(echo "$AUTH" | sed -e 's/[\/&]/\\&/g');
        sed -i "s/REPLACE_AUTH_SECRET/${ESCAPED_AUTH}/" "$HAPROXY_CONF"
    fi
    for loop in $(seq 1 10); do
      getent hosts redis-sentinel-harness-announce-2 && break
      echo "Waiting for service redis-sentinel-harness-announce-2 to be ready ($loop) ..." && sleep 1
    done
    ANNOUNCE_IP2=$(getent hosts "redis-sentinel-harness-announce-2" | awk '{ print $1 }')
    if [ -z "$ANNOUNCE_IP2" ]; then
      echo "Could not resolve the announce ip for redis-sentinel-harness-announce-2"
      exit 1
    fi
    sed -i "s/REPLACE_ANNOUNCE2/$ANNOUNCE_IP2/" "$HAPROXY_CONF"

    if [ "${AUTH:-}" ]; then
        echo "Setting auth values"
        ESCAPED_AUTH=$(echo "$AUTH" | sed -e 's/[\/&]/\\&/g');
        sed -i "s/REPLACE_AUTH_SECRET/${ESCAPED_AUTH}/" "$HAPROXY_CONF"
    fi
  init.sh: |
    HOSTNAME="$(hostname)"
    INDEX="${HOSTNAME##*-}"
    MASTER="$(redis-cli -h redis-sentinel-harness -p 26379 sentinel get-master-addr-by-name harness-redis | grep -E '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}')"
    MASTER_GROUP="harness-redis"
    QUORUM="2"
    REDIS_CONF=/data/conf/redis.conf
    REDIS_PORT=6379
    SENTINEL_CONF=/data/conf/sentinel.conf
    SENTINEL_PORT=26379
    SERVICE=redis-sentinel-harness
    set -eu

    sentinel_update() {
        echo "Updating sentinel config with master $MASTER"
        eval MY_SENTINEL_ID="\${SENTINEL_ID_$INDEX}"
        sed -i "1s/^/sentinel myid $MY_SENTINEL_ID\\n/" "$SENTINEL_CONF"
        sed -i "2s/^/sentinel monitor $MASTER_GROUP $1 $REDIS_PORT $QUORUM \\n/" "$SENTINEL_CONF"
        echo "sentinel announce-ip $ANNOUNCE_IP" >> $SENTINEL_CONF
        echo "sentinel announce-port $SENTINEL_PORT" >> $SENTINEL_CONF
    }

    redis_update() {
        echo "Updating redis config"
        echo "slaveof $1 $REDIS_PORT" >> "$REDIS_CONF"
        echo "slave-announce-ip $ANNOUNCE_IP" >> $REDIS_CONF
        echo "slave-announce-port $REDIS_PORT" >> $REDIS_CONF
    }

    copy_config() {
        cp /readonly-config/redis.conf "$REDIS_CONF"
        cp /readonly-config/sentinel.conf "$SENTINEL_CONF"
    }

    setup_defaults() {
        echo "Setting up defaults"
        if [ "$INDEX" = "0" ]; then
            echo "Setting this pod as the default master"
            redis_update "$ANNOUNCE_IP"
            sentinel_update "$ANNOUNCE_IP"
            sed -i "s/^.*slaveof.*//" "$REDIS_CONF"
        else
            DEFAULT_MASTER="$(getent hosts "$SERVICE-announce-0" | awk '{ print $1 }')"
            if [ -z "$DEFAULT_MASTER" ]; then
                echo "Unable to resolve host"
                exit 1
            fi
            echo "Setting default slave config.."
            redis_update "$DEFAULT_MASTER"
            sentinel_update "$DEFAULT_MASTER"
        fi
    }

    find_master() {
        echo "Attempting to find master"
        if [ "$(redis-cli -h "$MASTER" ping)" != "PONG" ]; then
           echo "Can't ping master, attempting to force failover"
           if redis-cli -h "$SERVICE" -p "$SENTINEL_PORT" sentinel failover "$MASTER_GROUP" | grep -q 'NOGOODSLAVE' ; then
               setup_defaults
               return 0
           fi
           sleep 10
           MASTER="$(redis-cli -h $SERVICE -p $SENTINEL_PORT sentinel get-master-addr-by-name $MASTER_GROUP | grep -E '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}')"
           if [ "$MASTER" ]; then
               sentinel_update "$MASTER"
               redis_update "$MASTER"
           else
              echo "Could not failover, exiting..."
              exit 1
           fi
        else
            echo "Found reachable master, updating config"
            sentinel_update "$MASTER"
            redis_update "$MASTER"
        fi
    }

    mkdir -p /data/conf/

    echo "Initializing config.."
    copy_config

    ANNOUNCE_IP=$(getent hosts "$SERVICE-announce-$INDEX" | awk '{ print $1 }')
    if [ -z "$ANNOUNCE_IP" ]; then
        "Could not resolve the announce ip for this pod"
        exit 1
    elif [ "$MASTER" ]; then
        find_master
    else
        setup_defaults
    fi

    if [ "${AUTH:-}" ]; then
        echo "Setting auth values"
        ESCAPED_AUTH=$(echo "$AUTH" | sed -e 's/[\/&]/\\&/g');
        sed -i "s/replace-default-auth/${ESCAPED_AUTH}/" "$REDIS_CONF" "$SENTINEL_CONF"
    fi

    echo "Ready..."
  redis.conf: |
    dir "/data"
    port 6379
    active-defrag-cycle-max 25
    active-defrag-ignore-bytes 1mb
    activedefrag yes
    maxmemory 0
    maxmemory-policy volatile-lru
    min-replicas-max-lag 10
    min-replicas-to-write 1
    rdbchecksum yes
    rdbcompression yes
    repl-diskless-sync yes
    save 60 1
    maxclients 30000
    timeout 10
  sentinel.conf: |
    dir "/data"
        sentinel down-after-milliseconds harness-redis 10000
        sentinel failover-timeout harness-redis 180000
        maxclients 30000
        sentinel parallel-syncs harness-redis 5
kind: ConfigMap
metadata:
  labels:
    app: redis-sentinel-harness
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 6.2.14-alpine
    helm.sh/chart: redis-0.8.2
  name: redis-sentinel-harness-configmap
  namespace: harness
---
apiVersion: v1
data:
  ENABLE_CDN: "false"
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  PROMETHEUS_COLLECTOR_PORT: "8889"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: srm-ui
    app.kubernetes.io/version: 0.6.1
    helm.sh/chart: srm-ui-1.13.1
  name: srm-ui
  namespace: harness
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control:9006/api/
  ACCESS_CONTROL_ENABLED: "true"
  ALLOWED_ORIGINS: https://harness.mcintosh.farm
  AUDIT_SERVICE_BASE_URL: http://platform-service:9005/api/
  CACHE_BACKEND: REDIS
  CACHE_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  CACHE_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  CACHE_CONFIG_USE_SENTINEL: "true"
  DEPLOY_MODE: KUBERNETES_ONPREM
  ENABLE_AUDIT: "true"
  ENABLE_AUTH: "true"
  ENABLE_GIT_SYNC: "true"
  ENABLE_OPA_EVALUATION: "true"
  ENABLE_PROMETHEUS_COLLECTOR: "false"
  ENFORCEMENT_CHECK_ENABLED: "true"
  ENV: SMP
  EVENTS_FRAMEWORK_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_USE_SENTINEL: "true"
  FILE_LOGGING_ENABLED: "true"
  FIPS_ENABLED: "false"
  IACM_SERVICE_ENDPOINT: http://iac-server:8080
  INTERNAL_MANAGER_AUTHORITY: harness-manager:9879
  INTERNAL_MANAGER_TARGET: harness-manager:9879
  INTERNAL_NG_MANAGER_GITSYNC_AUTHORITY: ng-manager:13002
  INTERNAL_NG_MANAGER_GITSYNC_TARGET: ng-manager:13002
  INTERNAL_PMS_GRPC_AUTHORITY: pipeline-service:12011
  INTERNAL_PMS_GRPC_TARGET: pipeline-service:12011
  JAVA_17_FLAGS: --illegal-access=debug --add-opens java.base/java.lang=ALL-UNNAMED
    --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens java.base/java.time=ALL-UNNAMED
    --add-opens java.base/java.io=ALL-UNNAMED --add-opens java.base/java.lang.invoke=ALL-UNNAMED
    --add-opens java.base/java.math=ALL-UNNAMED --add-opens java.base/java.nio.file=ALL-UNNAMED
    --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.xml/com.sun.org.apache.xpath.internal=ALL-UNNAMED
    --add-opens java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED
    --add-exports java.xml/com.sun.org.apache.xerces.internal.parsers=ALL-UNNAMED
    --add-exports java.base/sun.nio.ch=ALL-UNNAMED
  JAVA_ADVANCED_FLAGS: -XX:+ExitOnOutOfMemoryError
  LOCK_CONFIG_REDIS_SENTINELS: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_REDIS_URL: redis://redis-sentinel-harness-announce-0:26379,redis://redis-sentinel-harness-announce-1:26379,redis://redis-sentinel-harness-announce-2:26379
  LOCK_CONFIG_SENTINEL_MASTER_NAME: harness-redis
  LOCK_CONFIG_USE_SENTINEL: "true"
  LOG_FILENAME: /opt/harness/logs/pod.log
  LOG_MAX_FILE_COUNT: "10"
  LOG_MAX_FILE_SIZE: 50MB
  LOG_TOTAL_FILE_SIZE_CAP: 600MB
  LOGGING_LEVEL: INFO
  MANAGER_AUTHORITY: harness-manager:9879
  MANAGER_CLIENT_BASEURL: http://harness-manager:9090/api/
  MANAGER_TARGET: harness-manager:9879
  MEMORY: 1024m
  NG_MANAGER_BASE_URL: http://ng-manager:7090/
  NG_MANAGER_GITSYNC_AUTHORITY: ng-manager:13002
  NG_MANAGER_GITSYNC_TARGET: ng-manager:13002
  OPA_CONNECTIVITY_ENABLED: "true"
  OPA_SERVER_BASEURL: http://policy-mgmt.harness.svc.cluster.local:3000/
  PIPELINE_SERVICE_CLIENT_BASEURL: http://pipeline-service:12001/api/
  PMS_GRPC_AUTHORITY: pipeline-service:12011
  PMS_GRPC_TARGET: pipeline-service:12011
  PROMETHEUS_COLLECTOR_PORT: "8889"
  REDISSON_PING_CONNECTION_INTERVAL_IN_MILLIS: "0"
  SCM_SERVICE_URI: dns:///scm-service-headless:8091
  SERVER_PORT: "15002"
  STACK_DRIVER_LOGGING_ENABLED: "false"
kind: ConfigMap
metadata:
  name: template-service
  namespace: harness
---
apiVersion: v1
data:
  ENV: SMP
  EVENTS_FRAMEWORK_REDIS_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_REDIS_SENTINEL_URLS: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_USE_SENTINEL: "true"
  TI_SERVICE_ACCESS_CONTROL_BASE_URL: http://access-control:9006/api
  TI_SERVICE_AGENT_BASE_URL: https://app.harness.io/storage/harness-download/harness-ti
  TI_SERVICE_COVERAGE_HYPER_TABLE: coverage
  TI_SERVICE_DB_NAME: harnessti
  TI_SERVICE_DISABLE_AUTH: "true"
  TI_SERVICE_HYPER_TABLE: evaluation
  TI_SERVICE_MANAGER_URL: http://harness-manager:9090/api
  TI_SERVICE_MONGODB_DB_NAME: ti-harness
  TI_SERVICE_SAVINGS_HYPER_TABLE: savings
  TI_SERVICE_SELECTION_HYPER_TABLE: selection
  TI_SERVICE_TAG_HYPER_TABLE: tag
  TI_SERVICE_TIMESCALE_DEFAULT_DB: postgres
  TI_SERVICE_TIMESCALE_PORT: "5432"
kind: ConfigMap
metadata:
  name: ti-service
  namespace: harness
---
apiVersion: v1
data:
  SMP_VERSION: 0.33.2
kind: ConfigMap
metadata:
  labels:
    chart: harness
    release: harness
    version: 0.33.2
  name: global-smp-config
---
apiVersion: v1
data:
  ACCESS_CONTROL_BASE_URL: http://access-control.harness.svc.cluster.local:9006
  AUDIT_BASE_URL: http://platform-service.harness.svc.cluster.local:9005
  AWS_ENABLED: "false"
  CG_MANAGER_BASE_URL: http://harness-manager.harness.svc.cluster.local:9090
  DATABASE_SSL_MODE: disable
  ENABLE_SMP: "true"
  EVENTS_FRAMEWORK_REDIS_ENABLED: "true"
  EVENTS_FRAMEWORK_REDIS_SENTINEL_MASTER_NAME: harness-redis
  EVENTS_FRAMEWORK_REDIS_SENTINEL_URLS: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_URL: redis-sentinel-harness-announce-0:26379,redis-sentinel-harness-announce-1:26379,redis-sentinel-harness-announce-2:26379
  EVENTS_FRAMEWORK_REDIS_USE_PASSWORD: "false"
  EVENTS_FRAMEWORK_REDIS_USE_SENTINEL: "true"
  FF_BASE_URL: https://harness0.harness.io/sdk/api/1.0
  FF_EVENT_URL: https://harness0.harness.io/events
  GCP_GCS_PROJECT: null
  HARNESS_CODE_BASE_URL: http://code-api.harness.svc.cluster.local:80/
  IACM_GLOBAL_RATE_LIMIT_BURST: "1"
  IACM_GLOBAL_RATE_LIMIT_ENABLED: "false"
  IACM_GLOBAL_RATE_LIMIT_RPS: "1"
  LISTEN_ADDR: :8080
  MINIO_BUCKET_PREFIX: ""
  MINIO_ENDPOINT: minio.harness.svc.cluster.local:9000
  MODULE_REGISTRY_URL: /gateway/iacm/registry/account
  NG_MANAGER_BASE_URL: http://ng-manager.harness.svc.cluster.local:7090
  PIPELINE_SERVICE_BASE_URL: http://pipeline-service.harness.svc.cluster.local:12001
  PLATFORM_BASE_URL: https://pipeline-service.harness.svc.cluster.local:12001
  POLICY_MGM_BASE_URL: http://policy-mgmt.harness.svc.cluster.local:3000
  POSTGRES_DB: iac_server
  POSTGRES_HOST: postgres
  POSTGRES_PORT: "5432"
  PROVIDER_REGISTRY_BASE_URL: https://harness.mcintosh.farm/iacm/
  PROVIDER_REGISTRY_URL: /provider/account/
  TEMPLATE_SERVICE_BASE_URL: http://template-service.harness.svc.cluster.local:15002
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iac-server
    app.kubernetes.io/part-of: harness-infra-as-code
    helm.sh/chart: iac-server-1.242.0
  name: iac-server
---
apiVersion: v1
data:
  GITOPS_SERVICE_SECRET: SFZTS1VZcUQ0ZTVSeHUxMmhGRGRDSktHTTY0c3hnRXludmREaGFPSGFUSGh3d24wSzRUdHIwdW9PeFNzRVZZTnJVVT0=
  IDENTITY_SERVICE_SECRET: SFZTS1VZcUQ0ZTVSeHUxMmhGRGRDSktHTTY0c3hnRXludmREaGFPSGFUSGh3d24wSzRUdHIwdW9PeFNzRVZZTnJVVT0=
  OPA_SERVICE_SECRET: ZE9rZHNWcWRSUFBSSkczMVhVMHFZNE1QcW1CQk1rMFBUQUdJS002TzdUR3Foanl4U2NJZEplODBtd2g1WWI1ekYzS3hZQkh3NkIzTGZ6bHE=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: access-control
    app.kubernetes.io/version: 1.0.79802
    helm.sh/chart: access-control-1.64.1
  name: access-control
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  SOME_DEFAULT_SECRET: RFVNTVk=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: change-data-capture
    app.kubernetes.io/version: 0.0.81510
    helm.sh/chart: change-data-capture-1.37.4
  name: change-data-capture
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  CACHE_SERVICE_GLOBAL_TOKEN: ZjQ3YzY0NzAtMjQ4My00ZTA2LThmNDQtM2MzNWQ2YjU1YjI2
  HSQS_AUTH_TOKEN: VWVXZ1VSZUdYbGJyQjB6a0RDQkZ6MUVEZlUxenJYYmhBYkdmUThqc1NDYUE4ODFTWUZNbEhxbm4zT1FuQUtBVTZoVFE1Tm5pd3VNZUtTRlc=
  JWT_DATA_HANDLER_SECRET: UmRMN2o5WmRDejZUVlNITzdvYkpSUzZ5d1lMSmpIOHRkZlBQMzlpNE1iZXZLalZvZHZqZGhha2RoYXNoc2g0MzcxZGFzamxkYXM=
  LOG_SERVICE_GLOBAL_TOKEN: WXpjMlpUVTJOMkV0WWpNME1TMDBNRFJrTFdFNFpHUXRaRGszTXpnM01UUmxZamd5Q2c9PQ==
  OPA_SERVER_SECRET: ZE9rZHNWcWRSUFBSSkczMVhVMHFZNE1QcW1CQk1rMFBUQUdJS002TzdUR3Foanl4U2NJZEplODBtd2g1WWI1ekYzS3hZQkh3NkIzTGZ6bHE=
  SPLIT_TOKEN: bG9jYWxob3N0
  STO_SERVICE_GLOBAL_TOKEN: eTFJVUxIYUR6YQ==
  TI_SERVICE_GLOBAL_TOKEN: NTlNUjVSbFZBUmNkSDd6YjdwTng2R3pxaWdsQm1YUjg=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ci-manager
    app.kubernetes.io/version: 0.0.5309
    helm.sh/chart: ci-manager-1.51.8
  name: ci-manager
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  VERIFICATION_SERVICE_SECRET: NTlNUjVSbFZBUmNkSDd6YjdwTng2R3pxaWdsQm1YUjg=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: cv-nextgen
    app.kubernetes.io/version: 1.9.0
    helm.sh/chart: cv-nextgen-1.27.4
  name: cv-nextgen
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  JWT_ADMIN_PORTAL_SECRET: bmhVbXV0Mk5NY1Vuc1IwMU9nT3owZTUxTVo1MUFxVXdyT0FUSjNmSg==
  JWT_DATA_HANDLER_SECRET: UmRMN2o5WmRDejZUVlNITzdvYkpSUzZ5d1lMSmpIOHRkZlBQMzlpNE1iZXZLalZvZHZqZGhha2RoYXNoc2g0MzcxZGFzamxkYXM=
  LOG_SVC_GLOBAL_TOKEN: Yzc2ZTU2N2EtYjM0MS00MDRkLWE4ZGQtZDk3Mzg3MTRlYjgy
  TI_SVC_GLOBAL_TOKEN: NzhkMTZiNjYtNGI0Yy0xMWViLTgzNzctYWNkZTQ4MDAxMTIy
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gateway
    app.kubernetes.io/version: 0.0.11401
    helm.sh/chart: gateway-1.37.1
  name: gateway
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  ACL_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  IDENTITY_SERVICE_SECRET: SFZTS1VZcUQ0ZTVSeHUxMmhGRGRDSktHTTY0c3hnRXludmREaGFPSGFUSGh3d24wSzRUdHIwdW9PeFNzRVZZTnJVVT0=
  JWT_SECRET: SFZTS1VZcUQ0ZTVSeHUxMmhGRGRDSktHTTY0c3hnRXludmREaGFPSGFUSGh3d24wSzRUdHIwdW9PeFNzRVZZTnJVVT0=
  MANAGER_JWT_AUTH_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  PLATFORM_AUTH_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  PLATFORMSERVICE_AUTH_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gitops
    app.kubernetes.io/version: v0.81.3
    helm.sh/chart: gitops-1.19.4
  name: gitops
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  NG_LICENSE: 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
kind: Secret
metadata:
  name: harness-license
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  CF_CLIENT_API_KEY: RFVNTVk=
  LOG_STREAMING_SERVICE_TOKEN: Yzc2ZTU2N2EtYjM0MS00MDRkLWE4ZGQtZDk3Mzg3MTRlYjgy
  VERIFICATION_SERVICE_SECRET: NTlNUjVSbFZBUmNkSDd6YjdwTng2R3pxaWdsQm1YUjg=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-manager
    app.kubernetes.io/version: 0.0.81725
    helm.sh/chart: harness-manager-1.58.8
  name: harness-manager
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  PATRONI_REPLICATION_PASSWORD: emNZbEplY1F3V1pmOW91MA==
  PATRONI_SUPERUSER_PASSWORD: ZkFLTEZVa2E5UGh5bXdXTA==
  PATRONI_admin_PASSWORD: dWNnS0pDNlR4MFpnaWdKbQ==
  minio-password: aGFybmVzcy1wYXNzd29yZA==
  minio-user: aGFybmVzcw==
  mongodbPassword: bXFhaU5YWkFKVXE2eFhzNQ==
  mongodbUsername: YWRtaW4=
  postgresdbAdminPassword: NkJsSDhWRDNEdDk5YklGNA==
  stoAppAuditJWTSecret: czVEVFUyUnNleGplbmxDcg==
  stoAppHarnessToken: Y0hsRGh3RTBTZ1czY012bg==
  timescaledbAdminPassword: dWNnS0pDNlR4MFpnaWdKbQ==
  timescaledbPostgresPassword: ZkFLTEZVa2E5UGh5bXdXTA==
  timescaledbStandbyPassword: emNZbEplY1F3V1pmOW91MA==
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-secrets
    app.kubernetes.io/version: 0.0.0
    helm.sh/chart: harness-secrets-0.10.0
  name: harness-secrets
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  VERIFICATION_SERVICE_SECRET: NjdkOWI5NGQ5ODU2NjY1YWZjMjFhY2QzYWE3NDU0MDE=
kind: Secret
metadata:
  labels: null
  name: iacm-manager
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  VERIFICATION_SERVICE_SECRET: NTlNUjVSbFZBUmNkSDd6YjdwTng2R3pxaWdsQm1YUjg=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: le-nextgen
    app.kubernetes.io/version: 0.0.68305
    helm.sh/chart: le-nextgen-1.5.6
  name: le-nextgen
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  LOG_SERVICE_GLOBAL_TOKEN: Yzc2ZTU2N2EtYjM0MS00MDRkLWE4ZGQtZDk3Mzg3MTRlYjgy
  LOG_SERVICE_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: log-service
    app.kubernetes.io/version: 0.0.release-128-ubi
    helm.sh/chart: log-service-1.14.5
  name: log-service
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  root-password: WnZHSWtwbnFycA==
  root-user: YWRtaW4=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-secrets
    app.kubernetes.io/version: 0.0.0
    helm.sh/chart: harness-secrets-0.10.0
  name: minio
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  mongodb-replica-set-key: TGQ2cGtEYlRwSA==
  mongodb-root-password: Wks4djVUYUlsWg==
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-secrets
    app.kubernetes.io/version: 0.0.0
    helm.sh/chart: harness-secrets-0.10.0
  name: mongodb-replicaset-chart
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  CAPTCHA_TOKEN: dFVBU1FUTGNOTQ==
  INVISIBLE_CAPTCHA_TOKEN: N2hYM05jRDVhWQ==
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-auth-ui
    app.kubernetes.io/version: 0.0.1
    helm.sh/chart: ng-auth-ui-1.28.3
  name: ng-auth-ui
  namespace: harness
type: Opaque
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-dashboard-aggregator
    app.kubernetes.io/version: 0.0.80909
    helm.sh/chart: ng-dashboard-aggregator-1.30.1
  name: ng-dashboard-aggregator
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  CE_AWS_ACCESS_KEY: SGprZjhINmVrOA==
  CE_AWS_DESTINATION_BUCKET: VXZ2VWtaNmhwOA==
  CE_AWS_SECRET_KEY: S0dYeFp6RGZlTg==
  CE_AWS_TEMPLATE_URL: WXFkZUlkUjNwZQ==
  DEVOPS_STRIPE_API_KEY: aHBFS3V2QnYzWA==
  GITOPS_SERVICE_SECRET: SFZTS1VZcUQ0ZTVSeHUxMmhGRGRDSktHTTY0c3hnRXludmREaGFPSGFUSGh3d24wSzRUdHIwdW9PeFNzRVZZTnJVVT0=
  HSQS_AUTH_TOKEN: VWVXZ1VSZUdYbGJyQjB6a0RDQkZ6MUVEZlUxenJYYmhBYkdmUThqc1NDYUE4ODFTWUZNbEhxbm4zT1FuQUtBVTZoVFE1Tm5pd3VNZUtTRlc=
  LOG_STREAMING_SERVICE_TOKEN: Yzc2ZTU2N2EtYjM0MS00MDRkLWE4ZGQtZDk3Mzg3MTRlYjgy
  OPA_SERVER_SECRET: ZE9rZHNWcWRSUFBSSkczMVhVMHFZNE1QcW1CQk1rMFBUQUdJS002TzdUR3Foanl4U2NJZEplODBtd2g1WWI1ekYzS3hZQkh3NkIzTGZ6bHE=
  STRIPE_API_KEY: QncxbDJ4UjJ2dQ==
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-manager
    app.kubernetes.io/version: 0.0.80209
    helm.sh/chart: ng-manager-1.62.12
  name: ng-manager
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  CF_CLIENT_API_KEY: WlVMcDVYM1RyRQ==
  LOG_STREAMING_SERVICE_TOKEN: Yzc2ZTU2N2EtYjM0MS00MDRkLWE4ZGQtZDk3Mzg3MTRlYjgy
  OPA_SERVER_SECRET: ZE9rZHNWcWRSUFBSSkczMVhVMHFZNE1QcW1CQk1rMFBUQUdJS002TzdUR3Foanl4U2NJZEplODBtd2g1WWI1ekYzS3hZQkh3NkIzTGZ6bHE=
  STO_SERVICE_GLOBAL_TOKEN: eTFJVUxIYUR6YQ==
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pipeline-service
    app.kubernetes.io/version: 1.41.3
    helm.sh/chart: pipeline-service-1.101.11
  name: pipeline-service
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  CF_CLIENT_API_KEY: WlVMcDVYM1RyRQ==
  ET_AGENT_TOKEN: RFVNTVk=
  PIPELINE_SERVICE_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  TEMPLATE_SERVICE_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: platform-service
    app.kubernetes.io/version: 0.0.80000
    helm.sh/chart: platform-service-1.42.3
  name: platform-service
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  APP_INTERNAL_TOKEN_JWT_SECRET: ZE9rZHNWcWRSUFBSSkczMVhVMHFZNE1QcW1CQk1rMFBUQUdJS002TzdUR3Foanl4U2NJZEplODBtd2g1WWI1ekYzS3hZQkh3NkIzTGZ6bHE=
  APP_NEXT_GEN_MANAGER_JWT_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  APP_TOKEN_JWT_SECRET: SFZTS1VZcUQ0ZTVSeHUxMmhGRGRDSktHTTY0c3hnRXludmREaGFPSGFUSGh3d24wSzRUdHIwdW9PeFNzRVZZTnJVVT0=
  HARNESS_SERVICES_PIPELINE_JWT_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: policy-mgmt
    app.kubernetes.io/version: v1.68.0
    helm.sh/chart: policy-mgmt-1.10.3
  name: policy-mgmt
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  postgres-password: MmZzSGJKOHpGYw==
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-secrets
    app.kubernetes.io/version: 0.0.0
    helm.sh/chart: harness-secrets-0.10.0
  name: postgres
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  JWT_SECRET: VWVXZ1VSZUdYbGJyQjB6a0RDQkZ6MUVEZlUxenJYYmhBYkdmUThqc1NDYUE4ODFTWUZNbEhxbm4zT1FuQUtBVTZoVFE1Tm5pd3VNZUtTRlc=
kind: Secret
metadata:
  name: queue-service
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  cloud-data-store: null
  redis-labs-ca-truststore: null
kind: Secret
metadata:
  labels: null
  name: service-accounts-iacm-manager
  namespace: harness
---
apiVersion: v1
data:
  OPA_SERVER_SECRET: ZE9rZHNWcWRSUFBSSkczMVhVMHFZNE1QcW1CQk1rMFBUQUdJS002TzdUR3Foanl4U2NJZEplODBtd2g1WWI1ekYzS3hZQkh3NkIzTGZ6bHE=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: template-service
    app.kubernetes.io/version: 1.12.1
    helm.sh/chart: template-service-1.63.2
  name: template-service
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  TI_SERVICE_GLOBAL_TOKEN: NzhkMTZiNjYtNGI0Yy0xMWViLTgzNzctYWNkZTQ4MDAxMTIy
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ti-service
    app.kubernetes.io/version: 0.0.release-223
    helm.sh/chart: ti-service-1.34.1
  name: ti-service
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  password: ZkFLTEZVa2E5UGh5bXdXTA==
  username: cG9zdGdyZXMK
kind: Secret
metadata:
  name: tsdb-secret
  namespace: harness
type: Opaque
---
apiVersion: v1
data:
  AUDIT_AUTH_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  HARNESS_CODE_AUTH_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  NG_MANAGER_AUTH_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  PIPELINE_SERVICE_AUTH_SECRET: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  PLATFORM_SECRET_KEY: SUMwNExZTUJmMWxEUDVvZVk0aHVweGQ0SEpoTG1ONmF6VWt1M3hFYmVFM1NVeDVHM1pZemhiaXdWdEs0aTdBbXF5VTlPWmt3QjR2OEU5cU0=
  POLICY_MGMT_AUTH_SECRET: SFZTS1VZcUQ0ZTVSeHUxMmhGRGRDSktHTTY0c3hnRXludmREaGFPSGFUSGh3d24wSzRUdHIwdW9PeFNzRVZZTnJVVT0=
  SEGMENT_WRITE_KEY: NXNieTlrWVhLTw==
  SERVICE_GLOBAL_TOKEN: NTUxNzE1ZWEtY2E3MS0xMWVjLTlkNjQtMDI0MmFjMTIwMDAy
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iac-server
    app.kubernetes.io/part-of: harness-infra-as-code
    helm.sh/chart: iac-server-1.258.2
  name: iac-server
type: Opaque
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iac-server
    app.kubernetes.io/part-of: harness-infra-as-code
    helm.sh/chart: iac-server-1.242.0
  name: iac-server-service-accounts
stringData:
  redis-labs-ca-pem: null
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: access-control
    app.kubernetes.io/version: 1.0.79802
    helm.sh/chart: access-control-1.105.1
  name: access-control
  namespace: harness
spec:
  ports:
  - name: http
    port: 9006
    protocol: TCP
    targetPort: 9006
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: access-control
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: change-data-capture
    app.kubernetes.io/version: 0.0.81510
    helm.sh/chart: change-data-capture-1.46.3
  name: change-data-capture
  namespace: harness
spec:
  ports:
  - name: http
    port: 8190
    protocol: TCP
    targetPort: 8190
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: change-data-capture
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ci-manager
    app.kubernetes.io/version: 0.0.5309
    helm.sh/chart: ci-manager-1.97.3
  name: ci-manager
  namespace: harness
spec:
  ports:
  - name: ci-manager
    port: 7090
    protocol: TCP
    targetPort: 7090
  - name: grpc-ci-manager
    port: 9979
    protocol: TCP
    targetPort: 9979
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: ci-manager
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ci-manager
    app.kubernetes.io/version: 0.0.5309
    helm.sh/chart: ci-manager-1.97.3
  name: ci-manager-headless
  namespace: harness
spec:
  clusterIP: None
  ports:
  - name: ci-manager
    port: 7090
    protocol: TCP
    targetPort: 7090
  - name: grpc-ci-manager
    port: 9979
    protocol: TCP
    targetPort: 9979
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: ci-manager
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: cv-nextgen
    app.kubernetes.io/version: 1.9.0
    helm.sh/chart: cv-nextgen-1.44.0
  name: cv-nextgen
  namespace: harness
spec:
  ports:
  - name: cv
    port: 6060
    protocol: TCP
    targetPort: 6060
  - name: grpc-cv-nextgen
    port: 9979
    protocol: TCP
    targetPort: 9979
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: cv-nextgen
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: delegate-proxy
    app.kubernetes.io/version: 0.0.80104
    helm.sh/chart: delegate-proxy-1.3.0
  name: delegate-proxy
  namespace: harness
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: delegate-proxy
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gateway
    app.kubernetes.io/version: 0.0.11401
    helm.sh/chart: gateway-1.54.7
  name: gateway
  namespace: harness
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: gateway
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gitops
    app.kubernetes.io/version: v0.81.3
    helm.sh/chart: gitops-1.41.5
  name: gitops
  namespace: harness
spec:
  ports:
  - name: gitops-grpc
    port: 7909
    protocol: TCP
    targetPort: gitops-grpc
  - name: gitops-http
    port: 7908
    protocol: TCP
    targetPort: gitops-http
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: gitops
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-manager
    app.kubernetes.io/version: 0.0.81725
    helm.sh/chart: harness-manager-1.105.3
  name: harness-manager
  namespace: harness
spec:
  ports:
  - name: http-manager
    port: 9090
    protocol: TCP
    targetPort: 9090
  - name: grpc-manager
    port: 9879
    protocol: TCP
    targetPort: 9879
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: harness-manager
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-manager
    app.kubernetes.io/version: 0.0.81725
    helm.sh/chart: harness-manager-1.105.3
  name: harness-manager-headless
  namespace: harness
spec:
  clusterIP: None
  ports:
  - name: http-manager
    port: 9090
    protocol: TCP
    targetPort: 9090
  - name: grpc-manager
    port: 9879
    protocol: TCP
    targetPort: 9879
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: harness-manager
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iacm-manager
    app.kubernetes.io/part-of: harness-infra-as-code
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: iacm-manager-1.100.1
  name: iacm-manager
  namespace: harness
spec:
  ports:
  - name: iacm-manager
    port: 7090
    protocol: TCP
    targetPort: iacm-manager
  - name: iacm-mgr-grpc
    port: 9979
    protocol: TCP
    targetPort: iacm-mgr-grpc
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: iacm-manager
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: le-nextgen
    app.kubernetes.io/version: 0.0.68305
    helm.sh/chart: le-nextgen-1.10.0
  name: le-nextgen
  namespace: harness
spec:
  ports:
  - name: learning
    port: 8108
    protocol: TCP
    targetPort: 8108
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: le-nextgen
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: log-service
    app.kubernetes.io/version: 0.0.release-128-ubi
    helm.sh/chart: log-service-1.26.3
  name: log-service
  namespace: harness
spec:
  ports:
  - name: log-service
    port: 8079
    protocol: TCP
    targetPort: 8079
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: log-service
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2025.7.18
    helm.sh/chart: minio-17.0.15
  name: minio
  namespace: harness
spec:
  ports:
  - name: tcp-api
    nodePort: null
    port: 9000
    targetPort: api
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: minio
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: mongodb
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/version: 6.0.1
    helm.sh/chart: mongodb-13.1.2
  name: mongodb-replicaset-chart
  namespace: harness
spec:
  clusterIP: None
  ports:
  - name: mongodb
    port: 27017
    targetPort: mongodb
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: mongodb
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: mongodb
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: arbiter
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/version: 6.0.1
    helm.sh/chart: mongodb-13.1.2
  name: mongodb-replicaset-chart-arbiter-headless
  namespace: harness
spec:
  clusterIP: None
  ports:
  - name: tcp-mongodb
    port: 27017
    targetPort: mongodb
  selector:
    app.kubernetes.io/component: arbiter
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: mongodb
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: next-gen-ui
    app.kubernetes.io/version: 0.353.10
    helm.sh/chart: next-gen-ui-1.93.7
  name: next-gen-ui
  namespace: harness
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: next-gen-ui
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-auth-ui
    app.kubernetes.io/version: 0.0.1
    helm.sh/chart: ng-auth-ui-1.36.2
  name: ng-auth-ui
  namespace: harness
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: ng-auth-ui
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-dashboard-aggregator
    app.kubernetes.io/version: 0.0.80909
    helm.sh/chart: ng-dashboard-aggregator-1.70.1
  name: ng-dashboard-aggregator
  namespace: harness
spec:
  ports:
  - name: http
    port: 7100
    protocol: TCP
    targetPort: 7100
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: ng-dashboard-aggregator
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-manager
    app.kubernetes.io/version: 0.0.80209
    helm.sh/chart: ng-manager-1.107.6
  name: ng-manager
  namespace: harness
spec:
  ports:
  - name: http-ng-manager
    port: 7090
    protocol: TCP
    targetPort: 7090
  - name: grpc-ng-manager
    port: 9979
    protocol: TCP
    targetPort: 9979
  - name: grpc-git-sync
    port: 13002
    protocol: TCP
    targetPort: 13002
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: ng-manager
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-manager
    app.kubernetes.io/version: 0.0.80209
    helm.sh/chart: ng-manager-1.107.6
  name: ng-manager-headless
  namespace: harness
spec:
  clusterIP: None
  ports:
  - name: grpc-ng-manager
    port: 9979
    protocol: TCP
    targetPort: 9979
  - name: grpc-git-sync
    port: 13002
    protocol: TCP
    targetPort: 13002
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: ng-manager
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pipeline-service
    app.kubernetes.io/version: 1.41.3
    helm.sh/chart: pipeline-service-1.147.3
  name: pipeline-service
  namespace: harness
spec:
  ports:
  - name: grpc-pms
    port: 12011
    protocol: TCP
    targetPort: 12011
  - name: http-pms
    port: 12001
    protocol: TCP
    targetPort: 12001
  - name: grpc-gitsync
    port: 14002
    protocol: TCP
    targetPort: 14002
  - name: grpc-pms-sdk
    port: 15302
    protocol: TCP
    targetPort: 15302
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: pipeline-service
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pipeline-service
    app.kubernetes.io/version: 1.41.3
    helm.sh/chart: pipeline-service-1.147.3
  name: pipeline-service-headless
  namespace: harness
spec:
  clusterIP: None
  ports:
  - name: grpc-pms
    port: 12011
    protocol: TCP
    targetPort: 12011
  - name: grpc-gitsync
    port: 14002
    protocol: TCP
    targetPort: 14002
  - name: sdk-grpc-pms
    port: 15302
    protocol: TCP
    targetPort: 15302
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: pipeline-service
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: platform-service
    app.kubernetes.io/version: 0.0.80000
    helm.sh/chart: platform-service-1.84.1
  name: platform-service
  namespace: harness
spec:
  ports:
  - name: http
    port: 9005
    protocol: TCP
    targetPort: 9005
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: platform-service
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: policy-mgmt
    app.kubernetes.io/version: v1.68.0
    helm.sh/chart: policy-mgmt-1.24.4
  name: policy-mgmt
  namespace: harness
spec:
  ports:
  - name: http
    port: 3000
    protocol: TCP
    targetPort: http
  - name: metrics
    port: 3535
    protocol: TCP
    targetPort: metrics
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: policy-mgmt
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: postgres
    app.kubernetes.io/component: primary
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.2.0
    helm.sh/chart: postgresql-12.4.2
  name: postgres
  namespace: harness
spec:
  ports:
  - name: tcp-postgresql
    nodePort: null
    port: 5432
    targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/component: primary
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: postgresql
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: postgres
    app.kubernetes.io/component: primary
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.2.0
    helm.sh/chart: postgresql-12.4.2
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  name: postgres-hl
  namespace: harness
spec:
  clusterIP: None
  ports:
  - name: tcp-postgresql
    port: 5432
    targetPort: tcp-postgresql
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: primary
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: postgresql
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: queue-service
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: queue-service-1.7.4
  name: queue-service
  namespace: harness
spec:
  ports:
  - name: http
    port: 9091
    protocol: TCP
    targetPort: 9091
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: queue-service
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: redis-sentinel
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 6.2.14-alpine
    helm.sh/chart: redis-0.8.2
  name: redis-sentinel-harness
  namespace: harness
spec:
  clusterIP: None
  ports:
  - name: server
    port: 6379
    protocol: TCP
    targetPort: redis
  - name: sentinel
    port: 26379
    protocol: TCP
    targetPort: sentinel
  selector:
    app: redis-sentinel
    release: redis-ha
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  labels:
    app: redis-sentinel
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 6.2.14-alpine
    helm.sh/chart: redis-0.8.2
  name: redis-sentinel-harness-announce-0
  namespace: harness
spec:
  ports:
  - name: server
    port: 6379
    protocol: TCP
    targetPort: redis
  - name: sentinel
    port: 26379
    protocol: TCP
    targetPort: sentinel
  publishNotReadyAddresses: true
  selector:
    app: redis-sentinel
    release: redis-ha
    statefulset.kubernetes.io/pod-name: redis-sentinel-harness-server-0
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  labels:
    app: redis-sentinel
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 6.2.14-alpine
    helm.sh/chart: redis-0.8.2
  name: redis-sentinel-harness-announce-1
  namespace: harness
spec:
  ports:
  - name: server
    port: 6379
    protocol: TCP
    targetPort: redis
  - name: sentinel
    port: 26379
    protocol: TCP
    targetPort: sentinel
  publishNotReadyAddresses: true
  selector:
    app: redis-sentinel
    release: redis-ha
    statefulset.kubernetes.io/pod-name: redis-sentinel-harness-server-1
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  labels:
    app: redis-sentinel
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 6.2.14-alpine
    helm.sh/chart: redis-0.8.2
  name: redis-sentinel-harness-announce-2
  namespace: harness
spec:
  ports:
  - name: server
    port: 6379
    protocol: TCP
    targetPort: redis
  - name: sentinel
    port: 26379
    protocol: TCP
    targetPort: sentinel
  publishNotReadyAddresses: true
  selector:
    app: redis-sentinel
    release: redis-ha
    statefulset.kubernetes.io/pod-name: redis-sentinel-harness-server-2
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: scm-service
    app.kubernetes.io/version: 0.0.release-181-ubi
    helm.sh/chart: scm-service-1.40.2
  name: scm-service
  namespace: harness
spec:
  ports:
  - name: scm
    port: 8091
    protocol: TCP
    targetPort: 8091
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: scm-service
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: scm-service
    app.kubernetes.io/version: 0.0.release-181-ubi
    helm.sh/chart: scm-service-1.40.2
  name: scm-service-headless
  namespace: harness
spec:
  clusterIP: None
  ports:
  - name: scm
    port: 8091
    protocol: TCP
    targetPort: 8091
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: scm-service
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: srm-ui
    app.kubernetes.io/version: 0.6.1
    helm.sh/chart: srm-ui-1.13.1
  name: srm-ui
  namespace: harness
spec:
  ports:
  - name: http
    port: 80
    protocol: null
    targetPort: srm-ui-port
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: srm-ui
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: template-service
    app.kubernetes.io/version: 1.12.1
    helm.sh/chart: template-service-1.109.2
  name: template-service
  namespace: harness
spec:
  ports:
  - name: grpc-template
    port: 15011
    protocol: TCP
    targetPort: 15011
  - name: http-template
    port: 15002
    protocol: TCP
    targetPort: 15002
  - name: grpc-gitsync
    port: 16002
    protocol: TCP
    targetPort: 16002
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: template-service
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ti-service
    app.kubernetes.io/version: 0.0.release-223
    helm.sh/chart: ti-service-1.49.0
  name: ti-service
  namespace: harness
spec:
  ports:
  - name: ti-service
    port: 8078
    protocol: TCP
    targetPort: 8078
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: ti-service
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    app: tiemscaledb
    owner: mcintoshj@gmail.com
  name: timescaledb
  namespace: harness
spec:
  clusterIP: None
  ports:
  - port: 5432
  selector:
    app: tiemscaledb
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iac-server
    app.kubernetes.io/part-of: harness-infra-as-code
    helm.sh/chart: iac-server-1.242.0
  name: iac-server
spec:
  ports:
  - name: iac-server
    port: 8080
    protocol: TCP
    targetPort: 8080
  selector:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/name: iac-server
  type: ClusterIP
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2025.7.18
    helm.sh/chart: minio-17.0.15
  name: minio
  namespace: harness
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 200Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: tiemscaledb
  namespace: harness
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: access-control
    app.kubernetes.io/version: 1.0.79802
    helm.sh/chart: access-control-1.105.1
  name: access-control
  namespace: harness
spec:
  progressDeadlineSeconds: 720
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: access-control
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: a5561fb1252fad34f87f118f483dc7fca14dabf01fe456dd73b21296148a176c
        checksum/credentials-secret: 4d96221442f773f76a94c3790d91ecb1797bbff99270bd02dfdb7588f28b7f7d
      labels:
        app: access-control
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: access-control
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - access-control
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: GITOPS_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: GITOPS_SERVICE_SECRET
              name: access-control
        - name: IDENTITY_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: IDENTITY_SERVICE_SECRET
              name: access-control
        - name: OPA_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: OPA_SERVICE_SECRET
              name: access-control
        - name: MONGODB_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: MONGODB_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(MONGODB_USER):$(MONGODB_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/accesscontrol?authSource=admin
        - name: RESOURCEGROUPS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: RESOURCEGROUPS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: RESOURCE_GROUP_MONGO_URI
          value: mongodb://$(RESOURCEGROUPS_MONGO_USER):$(RESOURCEGROUPS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/resource-groups?authSource=admin
        envFrom:
        - configMapRef:
            name: access-control
        image: docker.io/harness/accesscontrol-service-signed:1.105.1
        imagePullPolicy: IfNotPresent
        lifecycle: null
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /api/health/liveness
            port: 9006
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        name: access-control
        ports:
        - containerPort: 9006
          name: http
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /api/health
            port: 9006
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 10
        resources:
          limits:
            memory: 8192Mi
          requests:
            cpu: 1
            memory: 712Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 32
          httpGet:
            path: /api/health
            port: 9006
          initialDelaySeconds: 25
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
        resources:
          limits:
            memory: 128Mi
          requests:
            cpu: 128m
            memory: 128Mi
      - args:
        - pod
        - -lapp=redis-sentinel
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-redis
        resources:
          limits:
            memory: 128Mi
          requests:
            cpu: 128m
            memory: 128Mi
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 180
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: change-data-capture
    app.kubernetes.io/version: 0.0.81510
    helm.sh/chart: change-data-capture-1.46.3
  name: change-data-capture
  namespace: harness
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: change-data-capture
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: change-data-capture
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: change-data-capture
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - change-data-capture
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: SOME_DEFAULT_SECRET
          valueFrom:
            secretKeyRef:
              key: SOME_DEFAULT_SECRET
              name: change-data-capture
        - name: TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: TIMESCALEDB_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: TIMESCALEDB_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        - name: HARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: HARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(HARNESS_MONGO_USER):$(HARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/harness?authSource=admin
        - name: EVENTS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: EVENTS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: EVENTS_MONGO_URI
          value: mongodb://$(EVENTS_MONGO_USER):$(EVENTS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/events?authSource=admin
        - name: PMSHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: PMSHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: PMS_MONGO_URI
          value: mongodb://$(PMSHARNESS_MONGO_USER):$(PMSHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/pms-harness?authSource=admin
        - name: CHANGEDATACAPTURE_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: CHANGEDATACAPTURE_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: CDC_MONGO_URI
          value: mongodb://$(CHANGEDATACAPTURE_MONGO_USER):$(CHANGEDATACAPTURE_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/change-data-capture?authSource=admin
        - name: NGHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: NGHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: NG_HARNESS_MONGO_URI
          value: mongodb://$(NGHARNESS_MONGO_USER):$(NGHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/ng-harness?authSource=admin
        - name: CVNGHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: CVNGHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: CVNG_MONGO_URI
          value: mongodb://$(CVNGHARNESS_MONGO_USER):$(CVNGHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/cvng-harness?authSource=admin
        - name: HARNESSCHAOS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: HARNESSCHAOS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: CHAOS_MONGO_URI
          value: mongodb://$(HARNESSCHAOS_MONGO_USER):$(HARNESSCHAOS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/harness-chaos?authSource=admin
        - name: SSCAHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: SSCAHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: SSCA_MONGO_URI
          value: mongodb://$(SSCAHARNESS_MONGO_USER):$(SSCAHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/ssca-harness?authSource=admin
        envFrom:
        - configMapRef:
            name: change-data-capture
        image: docker.io/harness/cdcdata-signed:1.46.3
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 10
          httpGet:
            path: /health
            port: 8190
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
        name: change-data-capture
        ports:
        - containerPort: 8190
        readinessProbe:
          failureThreshold: 2
          httpGet:
            path: /health
            port: 8190
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
        resources:
          limits:
            memory: 2880Mi
          requests:
            cpu: 1
            memory: 2880Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 90
          httpGet:
            path: /health
            port: 8190
          initialDelaySeconds: 0
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
        resources:
          limits:
            memory: 128Mi
          requests:
            cpu: 128m
            memory: 128Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
      - args:
        - pod
        - -lapp=ng-manager
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-ng-manager
        resources:
          limits:
            memory: 128Mi
          requests:
            cpu: 128m
            memory: 128Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 180
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ci-manager
    app.kubernetes.io/version: 0.0.5309
    helm.sh/chart: ci-manager-1.97.3
  name: ci-manager
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ci-manager
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 4a28afd55c8c87ec65c97db7257977eeb5967c1543105bf1bba17d9a625e8605
      labels:
        app: ci-manager
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: ci-manager
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - ci-manager
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: STO_SERVICE_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: stoAppHarnessToken
              name: harness-secrets
        - name: TI_SERVICE_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: TI_SERVICE_GLOBAL_TOKEN
              name: ci-manager
        - name: CACHE_SERVICE_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: CACHE_SERVICE_GLOBAL_TOKEN
              name: ci-manager
        - name: HSQS_AUTH_TOKEN
          valueFrom:
            secretKeyRef:
              key: HSQS_AUTH_TOKEN
              name: ci-manager
        - name: JWT_DATA_HANDLER_SECRET
          valueFrom:
            secretKeyRef:
              key: JWT_DATA_HANDLER_SECRET
              name: ci-manager
        - name: LOG_SERVICE_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: LOG_SERVICE_GLOBAL_TOKEN
              name: ci-manager
        - name: OPA_SERVER_SECRET
          valueFrom:
            secretKeyRef:
              key: OPA_SERVER_SECRET
              name: ci-manager
        - name: SPLIT_TOKEN
          valueFrom:
            secretKeyRef:
              key: SPLIT_TOKEN
              name: ci-manager
        - name: TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: TIMESCALE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: TIMESCALE_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        - name: HARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: HARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(HARNESS_MONGO_USER):$(HARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/harness?authSource=admin
        - name: HARNESSCI_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: HARNESSCI_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: CIMANAGER_MONGO_URI
          value: mongodb://$(HARNESSCI_MONGO_USER):$(HARNESSCI_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/harness-ci?authSource=admin
        - name: PMSHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: PMSHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: PMS_MONGO_URI
          value: mongodb://$(PMSHARNESS_MONGO_USER):$(PMSHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/pms-harness?authSource=admin
        envFrom:
        - configMapRef:
            name: ci-manager
        image: docker.io/harness/ci-manager-signed:1.97.3
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 20
          httpGet:
            path: /health/liveness
            port: http-ci-manager
          initialDelaySeconds: 40
          periodSeconds: 10
          timeoutSeconds: 5
        name: ci-manager
        ports:
        - containerPort: 7090
          name: http-ci-manager
          protocol: TCP
        - containerPort: 9979
          name: grpc-ci-manager
          protocol: TCP
        readinessProbe:
          failureThreshold: 8
          httpGet:
            path: /health
            port: http-ci-manager
          initialDelaySeconds: 60
          periodSeconds: 5
          timeoutSeconds: 5
        resources:
          limits:
            memory: 8192Mi
          requests:
            cpu: 1
            memory: 1400Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
      imagePullSecrets:
      - name: regcred
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      - args:
        - pod
        - -lapp=pipeline-service
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-pipeline-service
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 180
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: cv-nextgen
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: cv-nextgen
    app.kubernetes.io/version: 1.9.0
    helm.sh/chart: cv-nextgen-1.44.0
  name: cv-nextgen
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: cv-nextgen
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 2cba071b6fb8c67e2faeac4c1aca98852af57364ba1b581e0fb5d67ca47d90cd
        prometheus.io/path: /cv/api/metrics
        prometheus.io/port: "8889"
        prometheus.io/scrape: "true"
      labels:
        app: cv-nextgen
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: cv-nextgen
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - cv-nextgen
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: VERIFICATION_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: VERIFICATION_SERVICE_SECRET
              name: cv-nextgen
        - name: TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: TIMESCALE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: TIMESCALE_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        - name: CVNGHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: CVNGHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(CVNGHARNESS_MONGO_USER):$(CVNGHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/cvng-harness?authSource=admin
        - name: NOTIFICATIONS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: NOTIFICATIONS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: NOTIFICATION_MONGO_URI
          value: mongodb://$(NOTIFICATIONS_MONGO_USER):$(NOTIFICATIONS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/notifications?authSource=admin
        envFrom:
        - configMapRef:
            name: cv-nextgen
        image: docker.io/harness/cv-nextgen-signed:1.44.0
        imagePullPolicy: IfNotPresent
        lifecycle: null
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /cv/api/health/ping
            port: 6060
            scheme: HTTP
          initialDelaySeconds: 300
          periodSeconds: 60
          timeoutSeconds: 10
        name: cv-nextgen
        ports:
        - containerPort: 8889
          name: metrics
          protocol: TCP
        - containerPort: 6060
          name: cv
          protocol: TCP
        - containerPort: 9979
          name: grpc-cv-ng
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /cv/api/health
            port: 6060
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 5
          timeoutSeconds: 3
        resources:
          limits:
            memory: 6144Mi
          requests:
            cpu: 1
            memory: 6144Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=harness-manager
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-harness-manager
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 30
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: delegate-proxy
    app.kubernetes.io/version: 0.0.80104
    helm.sh/chart: delegate-proxy-1.3.0
  name: delegate-proxy
  namespace: harness
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: delegate-proxy
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: delegate-proxy
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: delegate-proxy
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - delegate-proxy
            topologyKey: kubernetes.io/hostname
      containers:
      - image: docker.io/harness/delegate-proxy-signed:1.3.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        name: delegate-proxy
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            memory: 100Mi
          requests:
            cpu: 200m
            memory: 100Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        volumeMounts:
        - mountPath: /etc/nginx/conf.d
          name: harness-nginx-conf
      securityContext: {}
      serviceAccountName: harness-default
      volumes:
      - configMap:
          items:
          - key: proxy.conf
            path: proxy.conf
          name: delegate-proxy
        name: harness-nginx-conf
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gateway
    app.kubernetes.io/version: 0.0.11401
    helm.sh/chart: gateway-1.54.7
  name: gateway
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: gateway
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: eb8867d1f07cfab54bfcb63315690e49d08f0d41e62659a75dfb7583df554ec4
      labels:
        app: gateway
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: gateway
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - gateway
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: GATEWAY_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: GATEWAY_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_DB_URL
          value: mongodb://$(GATEWAY_MONGO_USER):$(GATEWAY_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/gateway?authSource=admin
        - name: TI_SVC_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: TI_SVC_GLOBAL_TOKEN
              name: gateway
        - name: JWT_ADMIN_PORTAL_SECRET
          valueFrom:
            secretKeyRef:
              key: JWT_ADMIN_PORTAL_SECRET
              name: gateway
        - name: JWT_DATA_HANDLER_SECRET
          valueFrom:
            secretKeyRef:
              key: JWT_DATA_HANDLER_SECRET
              name: gateway
        - name: LOG_SVC_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: LOG_SVC_GLOBAL_TOKEN
              name: gateway
        envFrom:
        - configMapRef:
            name: gateway
        image: docker.io/harness/gateway-signed:1.54.7
        imagePullPolicy: IfNotPresent
        lifecycle: null
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /api/liveness
            port: gateway-port
            scheme: HTTP
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        name: gateway
        ports:
        - containerPort: 8080
          name: gateway-port
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /actuator/health
            port: gateway-port
            scheme: HTTP
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            memory: 2Gi
          requests:
            cpu: 0.5
            memory: 2Gi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 32
          httpGet:
            path: /actuator/health
            port: gateway-port
            scheme: HTTP
          initialDelaySeconds: 25
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 30
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gitops
    app.kubernetes.io/version: v0.81.3
    helm.sh/chart: gitops-1.41.5
  name: gitops
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: gitops
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        rollme: 5axef
      labels:
        app: gitops
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: gitops
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - gitops
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: IDENTITY_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: IDENTITY_SERVICE_SECRET
              name: gitops
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              key: JWT_SECRET
              name: gitops
        - name: MANAGER_JWT_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              key: MANAGER_JWT_AUTH_SECRET
              name: gitops
        - name: PLATFORMSERVICE_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              key: PLATFORMSERVICE_AUTH_SECRET
              name: gitops
        - name: PLATFORM_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              key: PLATFORM_AUTH_SECRET
              name: gitops
        - name: ACL_SECRET
          valueFrom:
            secretKeyRef:
              key: ACL_SECRET
              name: gitops
        - name: GITOPS_SERVICE_TIMESCALE_USER_NAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: GITOPS_SERVICE_TIMESCALE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: GITOPS_SERVICE_TIMESCALE_URL
          value: postgres://$(GITOPS_SERVICE_TIMESCALE_USER_NAME):$(GITOPS_SERVICE_TIMESCALE_PASSWORD)@timescaledb:5432/harness_gitops?sslmode=disable
        - name: HARNESSGITOPS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: HARNESSGITOPS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: GITOPS_SERVICE_MONGODB_URL
          value: mongodb://$(HARNESSGITOPS_MONGO_USER):$(HARNESSGITOPS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/harness-gitops?authSource=admin
        envFrom:
        - configMapRef:
            name: gitops
        image: docker.io/harness/gitops-service-signed:1.41.5
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 7908
          initialDelaySeconds: 3
          periodSeconds: 30
        name: gitops
        ports:
        - containerPort: 7908
          name: gitops-http
          protocol: TCP
        - containerPort: 7909
          name: gitops-grpc
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 7908
          initialDelaySeconds: 3
          periodSeconds: 30
        resources:
          limits:
            memory: 256Mi
          requests:
            cpu: 2
            memory: 256Mi
        securityContext: {}
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 30
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-manager
    app.kubernetes.io/version: 0.0.81725
    helm.sh/chart: harness-manager-1.105.3
  name: harness-manager
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: harness-manager
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        rollme: j0JCt
      labels:
        app: harness-manager
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: harness-manager
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - harness-manager
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: LOG_STREAMING_SERVICE_TOKEN
          valueFrom:
            secretKeyRef:
              key: LOG_STREAMING_SERVICE_TOKEN
              name: harness-manager
        - name: VERIFICATION_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: VERIFICATION_SERVICE_SECRET
              name: harness-manager
        - name: CF_CLIENT_API_KEY
          valueFrom:
            secretKeyRef:
              key: CF_CLIENT_API_KEY
              name: harness-manager
        - name: TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: TIMESCALEDB_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: SECONDARY_TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: SECONDARY_TIMESCALEDB_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: NOTIFICATIONS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: NOTIFICATIONS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: NOTIFICATION_MONGO_URI
          value: mongodb://$(NOTIFICATIONS_MONGO_USER):$(NOTIFICATIONS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/notifications?authSource=admin
        - name: HARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: HARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(HARNESS_MONGO_USER):$(HARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/harness?authSource=admin
        - name: EVENTS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: EVENTS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: EVENTS_MONGO_URI
          value: mongodb://$(EVENTS_MONGO_USER):$(EVENTS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/events?authSource=admin
        - name: DMSHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: DMSHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: DMS_MONGO_URI
          value: mongodb://$(DMSHARNESS_MONGO_USER):$(DMSHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/dms-harness?authSource=admin
        - name: ENABLE_ITERATORS
          value: "true"
        - name: TIMESCALEDB_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        - name: SECONDARY_TIMESCALEDB_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        envFrom:
        - configMapRef:
            name: harness-manager-config
        image: docker.io/harness/manager-signed:1.105.3
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - |
                touch shutdown; sleep 60;
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /admin/healthcheck/liveness
            port: 7458
            scheme: HTTP
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        name: manager
        ports:
        - containerPort: 9879
          name: grpc-manager
          protocol: TCP
        - containerPort: 9090
          name: manager
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /api/health
            port: 9090
            scheme: HTTP
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            memory: 8192Mi
          requests:
            cpu: 2
            memory: 3072Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 50
          httpGet:
            path: /api/health
            port: 9090
            scheme: HTTP
          initialDelaySeconds: 25
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /opt/harness/config
          name: dynamic-iterator-config
      imagePullSecrets:
      - name: regcred
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      - args:
        - pod
        - -lapp=redis-sentinel
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-redis
      serviceAccountName: harness-manager
      terminationGracePeriodSeconds: 180
      volumes:
      - configMap:
          defaultMode: 420
          name: iterator-config
        name: dynamic-iterator-config
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: iacm-manager
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iacm-manager
    app.kubernetes.io/part-of: harness-infra-as-code
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: iacm-manager-1.100.1
  name: iacm-manager
  namespace: harness
spec:
  progressDeadlineSeconds: 300
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: iacm-manager
  template:
    metadata:
      annotations:
        checksum/config: 5d6e147a8770d6887fac145862e078862801d85435e59d8f0eae2a22c0490863
      labels:
        app.kubernetes.io/component: admin
        app.kubernetes.io/instance: harness
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: iacm-manager
        app.kubernetes.io/part-of: harness-infra-as-code
        app.kubernetes.io/version: 1.16.0
        helm.sh/chart: iacm-manager-1.100.1
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - iacm-manager
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: VERIFICATION_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: VERIFICATION_SERVICE_SECRET
              name: iacm-manager
        - name: STO_SERVICE_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: stoAppHarnessToken
              name: harness-secrets
        - name: TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: TIMESCALE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: TIMESCALE_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        - name: HARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: HARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(HARNESS_MONGO_USER):$(HARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/harness?authSource=admin
        - name: HARNESSIACM_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: HARNESSIACM_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: IACMMANAGER_MONGO_URI
          value: mongodb://$(HARNESSIACM_MONGO_USER):$(HARNESSIACM_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/harness-iacm?authSource=admin
        envFrom:
        - configMapRef:
            name: iacm-manager
        image: docker.io/harness/iacm-manager-signed:1.100.1
        imagePullPolicy: IfNotPresent
        lifecycle: null
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /health/liveness
            port: iacm-manager
          initialDelaySeconds: 40
          periodSeconds: 5
          timeoutSeconds: 2
        name: iacm-manager
        ports:
        - containerPort: 7090
          name: iacm-manager
          protocol: TCP
        - containerPort: 9979
          name: iacm-mgr-grpc
          protocol: TCP
        - containerPort: 8889
          name: metrics
          protocol: TCP
        readinessProbe:
          failureThreshold: 5
          httpGet:
            path: /health
            port: iacm-manager
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 2
        resources:
          limits:
            ephemeral-storage: 250M
            memory: 5G
          requests:
            cpu: 1
            ephemeral-storage: 250M
            memory: 5G
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 25
          httpGet:
            path: /health
            port: iacm-manager
          periodSeconds: 10
          timeoutSeconds: 2
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      - args:
        - pod
        - -lapp=pipeline-service
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-pipeline-service
      securityContext:
        fsGroup: 65534
      serviceAccountName: iacm-manager
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: le-nextgen
    app.kubernetes.io/version: 0.0.68305
    helm.sh/chart: le-nextgen-1.10.0
  name: le-nextgen
  namespace: harness
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: le-nextgen
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: le-nextgen
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: le-nextgen
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - le-nextgen
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: service_secret
          valueFrom:
            secretKeyRef:
              key: VERIFICATION_SERVICE_SECRET
              name: le-nextgen
        envFrom:
        - configMapRef:
            name: le-nextgen
        image: docker.io/harness/le-nextgen-signed:1.10.0
        imagePullPolicy: IfNotPresent
        name: le-nextgen
        ports:
        - containerPort: 8108
          name: learning
          protocol: TCP
        resources:
          limits:
            memory: 6144Mi
          requests:
            cpu: 1
            memory: 6144Mi
        securityContext:
          runAsNonRoot: true
        volumeMounts: null
      serviceAccountName: harness-default
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: le-nextgen
    app.kubernetes.io/version: 0.0.68305
    helm.sh/chart: le-nextgen-1.10.0
  name: le-nextgen-srm
  namespace: harness
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: le-nextgen
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: le-nextgen
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: le-nextgen
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - le-nextgen
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: service_secret
          valueFrom:
            secretKeyRef:
              key: VERIFICATION_SERVICE_SECRET
              name: le-nextgen
        envFrom:
        - configMapRef:
            name: le-nextgen-srm
        image: docker.io/harness/le-nextgen-signed:1.10.0
        imagePullPolicy: IfNotPresent
        name: le-nextgen
        ports:
        - containerPort: 8108
          name: learning
          protocol: TCP
        resources:
          limits:
            memory: 6144Mi
          requests:
            cpu: 1
            memory: 6144Mi
        securityContext:
          runAsNonRoot: true
        volumeMounts: null
      serviceAccountName: harness-default
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: log-service
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: log-service
    app.kubernetes.io/version: 0.0.release-128-ubi
    helm.sh/chart: log-service-1.26.3
  name: log-service
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: log-service
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: log-service
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: log-service
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - log-service
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: LOG_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: LOG_SERVICE_SECRET
              name: log-service
        - name: LOG_SERVICE_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: LOG_SERVICE_GLOBAL_TOKEN
              name: log-service
        - name: LOG_SERVICE_S3_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              key: root-user
              name: minio
        - name: LOG_SERVICE_S3_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              key: root-password
              name: minio
        envFrom:
        - configMapRef:
            name: log-service
        image: docker.io/harness/log-service-signed:1.26.3
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: http-log-svc
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 10
        name: log-service
        ports:
        - containerPort: 8079
          name: http-log-svc
          protocol: TCP
        readinessProbe:
          failureThreshold: 5
          httpGet:
            path: /ready/healthz
            port: http-log-svc
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 10
        resources:
          limits:
            memory: 1Gi
          requests:
            cpu: 500m
            memory: 1Gi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        volumeMounts: null
      initContainers: null
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 180
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2025.7.18
    helm.sh/chart: minio-17.0.15
  name: minio
  namespace: harness
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: minio
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: harness
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: minio
        app.kubernetes.io/version: 2025.7.18
        helm.sh/chart: minio-17.0.15
    spec:
      affinity:
        nodeAffinity: null
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/instance: harness
                  app.kubernetes.io/name: minio
              topologyKey: kubernetes.io/hostname
            weight: 1
      automountServiceAccountToken: false
      containers:
      - env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: MINIO_DISTRIBUTED_MODE_ENABLED
          value: "no"
        - name: MINIO_SCHEME
          value: http
        - name: MINIO_FORCE_NEW_KEYS
          value: "no"
        - name: MINIO_ROOT_USER_FILE
          value: /opt/bitnami/minio/secrets/root-user
        - name: MINIO_ROOT_PASSWORD_FILE
          value: /opt/bitnami/minio/secrets/root-password
        - name: MINIO_SKIP_CLIENT
          value: "no"
        - name: MINIO_DEFAULT_BUCKETS
          value: logs, sbom-store, policy-store, iro-thanos-store, metrics-store
        - name: MINIO_API_PORT_NUMBER
          value: "9000"
        - name: MINIO_BROWSER
          value: "off"
        - name: MINIO_PROMETHEUS_AUTH_TYPE
          value: public
        - name: MINIO_DATA_DIR
          value: /bitnami/minio/data
        image: docker.io/bitnamilegacy/minio:2025.7.18-debian-12-r0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /minio/health/live
            port: api
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 5
        name: minio
        ports:
        - containerPort: 9000
          name: api
        readinessProbe:
          failureThreshold: 5
          initialDelaySeconds: 5
          periodSeconds: 5
          successThreshold: 1
          tcpSocket:
            port: api
          timeoutSeconds: 1
        resources:
          limits:
            memory: 1024Mi
          requests:
            cpu: 2
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          readOnlyRootFilesystem: true
          runAsGroup: 1001
          runAsNonRoot: true
          runAsUser: 1001
          seccompProfile:
            type: RuntimeDefault
        volumeMounts:
        - mountPath: /tmp
          name: empty-dir
          subPath: tmp-dir
        - mountPath: /opt/bitnami/minio/tmp
          name: empty-dir
          subPath: app-tmp-dir
        - mountPath: /.mc
          name: empty-dir
          subPath: app-mc-dir
        - mountPath: /opt/bitnami/minio/secrets/
          name: minio-credentials
        - mountPath: /bitnami/minio/data
          name: data
      initContainers: null
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: OnRootMismatch
        supplementalGroups: []
        sysctls: []
      serviceAccountName: minio
      volumes:
      - emptyDir: {}
        name: empty-dir
      - name: minio-credentials
        secret:
          secretName: minio
      - name: data
        persistentVolumeClaim:
          claimName: minio
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: next-gen-ui
    app.kubernetes.io/version: 0.353.10
    helm.sh/chart: next-gen-ui-1.93.7
  name: next-gen-ui
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: next-gen-ui
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 86b6d7e905e98e9ddddddc367af125ff52f5658bb92dcd5cc2937b0431b1ea0d
      labels:
        app: next-gen-ui
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: next-gen-ui
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - next-gen-ui
            topologyKey: kubernetes.io/hostname
      containers:
      - env: null
        envFrom:
        - configMapRef:
            name: next-gen-ui
        image: docker.io/harness/nextgenui-signed:1.93.7
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /health
            port: ng-ui-port
          periodSeconds: 10
        name: next-gen-ui
        ports:
        - containerPort: 8080
          name: ng-ui-port
          protocol: TCP
        readinessProbe:
          failureThreshold: 5
          httpGet:
            path: /health
            port: ng-ui-port
          periodSeconds: 10
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 0.2
            memory: 200Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 30
          httpGet:
            path: /health
            port: ng-ui-port
          periodSeconds: 10
        volumeMounts: null
      initContainers: null
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 30
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-auth-ui
    app.kubernetes.io/version: 0.0.1
    helm.sh/chart: ng-auth-ui-1.36.2
  name: ng-auth-ui
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ng-auth-ui
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 404afaf65a98e0df16a31f2d1113c8b59618e8d5ab3f9b356adf4e31cacce98e
      labels:
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: ng-auth-ui
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - ng-auth-ui
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: INVISIBLE_CAPTCHA_TOKEN
          valueFrom:
            secretKeyRef:
              key: INVISIBLE_CAPTCHA_TOKEN
              name: ng-auth-ui
        - name: CAPTCHA_TOKEN
          valueFrom:
            secretKeyRef:
              key: CAPTCHA_TOKEN
              name: ng-auth-ui
        envFrom:
        - configMapRef:
            name: ng-auth-ui
        image: docker.io/harness/ng-auth-ui-signed:1.36.2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 2
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 90
          periodSeconds: 20
        name: ng-auth-ui
        ports:
        - containerPort: 8080
          name: ng-auth-ui-port
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 10
        resources:
          limits:
            cpu: 0.5
            memory: 512Mi
          requests:
            cpu: 0.5
            memory: 512Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        volumeMounts: null
      initContainers: null
      securityContext: {}
      serviceAccountName: harness-default
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-dashboard-aggregator
    app.kubernetes.io/version: 0.0.80909
    helm.sh/chart: ng-dashboard-aggregator-1.70.1
  name: ng-dashboard-aggregator
  namespace: harness
spec:
  progressDeadlineSeconds: 800
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ng-dashboard-aggregator
  template:
    metadata:
      annotations: null
      labels:
        app: ng-dashboard-aggregator
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: ng-dashboard-aggregator
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - ng-dashboard-aggregator
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: CONTAINER_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        envFrom:
        - configMapRef:
            name: ng-dashboard-aggregator
        image: docker.io/harness/ng-dashboard-aggregator-signed:1.70.1
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: dashbrd-port
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 10
        name: ng-dashboard-aggregator
        ports:
        - containerPort: 7100
          name: dashbrd-port
          protocol: TCP
        readinessProbe:
          failureThreshold: 10
          httpGet:
            path: /health
            port: dashbrd-port
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 10
        resources:
          limits:
            memory: 4096Mi
          requests:
            cpu: 1
            memory: 4096Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        volumeMounts: null
      initContainers: null
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 180
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: ng-manager
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-manager
    app.kubernetes.io/version: 0.0.80209
    helm.sh/chart: ng-manager-1.107.6
  name: ng-manager
  namespace: harness
spec:
  progressDeadlineSeconds: 800
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ng-manager
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: d578b610f4e751c67c595a366c70ef1f25c9743c9943a3b209edc328db5aae91
      labels:
        app: ng-manager
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: ng-manager
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - ng-manager
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: STRIPE_API_KEY
          valueFrom:
            secretKeyRef:
              key: STRIPE_API_KEY
              name: ng-manager
        - name: DEVOPS_STRIPE_API_KEY
          valueFrom:
            secretKeyRef:
              key: DEVOPS_STRIPE_API_KEY
              name: ng-manager
        - name: GITOPS_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: GITOPS_SERVICE_SECRET
              name: ng-manager
        - name: HSQS_AUTH_TOKEN
          valueFrom:
            secretKeyRef:
              key: HSQS_AUTH_TOKEN
              name: ng-manager
        - name: LOG_STREAMING_SERVICE_TOKEN
          valueFrom:
            secretKeyRef:
              key: LOG_STREAMING_SERVICE_TOKEN
              name: ng-manager
        - name: OPA_SERVER_SECRET
          valueFrom:
            secretKeyRef:
              key: OPA_SERVER_SECRET
              name: ng-manager
        - name: ENABLE_SMP_LICENSING
          value: "true"
        - name: SMP_LICENSE
          valueFrom:
            secretKeyRef:
              key: NG_LICENSE
              name: harness-license
        - name: TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: TIMESCALE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: SECONDARY_TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: SECONDARY_TIMESCALE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: TIMESCALE_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        - name: SECONDARY_TIMESCALE_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        - name: NGHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: NGHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(NGHARNESS_MONGO_USER):$(NGHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/ng-harness?authSource=admin
        - name: NOTIFICATIONS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: NOTIFICATIONS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: NOTIFICATION_MONGO_URI
          value: mongodb://$(NOTIFICATIONS_MONGO_USER):$(NOTIFICATIONS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/notifications?authSource=admin
        - name: SMP_VERSION
          valueFrom:
            configMapKeyRef:
              key: SMP_VERSION
              name: global-smp-config
              optional: true
        envFrom:
        - configMapRef:
            name: ng-manager
        image: docker.io/harness/ng-manager-signed:1.107.6
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - "touch shutdown; sleep 60; \n"
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /admin/healthcheck/liveness
            port: 7458
            scheme: HTTP
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        name: ng-manager
        ports:
        - containerPort: 7090
          name: http-ng-manager
          protocol: TCP
        - containerPort: 9979
          name: grpc-ng-manager
          protocol: TCP
        - containerPort: 13002
          name: grpc-git-sync
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: http-ng-manager
            scheme: HTTP
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            memory: 8192Mi
          requests:
            cpu: 2
            memory: 200Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 40
          httpGet:
            path: /health
            port: http-ng-manager
            scheme: HTTP
          initialDelaySeconds: 25
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /opt/harness/config
          name: oidc-config
        - mountPath: /opt/harness/devops
          name: devops-essentials-config
        - mountPath: /opt/harness/cgi-config
          name: cgi-config
      imagePullSecrets:
      - name: regcred
      initContainers:
      - args:
        - pod
        - -lapp=harness-manager
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-harness-manager
      - args:
        - pod
        - -lapp=pipeline-service
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-pipeline-service
      securityContext: {}
      serviceAccountName: ng-manager
      terminationGracePeriodSeconds: 180
      volumes:
      - configMap:
          name: oidc-config-ng-manager
        name: oidc-config
      - configMap:
          name: devops-essentials-config-ng-manager
        name: devops-essentials-config
      - configMap:
          name: cgi-config-ng-manager
        name: cgi-config
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: pipeline-service
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pipeline-service
    app.kubernetes.io/version: 1.41.3
    helm.sh/chart: pipeline-service-1.147.3
  name: pipeline-service
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: pipeline-service
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 67cc63a645509d41d0c3a0dbcd45550bd4fb48ba91212e1a2c33b484f59fa2fe
      labels:
        app: pipeline-service
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: pipeline-service
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - pipeline-service
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: CONTAINER_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: CF_CLIENT_API_KEY
          valueFrom:
            secretKeyRef:
              key: CF_CLIENT_API_KEY
              name: pipeline-service
        - name: LOG_STREAMING_SERVICE_TOKEN
          valueFrom:
            secretKeyRef:
              key: LOG_STREAMING_SERVICE_TOKEN
              name: pipeline-service
        - name: OPA_SERVER_SECRET
          valueFrom:
            secretKeyRef:
              key: OPA_SERVER_SECRET
              name: pipeline-service
        - name: STO_SERVICE_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: stoAppHarnessToken
              name: harness-secrets
        - name: TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: TIMESCALE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: SECONDARY_TIMESCALEDB_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: SECONDARY_TIMESCALE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: TIMESCALE_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        - name: SECONDARY_TIMESCALE_URI
          value: jdbc:postgresql://timescaledb:5432/harness
        - name: PMSHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: PMSHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(PMSHARNESS_MONGO_USER):$(PMSHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/pms-harness?authSource=admin
        - name: NOTIFICATIONS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: NOTIFICATIONS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: NOTIFICATION_MONGO_URI
          value: mongodb://$(NOTIFICATIONS_MONGO_USER):$(NOTIFICATIONS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/notifications?authSource=admin
        envFrom:
        - configMapRef:
            name: pipeline-service
        image: docker.io/harness/pipeline-service-signed:1.147.3
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - "touch shutdown; sleep 60; \n"
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /api/health/liveness
            port: http-pms
            scheme: HTTP
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        name: pipeline-service
        ports:
        - containerPort: 12011
          name: grpc-pms
          protocol: TCP
        - containerPort: 12001
          name: http-pms
          protocol: TCP
        - containerPort: 14002
          name: grpc-gitsync
          protocol: TCP
        - containerPort: 15302
          name: pms-sdk-grpc
          protocol: TCP
        readinessProbe:
          failureThreshold: 10
          httpGet:
            path: /api/health
            port: http-pms
            scheme: HTTP
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            memory: 6144Mi
          requests:
            cpu: 1
            memory: 6144Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 30
          httpGet:
            path: /api/health
            port: http-pms
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
      imagePullSecrets:
      - name: regcred
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 180
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: platform-service
    app.kubernetes.io/version: 0.0.80000
    helm.sh/chart: platform-service-1.84.1
  name: platform-service
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: platform-service
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: c2e984910ea661a3aa1c22c8e0189ce14884dbe6165c0f47cfa516cca7ac9dd9
      labels:
        app: platform-service
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: platform-service
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - platform-service
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: CF_CLIENT_API_KEY
          valueFrom:
            secretKeyRef:
              key: CF_CLIENT_API_KEY
              name: platform-service
        - name: ET_AGENT_TOKEN
          valueFrom:
            secretKeyRef:
              key: ET_AGENT_TOKEN
              name: platform-service
        - name: PIPELINE_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: PIPELINE_SERVICE_SECRET
              name: platform-service
        - name: TEMPLATE_SERVICE_SECRET
          valueFrom:
            secretKeyRef:
              key: TEMPLATE_SERVICE_SECRET
              name: platform-service
        - name: NOTIFICATIONS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: NOTIFICATIONS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(NOTIFICATIONS_MONGO_USER):$(NOTIFICATIONS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/notifications?authSource=admin
        - name: STREAMING_MANAGER_MONGO_URI
          value: mongodb://$(NOTIFICATIONS_MONGO_USER):$(NOTIFICATIONS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/notifications?authSource=admin
        - name: AUDITS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: AUDITS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: AUDIT_MONGO_URI
          value: mongodb://$(AUDITS_MONGO_USER):$(AUDITS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/audits?authSource=admin
        - name: RESOURCEGROUPS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: RESOURCEGROUPS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: RESOURCE_GROUP_MONGO_URI
          value: mongodb://$(RESOURCEGROUPS_MONGO_USER):$(RESOURCEGROUPS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/resource-groups?authSource=admin
        envFrom:
        - configMapRef:
            name: platform-service
        image: docker.io/harness/platform-service-signed:1.84.1
        imagePullPolicy: IfNotPresent
        lifecycle: null
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /api/admin/healthcheck/liveness
            port: 7458
            scheme: HTTP
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        name: platform-service
        ports:
        - containerPort: 9005
          name: http
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /api/health
            port: 9005
            scheme: HTTP
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            memory: 8192Mi
          requests:
            cpu: 0.5
            memory: 1024Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 32
          httpGet:
            path: /api/health
            port: 9005
            scheme: HTTP
          initialDelaySeconds: 25
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      securityContext: {}
      serviceAccountName: harness-platform-service
      terminationGracePeriodSeconds: 180
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: policy-mgmt
    app.kubernetes.io/version: v1.68.0
    helm.sh/chart: policy-mgmt-1.24.4
  name: policy-mgmt
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: policy-mgmt
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations: null
      labels:
        app: policy-mgmt
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: policy-mgmt
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - policy-mgmt
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: APP_DATABASE_USER
          value: postgres
        - name: APP_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: postgres-password
              name: postgres
        - name: APP_DATABASE_DATASOURCE
          value: host=postgres port=5432 dbname=$(APP_DATABASE_DBNAME) user=DBUSER
            password=DBPASSWORD sslmode=disable
        - name: PG_SSLMODE
          value: disable
        - name: APP_NEXT_GEN_MANAGER_JWT_SECRET
          valueFrom:
            secretKeyRef:
              key: APP_NEXT_GEN_MANAGER_JWT_SECRET
              name: policy-mgmt
        - name: APP_TOKEN_JWT_SECRET
          valueFrom:
            secretKeyRef:
              key: APP_TOKEN_JWT_SECRET
              name: policy-mgmt
        - name: HARNESS_SERVICES_PIPELINE_JWT_SECRET
          valueFrom:
            secretKeyRef:
              key: HARNESS_SERVICES_PIPELINE_JWT_SECRET
              name: policy-mgmt
        - name: APP_INTERNAL_TOKEN_JWT_SECRET
          valueFrom:
            secretKeyRef:
              key: APP_INTERNAL_TOKEN_JWT_SECRET
              name: policy-mgmt
        envFrom:
        - configMapRef:
            name: policy-mgmt
        image: docker.io/harness/policy-mgmt:1.24.4
        imagePullPolicy: Always
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /api/v1/system/health
            port: http
            scheme: HTTP
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 10
        name: policy-mgmt
        ports:
        - containerPort: 3000
          name: http
          protocol: TCP
        readinessProbe:
          failureThreshold: 10
          httpGet:
            path: /api/v1/system/health
            port: http
            scheme: HTTP
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            memory: 512Mi
          requests:
            cpu: 500m
            memory: 512Mi
        startupProbe:
          failureThreshold: 30
          httpGet:
            path: /api/v1/system/health
            port: http
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 1
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=postgres
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-postgres
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 30
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: queue-service
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: queue-service
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: queue-service-1.7.4
  name: queue-service
  namespace: harness
spec:
  progressDeadlineSeconds: 300
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: queue-service
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
  template:
    metadata:
      annotations: null
      labels:
        app: queue-service
        app.kubernetes.io/instance: harness
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: queue-service
        app.kubernetes.io/version: 1.16.0
        helm.sh/chart: queue-service-1.7.4
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - queue-service
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              key: JWT_SECRET
              name: queue-service
        envFrom:
        - configMapRef:
            name: queue-service
        image: docker.io/harness/queue-service-signed:1.7.4
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 10
          httpGet:
            path: /v1/healthz
            port: 9091
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 10
        name: queue-service
        ports:
        - containerPort: 9091
          name: http
          protocol: TCP
        readinessProbe:
          failureThreshold: 10
          httpGet:
            path: /v1/healthz
            port: 9091
            scheme: HTTP
          periodSeconds: 5
          timeoutSeconds: 5
        resources:
          limits:
            memory: 250M
          requests:
            cpu: 100m
            memory: 250M
        startupProbe:
          failureThreshold: 10
          httpGet:
            path: /v1/healthz
            port: 9091
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 5
        volumeMounts: null
      initContainers: null
      serviceAccountName: harness-queue-service
      terminationGracePeriodSeconds: 30
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: scm-service
    app.kubernetes.io/version: 0.0.release-181-ubi
    helm.sh/chart: scm-service-1.40.2
  name: scm
  namespace: harness
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: scm-service
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: scm-service
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: scm-service
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - scm-service
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: FIPS_ENABLED
          value: "false"
        image: docker.io/harness/ci-scm-signed:1.40.2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - /grpc_health_probe
            - -addr=:8091
          initialDelaySeconds: 10
        name: scm
        ports:
        - containerPort: 8091
          name: scm
          protocol: TCP
        readinessProbe:
          exec:
            command:
            - /grpc_health_probe
            - -addr=:8091
          initialDelaySeconds: 5
        resources:
          limits:
            memory: 512Mi
          requests:
            cpu: 0.5
            memory: 512Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
      initContainers: null
      securityContext: {}
      serviceAccountName: harness-default
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: srm-ui
    app.kubernetes.io/version: 0.6.1
    helm.sh/chart: srm-ui-1.13.1
  name: srm-ui
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: srm-ui
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: srm-ui
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: srm-ui
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - srm-ui
            topologyKey: kubernetes.io/hostname
      containers:
      - envFrom:
        - configMapRef:
            name: srm-ui
        image: docker.io/harness/srm-ui-signed:1.13.1
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 2
          httpGet:
            path: /health
            port: srm-ui-port
          initialDelaySeconds: 100
          periodSeconds: 20
        name: srm-ui
        ports:
        - containerPort: 8189
          name: srm-ui-port
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /health
            port: srm-ui-port
          initialDelaySeconds: 15
          periodSeconds: 10
        resources:
          limits:
            memory: 250M
          requests:
            cpu: 25m
            memory: 250M
        securityContext: {}
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 30
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: template-service
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: template-service
    app.kubernetes.io/version: 1.12.1
    helm.sh/chart: template-service-1.109.2
  name: template-service
  namespace: harness
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: template-service
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 8781cf260baf547e704a5785285427ef907ec205b00d214c9ae470eed05f0d0b
      labels:
        app: template-service
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: template-service
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - template-service
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: CONTAINER_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: OPA_SERVER_SECRET
          valueFrom:
            secretKeyRef:
              key: OPA_SERVER_SECRET
              name: template-service
        - name: TEMPLATEHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: TEMPLATEHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(TEMPLATEHARNESS_MONGO_USER):$(TEMPLATEHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/template-harness?authSource=admin
        envFrom:
        - configMapRef:
            name: template-service
        image: docker.io/harness/template-service-signed:1.109.2
        imagePullPolicy: IfNotPresent
        lifecycle: null
        livenessProbe:
          failureThreshold: 20
          httpGet:
            path: /api/health
            port: 15002
            scheme: HTTP
          initialDelaySeconds: 40
          periodSeconds: 10
          timeoutSeconds: 5
        name: template-service
        ports:
        - containerPort: 15011
          name: grpc-template
          protocol: TCP
        - containerPort: 15002
          name: http-template
          protocol: TCP
        - containerPort: 16002
          name: grpc-gitsync
          protocol: TCP
        readinessProbe:
          failureThreshold: 8
          httpGet:
            path: /api/health
            port: 15002
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 5
          timeoutSeconds: 5
        resources:
          limits:
            memory: 1400Mi
          requests:
            cpu: 1
            memory: 1400Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 75
          httpGet:
            path: /api/health
            port: 15002
            scheme: HTTP
          initialDelaySeconds: 120
          periodSeconds: 5
          timeoutSeconds: 5
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      - args:
        - pod
        - -lapp=pipeline-service
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-pipeline-service
      serviceAccountName: template-service
      terminationGracePeriodSeconds: 180
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ti-service
    app.kubernetes.io/version: 0.0.release-223
    helm.sh/chart: ti-service-1.49.0
  name: ti-service
  namespace: harness
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ti-service
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: ti-service
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: ti-service
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - ti-service
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: TI_SERVICE_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: TI_SERVICE_GLOBAL_TOKEN
              name: ti-service
        - name: TI_SERVICE_TIMESCALE_USERNAME
          valueFrom:
            secretKeyRef:
              key: username
              name: tsdb-secret
        - name: TI_SERVICE_TIMESCALE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: password
              name: tsdb-secret
        - name: TI_SERVICE_TIMESCALE_HOST
          value: timescaledb
        - name: TSDB_URL
          value: postgres://$(TI_SERVICE_TIMESCALE_USERNAME):$(TI_SERVICE_TIMESCALE_PASSWORD)@timescaledb:5432/harnessti?sslmode=disable
        - name: TIHARNESS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: TIHARNESS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: TI_SERVICE_MONGODB_USERNAME
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: TI_SERVICE_MONGODB_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: TI_SERVICE_MONGODB_CONN_STR
          value: mongodb://$(TIHARNESS_MONGO_USER):$(TIHARNESS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/ti-harness?authSource=admin
        envFrom:
        - configMapRef:
            name: ti-service
        image: docker.io/harness/ti-service-signed:1.49.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: http-ti-service
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        name: ti-service
        ports:
        - containerPort: 8078
          name: http-ti-service
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /ready/healthz
            port: http-ti-service
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        resources:
          limits:
            memory: 3072Mi
          requests:
            cpu: 1
            memory: 3072Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        startupProbe:
          failureThreshold: 10
          httpGet:
            path: /healthz
            port: http-ti-service
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 20
          successThreshold: 1
          timeoutSeconds: 5
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 30
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    app: tiemscaledb
    owner: mcintoshj@gmail.com
  labels:
    app: tiemscaledb
  name: tiemscaledb
  namespace: harness
spec:
  replicas: 1
  revisionHistoryLimit: 5
  selector:
    matchLabels:
      app: tiemscaledb
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        app: tiemscaledb
        owner: mcintoshj@gmail.com
      labels:
        app: tiemscaledb
    spec:
      containers:
      - env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              key: timescaledbPostgresPassword
              name: harness-secrets
        - name: POSTGRES_USER
          value: postgres
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        image: timescale/timescaledb-ha:pg17
        imagePullPolicy: Always
        livenessProbe:
          failureThreshold: 3
          periodSeconds: 15
          successThreshold: 1
          tcpSocket:
            port: 5432
          timeoutSeconds: 1
        name: timescaledb
        ports:
        - containerPort: 5432
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          periodSeconds: 15
          successThreshold: 1
          tcpSocket:
            port: 5432
          timeoutSeconds: 1
        startupProbe:
          failureThreshold: 3
          periodSeconds: 15
          successThreshold: 1
          tcpSocket:
            port: 5432
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /var/lib/postgresql/data
          name: data
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      securityContext:
        fsGroup: 1000
        fsGroupChangePolicy: Always
        runAsGroup: 1000
        runAsUser: 1000
      terminationGracePeriodSeconds: 30
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: tiemscaledb
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: iac-server
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iac-server
    app.kubernetes.io/part-of: harness-infra-as-code
    helm.sh/chart: iac-server-1.242.0
  name: iac-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: iac-server
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 941afa9b53bca6f0edfd331c7439d690fb3abb5d6af8b1520f7cdbb7d3fe3923
      labels:
        app: iac-server
        app.kubernetes.io/component: admin
        app.kubernetes.io/instance: harness
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: iac-server
        app.kubernetes.io/part-of: harness-infra-as-code
        helm.sh/chart: iac-server-1.242.0
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - iac-server
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: PLATFORM_SECRET_KEY
          valueFrom:
            secretKeyRef:
              key: PLATFORM_SECRET_KEY
              name: iac-server
        - name: POLICY_MGMT_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              key: POLICY_MGMT_AUTH_SECRET
              name: iac-server
        - name: SEGMENT_WRITE_KEY
          valueFrom:
            secretKeyRef:
              key: SEGMENT_WRITE_KEY
              name: iac-server
        - name: SERVICE_GLOBAL_TOKEN
          valueFrom:
            secretKeyRef:
              key: SERVICE_GLOBAL_TOKEN
              name: iac-server
        - name: AUDIT_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              key: AUDIT_AUTH_SECRET
              name: iac-server
        - name: HARNESS_CODE_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              key: HARNESS_CODE_AUTH_SECRET
              name: iac-server
        - name: NG_MANAGER_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              key: NG_MANAGER_AUTH_SECRET
              name: iac-server
        - name: PIPELINE_SERVICE_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              key: PIPELINE_SERVICE_AUTH_SECRET
              name: iac-server
        - name: MINIO_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              key: root-password
              name: minio
        - name: MINIO_ROOT_USER
          valueFrom:
            secretKeyRef:
              key: root-user
              name: minio
        - name: POSTGRES_USER
          value: postgres
        - name: DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: postgres-password
              name: postgres
        - name: DATABASE_URL
          value: postgres://$(POSTGRES_USER):$(DATABASE_PASSWORD)@postgres:5432/$(POSTGRES_DB)?
        envFrom:
        - configMapRef:
            name: iac-server
        image: docker.io/harness/iac-server-signed:1.242.0
        imagePullPolicy: Always
        livenessProbe:
          httpGet:
            path: /api/health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
        name: iac-server
        readinessProbe:
          httpGet:
            path: /api/health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
        resources:
          limits:
            ephemeral-storage: 250M
            memory: 500M
          requests:
            cpu: 500m
            ephemeral-storage: 250M
            memory: 500M
        securityContext:
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 65534
        volumeMounts:
        - mountPath: /opt/harness/svc
          name: service-account
      initContainers:
      - command:
        - /bin/sh
        - -c
        - psql $DATABASE_URL -c "SELECT 1 FROM pg_database WHERE datname = 'iac_server'"
          | grep -q 1 || psql $DATABASE_URL -c "CREATE DATABASE iac_server"
        env:
        - name: POSTGRES_USER
          value: postgres
        - name: DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: postgres-password
              name: postgres
        - name: DATABASE_URL
          value: postgres://$(POSTGRES_USER):$(DATABASE_PASSWORD)@postgres:5432/postgres?
        envFrom:
        - configMapRef:
            name: iac-server
        image: docker.io/bitnamilegacy/postgresql:14.11.0-debian-11-r17
        imagePullPolicy: IfNotPresent
        name: create-db
        securityContext:
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 65534
        volumeMounts:
        - mountPath: /opt/harness/svc
          name: service-account
      securityContext:
        fsGroup: 65534
        sysctls:
        - name: net.ipv4.ip_local_port_range
          value: 10240 65000
      serviceAccountName: harness-default
      volumes:
      - name: service-account
        secret:
          items:
          - key: redis-labs-ca-pem
            path: redis_labs_ca_truststore
          secretName: iac-server-service-accounts
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: audit-event-streaming
    app.kubernetes.io/version: 1.0.79802
    helm.sh/chart: audit-event-streaming-1.52.1
  name: audit-event-streaming
  namespace: harness
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: audit-event-streaming
  serviceName: audit-event-streaming
  template:
    metadata:
      annotations:
        checksum/config: f8e61d74a1d4422a1bdba945dc0571e166f2da97718f0a0883acef86ff677ace
      labels:
        app: audit-event-streaming
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: audit-event-streaming
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - audit-event-streaming
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: AUDITS_MONGO_USER
          valueFrom:
            secretKeyRef:
              key: mongodbUsername
              name: harness-secrets
        - name: AUDITS_MONGO_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGO_URI
          value: mongodb://$(AUDITS_MONGO_USER):$(AUDITS_MONGO_PASSWORD)@mongodb-replicaset-chart-0.mongodb-replicaset-chart.harness.svc/audits?authSource=admin
        envFrom:
        - configMapRef:
            name: audit-event-streaming
        image: docker.io/harness/audit-event-streaming-signed:1.52.1
        imagePullPolicy: IfNotPresent
        lifecycle: null
        name: audit-event-streaming
        resources:
          limits:
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 2Gi
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        volumeMounts: null
      initContainers:
      - args:
        - pod
        - -lapp=mongodb-replicaset
        image: docker.io/harness/helm-init-container:1.5.0
        imagePullPolicy: Always
        name: wait-for-mongo
      securityContext: {}
      serviceAccountName: harness-default
      terminationGracePeriodSeconds: 180
      volumes: null
  updateStrategy:
    type: RollingUpdate
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: mongodb
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/version: 6.0.1
    helm.sh/chart: mongodb-13.1.2
  name: mongodb-replicaset-chart
  namespace: harness
spec:
  podManagementPolicy: OrderedReady
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/component: mongodb
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: mongodb
  serviceName: mongodb-replicaset-chart
  template:
    metadata:
      annotations:
        prometheus.io/path: /metrics
        prometheus.io/port: "9216"
        prometheus.io/scrape: "false"
      labels:
        app: mongodb-replicaset
        app.kubernetes.io/component: mongodb
        app.kubernetes.io/instance: harness
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mongodb
        app.kubernetes.io/version: 6.0.1
        helm.sh/chart: mongodb-13.1.2
    spec:
      affinity:
        nodeAffinity: null
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: mongodb
                  app.kubernetes.io/instance: harness
                  app.kubernetes.io/name: mongodb
              topologyKey: kubernetes.io/hostname
            weight: 1
      containers:
      - command:
        - /scripts/setup.sh
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MY_POD_HOST_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: K8S_SERVICE_NAME
          value: mongodb-replicaset-chart
        - name: MONGODB_INITIAL_PRIMARY_HOST
          value: mongodb-replicaset-chart-0.$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local
        - name: MONGODB_REPLICA_SET_NAME
          value: rs0
        - name: MONGODB_ADVERTISED_HOSTNAME
          value: $(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local
        - name: MONGODB_ROOT_USER
          value: admin
        - name: MONGODB_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGODB_REPLICA_SET_KEY
          valueFrom:
            secretKeyRef:
              key: mongodb-replica-set-key
              name: mongodb-replicaset-chart
        - name: ALLOW_EMPTY_PASSWORD
          value: "no"
        - name: MONGODB_SYSTEM_LOG_VERBOSITY
          value: "0"
        - name: MONGODB_DISABLE_SYSTEM_LOG
          value: "no"
        - name: MONGODB_DISABLE_JAVASCRIPT
          value: "no"
        - name: MONGODB_ENABLE_JOURNAL
          value: "yes"
        - name: MONGODB_PORT_NUMBER
          value: "27017"
        - name: MONGODB_ENABLE_IPV6
          value: "no"
        - name: MONGODB_ENABLE_DIRECTORY_PER_DB
          value: "no"
        image: docker.io/harness/mongo:7.0.22
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - /bitnami/scripts/ping-mongodb.sh
          failureThreshold: 6
          initialDelaySeconds: 30
          periodSeconds: 20
          successThreshold: 1
          timeoutSeconds: 10
        name: mongodb
        ports:
        - containerPort: 27017
          name: mongodb
        readinessProbe:
          exec:
            command:
            - /bitnami/scripts/readiness-probe.sh
          failureThreshold: 6
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        resources:
          limits:
            cpu: 4
            memory: 8192Mi
          requests:
            cpu: 4
            memory: 8192Mi
        securityContext:
          runAsNonRoot: true
          runAsUser: 1001
        volumeMounts:
        - mountPath: /bitnami/mongodb
          name: datadir
          subPath: null
        - mountPath: /bitnami/scripts
          name: common-scripts
        - mountPath: /scripts/setup.sh
          name: scripts
          subPath: setup.sh
      securityContext:
        fsGroup: 1001
        sysctls: []
      serviceAccountName: mongodb-replicaset-chart
      volumes:
      - configMap:
          defaultMode: 360
          name: mongodb-replicaset-chart-common-scripts
        name: common-scripts
      - configMap:
          defaultMode: 493
          name: mongodb-replicaset-chart-scripts
        name: scripts
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: datadir
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 200Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: arbiter
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/version: 6.0.1
    helm.sh/chart: mongodb-13.1.2
  name: mongodb-replicaset-chart-arbiter
  namespace: harness
spec:
  podManagementPolicy: OrderedReady
  selector:
    matchLabels:
      app.kubernetes.io/component: arbiter
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: mongodb
  serviceName: mongodb-replicaset-chart-arbiter-headless
  template:
    metadata:
      labels:
        app.kubernetes.io/component: arbiter
        app.kubernetes.io/instance: harness
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mongodb
        app.kubernetes.io/version: 6.0.1
        helm.sh/chart: mongodb-13.1.2
    spec:
      affinity:
        nodeAffinity: null
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: arbiter
                  app.kubernetes.io/instance: harness
                  app.kubernetes.io/name: mongodb
              topologyKey: kubernetes.io/hostname
            weight: 1
      containers:
      - env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: K8S_SERVICE_NAME
          value: mongodb-replicaset-chart-arbiter-headless
        - name: MONGODB_REPLICA_SET_MODE
          value: arbiter
        - name: MONGODB_INITIAL_PRIMARY_HOST
          value: mongodb-replicaset-chart-0.mongodb-replicaset-chart.$(MY_POD_NAMESPACE).svc.cluster.local
        - name: MONGODB_REPLICA_SET_NAME
          value: rs0
        - name: MONGODB_ADVERTISED_HOSTNAME
          value: $(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local
        - name: MONGODB_PORT_NUMBER
          value: "27017"
        - name: MONGODB_INITIAL_PRIMARY_ROOT_USER
          value: admin
        - name: MONGODB_INITIAL_PRIMARY_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              key: mongodb-root-password
              name: mongodb-replicaset-chart
        - name: MONGODB_REPLICA_SET_KEY
          valueFrom:
            secretKeyRef:
              key: mongodb-replica-set-key
              name: mongodb-replicaset-chart
        - name: ALLOW_EMPTY_PASSWORD
          value: "no"
        image: docker.io/harness/mongo:7.0.22
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 6
          initialDelaySeconds: 30
          periodSeconds: 20
          successThreshold: 1
          tcpSocket:
            port: mongodb
          timeoutSeconds: 10
        name: mongodb-arbiter
        ports:
        - containerPort: 27017
          name: mongodb
        readinessProbe:
          failureThreshold: 6
          initialDelaySeconds: 5
          periodSeconds: 20
          successThreshold: 1
          tcpSocket:
            port: mongodb
          timeoutSeconds: 10
        resources:
          limits: {}
          requests: {}
        securityContext:
          runAsNonRoot: true
          runAsUser: 1001
      initContainers: null
      securityContext:
        fsGroup: 1001
        sysctls: []
      serviceAccountName: mongodb-replicaset-chart
  updateStrategy:
    type: RollingUpdate
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: postgres
    app.kubernetes.io/component: primary
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.2.0
    helm.sh/chart: postgresql-12.4.2
  name: postgres
  namespace: harness
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: primary
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: postgresql
  serviceName: postgres-hl
  template:
    metadata:
      labels:
        app: postgres
        app.kubernetes.io/component: primary
        app.kubernetes.io/instance: harness
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 15.2.0
        helm.sh/chart: postgresql-12.4.2
      name: postgres
    spec:
      affinity:
        nodeAffinity: null
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: primary
                  app.kubernetes.io/instance: harness
                  app.kubernetes.io/name: postgresql
              topologyKey: kubernetes.io/hostname
            weight: 1
      containers:
      - env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: POSTGRESQL_PORT_NUMBER
          value: "5432"
        - name: POSTGRESQL_VOLUME_DIR
          value: /bitnami/postgresql
        - name: PGDATA
          value: /bitnami/postgresql/data
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              key: postgres-password
              name: postgres
        - name: POSTGRES_DB
          value: overops
        - name: POSTGRESQL_ENABLE_LDAP
          value: "no"
        - name: POSTGRESQL_ENABLE_TLS
          value: "no"
        - name: POSTGRESQL_LOG_HOSTNAME
          value: "false"
        - name: POSTGRESQL_LOG_CONNECTIONS
          value: "false"
        - name: POSTGRESQL_LOG_DISCONNECTIONS
          value: "false"
        - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
          value: "off"
        - name: POSTGRESQL_CLIENT_MIN_MESSAGES
          value: error
        - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
          value: pgaudit
        image: docker.io/bitnamilegacy/postgresql:14.11.0-debian-11-r17
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - exec pg_isready -U "postgres" -d "dbname=overops" -h 127.0.0.1 -p 5432
          failureThreshold: 6
          initialDelaySeconds: 30
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        name: postgresql
        ports:
        - containerPort: 5432
          name: tcp-postgresql
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - -e
            - |
              exec pg_isready -U "postgres" -d "dbname=overops" -h 127.0.0.1 -p 5432
          failureThreshold: 6
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        resources:
          limits:
            cpu: 4
            memory: 8192Mi
          requests:
            cpu: 4
            memory: 8192Mi
        securityContext:
          runAsUser: 1001
        volumeMounts:
        - mountPath: /dev/shm
          name: dshm
        - mountPath: /bitnami/postgresql
          name: data
      hostIPC: false
      hostNetwork: false
      securityContext:
        fsGroup: 1001
      serviceAccountName: postgres
      volumes:
      - emptyDir:
          medium: Memory
        name: dshm
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 200Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: redis-sentinel
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 6.2.14-alpine
    helm.sh/chart: redis-0.8.2
    redis-sentinel-harness: replica
  name: redis-sentinel-harness-server
  namespace: harness
spec:
  podManagementPolicy: OrderedReady
  replicas: 3
  selector:
    matchLabels:
      app: redis-sentinel
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: redis
      release: redis-ha
  serviceName: redis-sentinel-harness
  template:
    metadata:
      annotations:
        checksum/init-config: 0fb17318c62ec6e7f89897284e4d3edf7b1a0fc156692f8b15db8fd976df2e48
        prometheus.io/path: /metrics
        prometheus.io/port: "9121"
        prometheus.io/scrape: "false"
      labels:
        app: redis-sentinel
        app.kubernetes.io/instance: harness
        app.kubernetes.io/name: redis
        redis-sentinel-harness: replica
        release: redis-ha
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: redis-sentinel
                  redis-sentinel-harness: replica
                  release: redis-ha
              topologyKey: failure-domain.beta.kubernetes.io/zone
            weight: 100
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: redis-sentinel
                release: redis-ha
            topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - /data/conf/redis.conf
        command:
        - redis-server
        env: null
        image: docker.io/redis:6.2.14-alpine
        imagePullPolicy: IfNotPresent
        livenessProbe:
          initialDelaySeconds: 15
          tcpSocket:
            port: 6379
        name: redis
        ports:
        - containerPort: 6379
          name: redis
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 0.1
            memory: 200Mi
        volumeMounts:
        - mountPath: /data
          name: data
      - args:
        - /data/conf/sentinel.conf
        command:
        - redis-sentinel
        image: docker.io/redis:6.2.14-alpine
        imagePullPolicy: IfNotPresent
        livenessProbe:
          initialDelaySeconds: 15
          tcpSocket:
            port: 26379
        name: sentinel
        ports:
        - containerPort: 26379
          name: sentinel
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - mountPath: /data
          name: data
      initContainers:
      - args:
        - /readonly-config/init.sh
        command:
        - sh
        env:
        - name: SENTINEL_ID_0
          value: ed89975e57ea5a6848fe664901b11b5e6b22b537
        - name: SENTINEL_ID_1
          value: 4abd57ef009b0a1595767af80ef815e3438ae7e9
        - name: SENTINEL_ID_2
          value: e21a3c2cf7abdfc6e8d921901addb1bf86fe32a0
        image: docker.io/redis:6.2.14-alpine
        imagePullPolicy: IfNotPresent
        name: config-init
        resources: {}
        volumeMounts:
        - mountPath: /readonly-config
          name: config
          readOnly: true
        - mountPath: /data
          name: data
      securityContext:
        fsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
      serviceAccountName: harness-default
      volumes:
      - configMap:
          name: redis-sentinel-harness-configmap
        name: config
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      annotations: null
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: access-control
    app.kubernetes.io/version: 1.0.79802
    helm.sh/chart: access-control-1.105.1
  name: access-control
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: access-control
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ci-manager
    app.kubernetes.io/version: 0.0.5309
    helm.sh/chart: ci-manager-1.97.3
  name: ci-manager
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ci-manager
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: cv-nextgen
    app.kubernetes.io/version: 1.9.0
    helm.sh/chart: cv-nextgen-1.44.0
  name: cv-nextgen
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: cv-nextgen
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gateway
    app.kubernetes.io/version: 0.0.11401
    helm.sh/chart: gateway-1.54.7
  name: gateway
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: gateway
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gitops
    app.kubernetes.io/version: v0.81.3
    helm.sh/chart: gitops-1.41.5
  name: gitops
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: gitops
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: harness-manager
    app.kubernetes.io/version: 0.0.81725
    helm.sh/chart: harness-manager-1.105.3
  name: harness-manager
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: harness-manager
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm-iterator
    app.kubernetes.io/name: harness-manager-iterator
    app.kubernetes.io/version: 0.0.81725
    helm.sh/chart: harness-manager-1.105.3
  name: harness-manager-iterator
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: harness-manager-iterator
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iacm-manager
    app.kubernetes.io/part-of: harness-infra-as-code
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: iacm-manager-1.100.1
  name: iacm-manager
  namespace: harness
spec:
  minAvailable: 60%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: iacm-manager
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: le-nextgen
    app.kubernetes.io/version: 0.0.68305
    helm.sh/chart: le-nextgen-1.10.0
  name: le-nextgen
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: le-nextgen
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: log-service
    app.kubernetes.io/version: 0.0.release-128-ubi
    helm.sh/chart: log-service-1.26.3
  name: log-service
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: log-service
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: next-gen-ui
    app.kubernetes.io/version: 0.353.10
    helm.sh/chart: next-gen-ui-1.93.7
  name: next-gen-ui
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: next-gen-ui
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-auth-ui
    app.kubernetes.io/version: 0.0.1
    helm.sh/chart: ng-auth-ui-1.36.2
  name: ng-auth-ui
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ng-auth-ui
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-dashboard-aggregator
    app.kubernetes.io/version: 0.0.80909
    helm.sh/chart: ng-dashboard-aggregator-1.70.1
  name: ng-dashboard-aggregator
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ng-dashboard-aggregator
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ng-manager
    app.kubernetes.io/version: 0.0.80209
    helm.sh/chart: ng-manager-1.107.6
  name: ng-manager
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ng-manager
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pipeline-service
    app.kubernetes.io/version: 1.41.3
    helm.sh/chart: pipeline-service-1.147.3
  name: pipeline-service
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: pipeline-service
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: platform-service
    app.kubernetes.io/version: 0.0.80000
    helm.sh/chart: platform-service-1.84.1
  name: platform-service
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: platform-service
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: policy-mgmt
    app.kubernetes.io/version: v1.68.0
    helm.sh/chart: policy-mgmt-1.24.4
  name: policy-mgmt
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: policy-mgmt
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: queue-service
    app.kubernetes.io/version: 1.16.0
    helm.sh/chart: queue-service-1.7.4
  name: queue-service
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: queue-service
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: scm-service
    app.kubernetes.io/version: 0.0.release-181-ubi
    helm.sh/chart: scm-service-1.40.2
  name: scm-service
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: scm-service
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: srm-ui
    app.kubernetes.io/version: 0.6.1
    helm.sh/chart: srm-ui-1.13.1
  name: srm-ui
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: srm-ui
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: template-service
    app.kubernetes.io/version: 1.12.1
    helm.sh/chart: template-service-1.109.2
  name: template-service
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: template-service
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ti-service
    app.kubernetes.io/version: 0.0.release-223
    helm.sh/chart: ti-service-1.49.0
  name: ti-service
  namespace: harness
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: ti-service
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: iac-server
    app.kubernetes.io/part-of: harness-infra-as-code
    helm.sh/chart: iac-server-1.242.0
  name: iac-server
spec:
  minAvailable: 60%
  selector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: iac-server
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: access-control-service
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /authz(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /api/$1
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: access-control-v1-apis
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/roles)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/roles/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/roles)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/roles/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/projects/.+/roles)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/projects/.+/roles/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/role-assignments)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/role-assignments/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/role-assignments)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/role-assignments/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/projects/.+/role-assignments)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/projects/.+/role-assignments/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/projects/.+/analyze-access-policies)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/orgs/.+/analyze-access-policies)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: access-control
            port:
              number: 9006
        path: /(v1/analyze-access-policies)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: audit-service
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /audit(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: change-data-capture-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: change-data-capture
            port:
              number: 8190
        path: /cdc(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: ci-manager-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: ci-manager
            port:
              number: 7090
        path: /ci(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /cv/api$1$2
  name: cv-nextgen-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: cv-nextgen
            port:
              number: 6060
        path: /cv/api(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /cv/api/$1
  name: cv-nextgen-1
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: cv-nextgen
            port:
              number: 6060
        path: /(v1/orgs/.+/projects/.+/slo.*)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: cv-nextgen
            port:
              number: 6060
        path: /(v1/orgs/.+/projects/.+/metric-graph/.+)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
  name: delegate-proxy
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: delegate-proxy
            port:
              number: 80
        path: /storage
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: gateway-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: gateway
            port:
              number: 80
        path: /gateway/(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: gitops-http
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: gitops
            port:
              number: 7908
        path: /gitops(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /api$1$2
  name: harness-manager-api
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: harness-manager
            port:
              number: 9090
        path: /api(/|$)(.*)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: harness-manager
            port:
              number: 9999
        path: /api/swagger(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /stream$1$2
  name: harness-manager-stream
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: harness-manager
            port:
              number: 9090
        path: /stream(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: next-gen-ui
    app.kubernetes.io/version: 0.353.10
    helm.sh/chart: next-gen-ui-1.93.7
  name: harness-ui
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: next-gen-ui
            port:
              number: 80
        path: /
        pathType: Prefix
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: iac-server-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: iac-server
            port:
              number: 8080
        path: /iacm(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
  name: iac-server-1
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: iac-server
            port:
              number: 8080
        path: /.well-known/terraform.json
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: iacm-manager-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: iacm-manager
            port:
              number: 7090
        path: /iacm-manager(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: log-service-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: log-service
            port:
              number: 8079
        path: /log-service(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: next-gen-ui-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: next-gen-ui
            port:
              number: 80
        path: /ng(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: ng-auth-ui-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: ng-auth-ui
            port:
              number: 80
        path: /auth(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: ng-dashboard-aggregator-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: ng-dashboard-aggregator
            port:
              number: 7100
        path: /ng-dashboard/api(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: ng-manager
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /ng/api(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$1
  name: ng-manager-v1-apis
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/secrets)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/secrets/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/secrets)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/secrets/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/secrets)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/secrets/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/connectors)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/connectors/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/connectors)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/connectors/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/connectors)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/connectors/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/services)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/services/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/services)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/services/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/services)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/services/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/environments)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/environments/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/environments)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/environments/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/environments)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/environments/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/ip-allowlist)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/ip-allowlist/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/favorites)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/favorites/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/eula/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/gitx-webhooks/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/gitx-webhooks)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/gitx-webhook-events)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/gitx-webhook-events/.+/validation-info)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/certificates)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/certificates/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/certificates)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/certificates/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/certificates)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/certificates/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/rancher/connectors/.+/clusters)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/rancher/connectors/.+/clusters)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/rancher/connectors/.+/clusters)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/rancher/environments/.+/infrastructure-definitions/.+/clusters)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/rancher/environments/.+/infrastructure-definitions/.+/clusters)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/rancher/environments/.+/infrastructure-definitions/.+/clusters)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/ldap-settings)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/ldap-settings/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/licenseUsageActivity/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/devSubscriptions)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/moduleLicenseUtilization)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/updateModuleAccess)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/moduleAccess/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/listPrincipalsWithAccess)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/creditOverUsage/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/credits/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/webhooks)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/webhooks)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/webhooks)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/webhooks/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/webhooks/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/webhooks/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/create-webhooks)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/create-webhooks)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/create-webhooks)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/webhooks/list)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/webhooks/list)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/orgs/.+/projects/.+/webhooks/list)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/licensedModules)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/dailyModuleAccountAccess)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/banners)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/banners/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/oidc-provider)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/oidc-provider/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/subscription/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: ng-manager
            port:
              number: 7090
        path: /(v1/subscription/devops/.+)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: notification-service
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /notifications(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: pipeline-service
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /pipeline(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /api/$1
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: pipeline-service-v1-apis
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/pipelines.*)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/input-sets.*)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/pipeline-schema.*)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/pipelines/.+/execute/stages-execution-list)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/pipelines/.+/execute/stages)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/pipelines/.+/execute/dynamic)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/pipelines/.+/execute/notification-rules/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/pipelines/.+/execute)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/step-pallete)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/triggers/catalog)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/approvals/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/pipelines/.+/triggers)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/pipelines/.+/triggers/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/execution/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: pipeline-service
            port:
              number: 12001
        path: /(v1/orgs/.+/projects/.+/pipelines/.+/execute/.+/retry-stages)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /api/$1
  name: platform-service-v1-apis
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/resource-groups)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/resource-groups/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/resource-groups)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/resource-groups/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/resource-groups)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/resource-groups/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/streaming-destinations)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/streaming-destinations/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/notification-channels/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/notification-channels)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/notification-channels/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/notification-channels)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/notification-channels/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/notification-channels)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/notification-rules/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/notification-rules)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/notification-rules/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/notification-rules)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/notification-rules/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/notification-rules)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/validate-channels/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/validate-rules/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/validate-channels/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/validate-rules/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/validate-channels/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/validate-rules/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/notification-resource-list)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/attachments)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/default-notification-template-set)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/default-notification-template-set/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/default-notification-template-set)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/default-notification-template-set/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/default-notification-template-set)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/orgs/.+/projects/.+/default-notification-template-set/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/data-sinks)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/data-sinks/validate-unique-identifier/.+)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /(v1/data-sinks/.+)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "1800"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: policy-mgmt-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: policy-mgmt
            port:
              number: 3000
        path: /pm(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: queue-service-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: queue-service
            port:
              number: 9091
        path: /queue-service(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: resource-group
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /resourcegroup(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
  name: srm-ui-ingress
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: srm-ui
            port:
              number: 80
        path: /srmui(/|$)(.*)
        pathType: Prefix
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: streaming-manager-service
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: platform-service
            port:
              number: 9005
        path: /streaming-manager-service(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: template-service-0
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: template-service
            port:
              number: 15002
        path: /template(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /api/$1
  name: template-service-smp-v1-apis
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: template-service
            port:
              number: 15002
        path: /(v1/templates.*)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: template-service
            port:
              number: 15002
        path: /(v1/orgs/.+/templates.*)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: template-service
            port:
              number: 15002
        path: /(v1/orgs/.+/projects/.+/templates.*)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: template-service
            port:
              number: 15002
        path: /(v1/template-schema.*)
        pathType: ImplementationSpecific
      - backend:
          service:
            name: template-service
            port:
              number: 15002
        path: /(v1/common/templates.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: cloudflare-issuer
    nginx.ingress.kubernetes.io/proxy-read-timeout: "11111111300"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: ti-service
  namespace: harness
spec:
  ingressClassName: nginx
  rules:
  - host: harness.mcintosh.farm
    http:
      paths:
      - backend:
          service:
            name: ti-service
            port:
              number: 8078
        path: /ti-service(/|$)(.*)
        pathType: ImplementationSpecific
  tls:
  - hosts:
    - harness.mcintosh.farm
    secretName: harness-cert
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  labels:
    app.kubernetes.io/instance: harness
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2025.7.18
    helm.sh/chart: minio-17.0.15
  name: minio
  namespace: harness
spec:
  egress:
  - {}
  ingress:
  - ports:
    - port: 9000
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: harness
      app.kubernetes.io/name: minio
  policyTypes:
  - Ingress
  - Egress
